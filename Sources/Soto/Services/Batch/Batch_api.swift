//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2024 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

#if canImport(FoundationEssentials)
import FoundationEssentials
#else
import Foundation
#endif
@_exported import SotoCore

/// Service object for interacting with AWS Batch service.
///
/// Batch Using Batch, you can run batch computing workloads on the Amazon Web Services Cloud. Batch computing is a common means for developers, scientists, and engineers to access large amounts of compute resources. Batch uses the advantages of the batch computing to remove the undifferentiated heavy lifting of configuring and managing required infrastructure. At the same time, it also adopts a familiar batch computing software approach. You can use Batch to efficiently provision resources, and work toward eliminating capacity constraints, reducing your overall compute costs, and delivering results more quickly. As a fully managed service, Batch can run batch computing workloads of any scale. Batch automatically provisions compute resources and optimizes workload distribution based on the quantity and scale of your specific workloads. With Batch, there's no need to install or manage batch computing software. This means that you can focus on analyzing results and solving your specific problems instead.
public struct Batch: AWSService {
    // MARK: Member variables

    /// Client used for communication with AWS
    public let client: AWSClient
    /// Service configuration
    public let config: AWSServiceConfig

    // MARK: Initialization

    /// Initialize the Batch client
    /// - parameters:
    ///     - client: AWSClient used to process requests
    ///     - region: Region of server you want to communicate with. This will override the partition parameter.
    ///     - partition: AWS partition where service resides, standard (.aws), china (.awscn), government (.awsusgov).
    ///     - endpoint: Custom endpoint URL to use instead of standard AWS servers
    ///     - middleware: Middleware chain used to edit requests before they are sent and responses before they are decoded 
    ///     - timeout: Timeout value for HTTP requests
    ///     - byteBufferAllocator: Allocator for ByteBuffers
    ///     - options: Service options
    public init(
        client: AWSClient,
        region: SotoCore.Region? = nil,
        partition: AWSPartition = .aws,
        endpoint: String? = nil,
        middleware: AWSMiddlewareProtocol? = nil,
        timeout: TimeAmount? = nil,
        byteBufferAllocator: ByteBufferAllocator = ByteBufferAllocator(),
        options: AWSServiceConfig.Options = []
    ) {
        self.client = client
        self.config = AWSServiceConfig(
            region: region,
            partition: region?.partition ?? partition,
            serviceName: "Batch",
            serviceIdentifier: "batch",
            serviceProtocol: .restjson,
            apiVersion: "2016-08-10",
            endpoint: endpoint,
            variantEndpoints: Self.variantEndpoints,
            errorType: BatchErrorType.self,
            xmlNamespace: "http://batch.amazonaws.com/doc/2016-08-10/",
            middleware: middleware,
            timeout: timeout,
            byteBufferAllocator: byteBufferAllocator,
            options: options
        )
    }




    /// FIPS and dualstack endpoints
    static var variantEndpoints: [EndpointVariantType: AWSServiceConfig.EndpointVariant] {[
        [.fips]: .init(endpoints: [
            "af-south-1": "fips.batch.af-south-1.amazonaws.com",
            "ap-east-1": "fips.batch.ap-east-1.amazonaws.com",
            "ap-northeast-1": "fips.batch.ap-northeast-1.amazonaws.com",
            "ap-northeast-2": "fips.batch.ap-northeast-2.amazonaws.com",
            "ap-northeast-3": "fips.batch.ap-northeast-3.amazonaws.com",
            "ap-south-1": "fips.batch.ap-south-1.amazonaws.com",
            "ap-south-2": "fips.batch.ap-south-2.amazonaws.com",
            "ap-southeast-1": "fips.batch.ap-southeast-1.amazonaws.com",
            "ap-southeast-2": "fips.batch.ap-southeast-2.amazonaws.com",
            "ap-southeast-3": "fips.batch.ap-southeast-3.amazonaws.com",
            "ap-southeast-4": "fips.batch.ap-southeast-4.amazonaws.com",
            "ap-southeast-5": "fips.batch.ap-southeast-5.amazonaws.com",
            "ap-southeast-7": "fips.batch.ap-southeast-7.amazonaws.com",
            "ca-central-1": "fips.batch.ca-central-1.amazonaws.com",
            "ca-west-1": "fips.batch.ca-west-1.amazonaws.com",
            "eu-central-1": "fips.batch.eu-central-1.amazonaws.com",
            "eu-central-2": "fips.batch.eu-central-2.amazonaws.com",
            "eu-north-1": "fips.batch.eu-north-1.amazonaws.com",
            "eu-south-1": "fips.batch.eu-south-1.amazonaws.com",
            "eu-south-2": "fips.batch.eu-south-2.amazonaws.com",
            "eu-west-1": "fips.batch.eu-west-1.amazonaws.com",
            "eu-west-2": "fips.batch.eu-west-2.amazonaws.com",
            "eu-west-3": "fips.batch.eu-west-3.amazonaws.com",
            "il-central-1": "fips.batch.il-central-1.amazonaws.com",
            "me-central-1": "fips.batch.me-central-1.amazonaws.com",
            "me-south-1": "fips.batch.me-south-1.amazonaws.com",
            "mx-central-1": "fips.batch.mx-central-1.amazonaws.com",
            "sa-east-1": "fips.batch.sa-east-1.amazonaws.com",
            "us-east-1": "fips.batch.us-east-1.amazonaws.com",
            "us-east-2": "fips.batch.us-east-2.amazonaws.com",
            "us-gov-east-1": "batch.us-gov-east-1.amazonaws.com",
            "us-gov-west-1": "batch.us-gov-west-1.amazonaws.com",
            "us-west-1": "fips.batch.us-west-1.amazonaws.com",
            "us-west-2": "fips.batch.us-west-2.amazonaws.com"
        ])
    ]}

    // MARK: API Calls

    /// Cancels a job in an Batch job queue. Jobs that are in a SUBMITTED, PENDING, or RUNNABLE state are cancelled and the job status is updated to FAILED.  A PENDING job is canceled after all dependency jobs are completed. Therefore, it may take longer than expected to cancel a job in PENDING status. When you try to cancel an array parent job in PENDING, Batch attempts to cancel all child jobs. The array parent job is canceled when all child jobs are completed.  Jobs that progressed to the STARTING or RUNNING state aren't canceled. However, the API operation still succeeds, even if no job is canceled. These jobs must be terminated with the TerminateJob operation.
    @Sendable
    @inlinable
    public func cancelJob(_ input: CancelJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CancelJobResponse {
        try await self.client.execute(
            operation: "CancelJob", 
            path: "/v1/canceljob", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Cancels a job in an Batch job queue. Jobs that are in a SUBMITTED, PENDING, or RUNNABLE state are cancelled and the job status is updated to FAILED.  A PENDING job is canceled after all dependency jobs are completed. Therefore, it may take longer than expected to cancel a job in PENDING status. When you try to cancel an array parent job in PENDING, Batch attempts to cancel all child jobs. The array parent job is canceled when all child jobs are completed.  Jobs that progressed to the STARTING or RUNNING state aren't canceled. However, the API operation still succeeds, even if no job is canceled. These jobs must be terminated with the TerminateJob operation.
    ///
    /// Parameters:
    ///   - jobId: The Batch job ID of the job to cancel.
    ///   - reason: A message to attach to the job that explains the reason for canceling it. This message is returned by future DescribeJobs operations on the job. It is also recorded in the Batch activity logs. This parameter has as limit of 1024 characters.
    ///   - logger: Logger use during operation
    @inlinable
    public func cancelJob(
        jobId: String? = nil,
        reason: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CancelJobResponse {
        let input = CancelJobRequest(
            jobId: jobId, 
            reason: reason
        )
        return try await self.cancelJob(input, logger: logger)
    }

    /// Creates an Batch compute environment. You can create MANAGED or UNMANAGED compute environments. MANAGED compute environments can use Amazon EC2 or Fargate resources. UNMANAGED compute environments can only use EC2 resources. In a managed compute environment, Batch manages the capacity and instance types of the compute resources within the environment. This is based on the compute resource specification that you define or the launch template that you specify when you create the compute environment. Either, you can choose to use EC2 On-Demand Instances and EC2 Spot Instances. Or, you can use Fargate and Fargate Spot capacity in your managed compute environment. You can optionally set a maximum price so that Spot Instances only launch when the Spot Instance price is less than a specified percentage of the On-Demand price.  Multi-node parallel jobs aren't supported on Spot Instances.  In an unmanaged compute environment, you can manage your own EC2 compute resources and have flexibility with how you configure your compute resources. For example, you can use custom AMIs. However, you must verify that each of your AMIs meet the Amazon ECS container instance AMI specification. For more information, see container instance AMIs in the Amazon Elastic Container Service Developer Guide. After you created your unmanaged compute environment, you can use the DescribeComputeEnvironments operation to find the Amazon ECS cluster that's associated with it. Then, launch your container instances into that Amazon ECS cluster. For more information, see Launching an Amazon ECS container instance in the Amazon Elastic Container Service Developer Guide.  To create a compute environment that uses EKS resources, the caller must have permissions to call eks:DescribeCluster.   Batch doesn't automatically upgrade the AMIs in a compute environment after it's created. For example, it also doesn't update the AMIs in your compute environment when a newer version of the Amazon ECS optimized AMI is available. You're responsible for the management of the guest operating system. This includes any updates and security patches. You're also responsible for any additional application software or utilities that you install on the compute resources. There are two ways to use a new AMI for your Batch jobs. The original method is to complete these steps:   Create a new compute environment with the new AMI.   Add the compute environment to an existing job queue.   Remove the earlier compute environment from your job queue.   Delete the earlier compute environment.   In April 2022, Batch added enhanced support for updating compute environments. For more information, see Updating compute environments. To use the enhanced updating of compute environments to update AMIs, follow these rules:   Either don't set the service role (serviceRole) parameter or set it to the AWSBatchServiceRole service-linked role.   Set the allocation strategy (allocationStrategy) parameter to BEST_FIT_PROGRESSIVE, SPOT_CAPACITY_OPTIMIZED, or SPOT_PRICE_CAPACITY_OPTIMIZED.   Set the update to latest image version (updateToLatestImageVersion) parameter to true. The updateToLatestImageVersion parameter  is used when you update a compute environment. This parameter is ignored when you create  a compute environment.   Don't specify an AMI ID in imageId, imageIdOverride (in  ec2Configuration ), or in the launch template (launchTemplate). In that case, Batch selects the latest Amazon ECS optimized AMI that's supported by Batch at the time the infrastructure update is initiated. Alternatively, you can specify the AMI ID in the imageId or imageIdOverride parameters, or the launch template identified by the LaunchTemplate properties. Changing any of these properties starts an infrastructure update. If the AMI ID is specified in the launch template, it can't be replaced by specifying an AMI ID in either the imageId or imageIdOverride parameters. It can only be replaced by specifying a different launch template, or if the launch template version is set to $Default or $Latest, by setting either a new default version for the launch template (if $Default) or by adding a new version to the launch template (if $Latest).   If these rules are followed, any update that starts an infrastructure update causes the AMI ID to be re-selected. If the version setting in the launch template (launchTemplate) is set to $Latest or $Default, the latest or default version of the launch template is evaluated up at the time of the infrastructure update, even if the launchTemplate wasn't updated.
    @Sendable
    @inlinable
    public func createComputeEnvironment(_ input: CreateComputeEnvironmentRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateComputeEnvironmentResponse {
        try await self.client.execute(
            operation: "CreateComputeEnvironment", 
            path: "/v1/createcomputeenvironment", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Batch compute environment. You can create MANAGED or UNMANAGED compute environments. MANAGED compute environments can use Amazon EC2 or Fargate resources. UNMANAGED compute environments can only use EC2 resources. In a managed compute environment, Batch manages the capacity and instance types of the compute resources within the environment. This is based on the compute resource specification that you define or the launch template that you specify when you create the compute environment. Either, you can choose to use EC2 On-Demand Instances and EC2 Spot Instances. Or, you can use Fargate and Fargate Spot capacity in your managed compute environment. You can optionally set a maximum price so that Spot Instances only launch when the Spot Instance price is less than a specified percentage of the On-Demand price.  Multi-node parallel jobs aren't supported on Spot Instances.  In an unmanaged compute environment, you can manage your own EC2 compute resources and have flexibility with how you configure your compute resources. For example, you can use custom AMIs. However, you must verify that each of your AMIs meet the Amazon ECS container instance AMI specification. For more information, see container instance AMIs in the Amazon Elastic Container Service Developer Guide. After you created your unmanaged compute environment, you can use the DescribeComputeEnvironments operation to find the Amazon ECS cluster that's associated with it. Then, launch your container instances into that Amazon ECS cluster. For more information, see Launching an Amazon ECS container instance in the Amazon Elastic Container Service Developer Guide.  To create a compute environment that uses EKS resources, the caller must have permissions to call eks:DescribeCluster.   Batch doesn't automatically upgrade the AMIs in a compute environment after it's created. For example, it also doesn't update the AMIs in your compute environment when a newer version of the Amazon ECS optimized AMI is available. You're responsible for the management of the guest operating system. This includes any updates and security patches. You're also responsible for any additional application software or utilities that you install on the compute resources. There are two ways to use a new AMI for your Batch jobs. The original method is to complete these steps:   Create a new compute environment with the new AMI.   Add the compute environment to an existing job queue.   Remove the earlier compute environment from your job queue.   Delete the earlier compute environment.   In April 2022, Batch added enhanced support for updating compute environments. For more information, see Updating compute environments. To use the enhanced updating of compute environments to update AMIs, follow these rules:   Either don't set the service role (serviceRole) parameter or set it to the AWSBatchServiceRole service-linked role.   Set the allocation strategy (allocationStrategy) parameter to BEST_FIT_PROGRESSIVE, SPOT_CAPACITY_OPTIMIZED, or SPOT_PRICE_CAPACITY_OPTIMIZED.   Set the update to latest image version (updateToLatestImageVersion) parameter to true. The updateToLatestImageVersion parameter  is used when you update a compute environment. This parameter is ignored when you create  a compute environment.   Don't specify an AMI ID in imageId, imageIdOverride (in  ec2Configuration ), or in the launch template (launchTemplate). In that case, Batch selects the latest Amazon ECS optimized AMI that's supported by Batch at the time the infrastructure update is initiated. Alternatively, you can specify the AMI ID in the imageId or imageIdOverride parameters, or the launch template identified by the LaunchTemplate properties. Changing any of these properties starts an infrastructure update. If the AMI ID is specified in the launch template, it can't be replaced by specifying an AMI ID in either the imageId or imageIdOverride parameters. It can only be replaced by specifying a different launch template, or if the launch template version is set to $Default or $Latest, by setting either a new default version for the launch template (if $Default) or by adding a new version to the launch template (if $Latest).   If these rules are followed, any update that starts an infrastructure update causes the AMI ID to be re-selected. If the version setting in the launch template (launchTemplate) is set to $Latest or $Default, the latest or default version of the launch template is evaluated up at the time of the infrastructure update, even if the launchTemplate wasn't updated.
    ///
    /// Parameters:
    ///   - computeEnvironmentName: The name for your compute environment. It can be up to 128 characters long. It can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
    ///   - computeResources: Details about the compute resources managed by the compute environment. This parameter is required for managed compute environments. For more information, see Compute Environments in the Batch User Guide.
    ///   - context: Reserved.
    ///   - eksConfiguration: The details for the Amazon EKS cluster that supports the compute environment.
    ///   - serviceRole: The full Amazon Resource Name (ARN) of the IAM role that allows Batch to make calls to other Amazon Web Services services on your behalf. For more information, see Batch service IAM role in the Batch User Guide.  If your account already created the Batch service-linked role, that role is used by default for your compute environment unless you specify a different role here. If the Batch service-linked role doesn't exist in your account, and no role is specified here, the service attempts to create the Batch service-linked role in your account.  If your specified role has a path other than /, then you must specify either the full role ARN (recommended) or prefix the role name with the path. For example, if a role with the name bar has a path of /foo/, specify /foo/bar as the role name. For more information, see Friendly names and paths in the IAM User Guide.  Depending on how you created your Batch service role, its ARN might contain the service-role path prefix. When you only specify the name of the service role, Batch assumes that your ARN doesn't use the service-role path prefix. Because of this, we recommend that you specify the full ARN of your service role when you create compute environments.
    ///   - state: The state of the compute environment. If the state is ENABLED, then the compute environment accepts jobs from a queue and can scale out automatically based on queues. If the state is ENABLED, then the Batch scheduler can attempt to place jobs from an associated job queue on the compute resources within the environment. If the compute environment is managed, then it can scale its instances out or in automatically, based on the job queue demand. If the state is DISABLED, then the Batch scheduler doesn't attempt to place jobs within the environment. Jobs in a STARTING or RUNNING state continue to progress normally. Managed compute environments in the DISABLED state don't scale out.   Compute environments in a DISABLED state may continue to incur billing charges. To prevent additional charges, turn off and then delete the compute environment. For more information, see State in the Batch User Guide.  When an instance is idle, the instance scales down to the minvCpus value. However, the instance size doesn't change. For example, consider a c5.8xlarge instance with a minvCpus value of 4 and a desiredvCpus value of 36. This instance doesn't scale down to a c5.large instance.
    ///   - tags: The tags that you apply to the compute environment to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging Amazon Web Services Resources in Amazon Web Services General Reference. These tags can be updated or removed using the TagResource and UntagResource API operations. These tags don't propagate to the underlying compute resources.
    ///   - type: The type of the compute environment: MANAGED or UNMANAGED. For more information, see Compute Environments in the Batch User Guide.
    ///   - unmanagedvCpus: The maximum number of vCPUs for an unmanaged compute environment. This parameter is only used for fair-share scheduling to reserve vCPU capacity for new share identifiers. If this parameter isn't provided for a fair-share job queue, no vCPU capacity is reserved.  This parameter is only supported when the type parameter is set to UNMANAGED.
    ///   - logger: Logger use during operation
    @inlinable
    public func createComputeEnvironment(
        computeEnvironmentName: String? = nil,
        computeResources: ComputeResource? = nil,
        context: String? = nil,
        eksConfiguration: EksConfiguration? = nil,
        serviceRole: String? = nil,
        state: CEState? = nil,
        tags: [String: String]? = nil,
        type: CEType? = nil,
        unmanagedvCpus: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateComputeEnvironmentResponse {
        let input = CreateComputeEnvironmentRequest(
            computeEnvironmentName: computeEnvironmentName, 
            computeResources: computeResources, 
            context: context, 
            eksConfiguration: eksConfiguration, 
            serviceRole: serviceRole, 
            state: state, 
            tags: tags, 
            type: type, 
            unmanagedvCpus: unmanagedvCpus
        )
        return try await self.createComputeEnvironment(input, logger: logger)
    }

    /// Creates an Batch consumable resource.
    @Sendable
    @inlinable
    public func createConsumableResource(_ input: CreateConsumableResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateConsumableResourceResponse {
        try await self.client.execute(
            operation: "CreateConsumableResource", 
            path: "/v1/createconsumableresource", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Batch consumable resource.
    ///
    /// Parameters:
    ///   - consumableResourceName: The name of the consumable resource. Must be unique.
    ///   - resourceType: Indicates whether the resource is available to be re-used after a job completes. Can be  one of:     REPLENISHABLE (default)    NON_REPLENISHABLE
    ///   - tags: The tags that you apply to the consumable resource to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging your Batch resources.
    ///   - totalQuantity: The total amount of the consumable resource that is available. Must be non-negative.
    ///   - logger: Logger use during operation
    @inlinable
    public func createConsumableResource(
        consumableResourceName: String? = nil,
        resourceType: String? = nil,
        tags: [String: String]? = nil,
        totalQuantity: Int64? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateConsumableResourceResponse {
        let input = CreateConsumableResourceRequest(
            consumableResourceName: consumableResourceName, 
            resourceType: resourceType, 
            tags: tags, 
            totalQuantity: totalQuantity
        )
        return try await self.createConsumableResource(input, logger: logger)
    }

    /// Creates an Batch job queue. When you create a job queue, you associate one or more compute environments to the queue and assign an order of preference for the compute environments. You also set a priority to the job queue that determines the order that the Batch scheduler places jobs onto its associated compute environments. For example, if a compute environment is associated with more than one job queue, the job queue with a higher priority is given preference for scheduling jobs to that compute environment.
    @Sendable
    @inlinable
    public func createJobQueue(_ input: CreateJobQueueRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateJobQueueResponse {
        try await self.client.execute(
            operation: "CreateJobQueue", 
            path: "/v1/createjobqueue", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Batch job queue. When you create a job queue, you associate one or more compute environments to the queue and assign an order of preference for the compute environments. You also set a priority to the job queue that determines the order that the Batch scheduler places jobs onto its associated compute environments. For example, if a compute environment is associated with more than one job queue, the job queue with a higher priority is given preference for scheduling jobs to that compute environment.
    ///
    /// Parameters:
    ///   - computeEnvironmentOrder: The set of compute environments mapped to a job queue and their order relative to each other. The job scheduler uses this parameter to determine which compute environment runs a specific job. Compute environments must be in the VALID state before you can associate them with a job queue. You can associate up to three compute environments with a job queue. All of the compute environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT); EC2 and Fargate compute environments can't be mixed.  All compute environments that are associated with a job queue must share the same architecture. Batch doesn't support mixing compute environment architecture types in a single job queue.
    ///   - jobQueueName: The name of the job queue. It can be up to 128 letters long. It can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
    ///   - jobStateTimeLimitActions: The set of actions that Batch performs on jobs that remain at the head of the job queue in the specified state longer than specified times. Batch will perform each action after maxTimeSeconds has passed. (Note: The minimum value for maxTimeSeconds is 600 (10 minutes) and its maximum value is 86,400 (24 hours).)
    ///   - priority: The priority of the job queue. Job queues with a higher priority (or a higher integer value for the priority parameter) are evaluated first when associated with the same compute environment. Priority is determined in descending order. For example, a job queue with a priority value of 10 is given scheduling preference over a job queue with a priority value of 1. All of the compute environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT); EC2 and Fargate compute environments can't be mixed.
    ///   - schedulingPolicyArn: The Amazon Resource Name (ARN) of the fair-share scheduling policy. Job queues that don't have a fair-share scheduling policy are scheduled in a first-in, first-out (FIFO) model.  After a job queue has a fair-share scheduling policy, it can be replaced but can't be removed. The format is aws:Partition:batch:Region:Account:scheduling-policy/Name . An example is aws:aws:batch:us-west-2:123456789012:scheduling-policy/MySchedulingPolicy. A job queue without a fair-share scheduling policy is scheduled as a FIFO job queue and can't have a fair-share scheduling policy added. Jobs queues with a fair-share scheduling policy can have a maximum of 500 active share identifiers. When the limit has been reached, submissions of any jobs that add a new share identifier fail.
    ///   - state: The state of the job queue. If the job queue state is ENABLED, it is able to accept jobs. If the job queue state is DISABLED, new jobs can't be added to the queue, but jobs already in the queue can finish.
    ///   - tags: The tags that you apply to the job queue to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging your Batch resources in Batch User Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func createJobQueue(
        computeEnvironmentOrder: [ComputeEnvironmentOrder]? = nil,
        jobQueueName: String? = nil,
        jobStateTimeLimitActions: [JobStateTimeLimitAction]? = nil,
        priority: Int? = nil,
        schedulingPolicyArn: String? = nil,
        state: JQState? = nil,
        tags: [String: String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateJobQueueResponse {
        let input = CreateJobQueueRequest(
            computeEnvironmentOrder: computeEnvironmentOrder, 
            jobQueueName: jobQueueName, 
            jobStateTimeLimitActions: jobStateTimeLimitActions, 
            priority: priority, 
            schedulingPolicyArn: schedulingPolicyArn, 
            state: state, 
            tags: tags
        )
        return try await self.createJobQueue(input, logger: logger)
    }

    /// Creates an Batch scheduling policy.
    @Sendable
    @inlinable
    public func createSchedulingPolicy(_ input: CreateSchedulingPolicyRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateSchedulingPolicyResponse {
        try await self.client.execute(
            operation: "CreateSchedulingPolicy", 
            path: "/v1/createschedulingpolicy", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Batch scheduling policy.
    ///
    /// Parameters:
    ///   - fairsharePolicy: The fair-share scheduling policy details.
    ///   - name: The name of the fair-share scheduling policy. It can be up to 128 letters long. It can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
    ///   - tags: The tags that you apply to the scheduling policy to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging Amazon Web Services Resources in Amazon Web Services General Reference. These tags can be updated or removed using the TagResource and UntagResource API operations.
    ///   - logger: Logger use during operation
    @inlinable
    public func createSchedulingPolicy(
        fairsharePolicy: FairsharePolicy? = nil,
        name: String? = nil,
        tags: [String: String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateSchedulingPolicyResponse {
        let input = CreateSchedulingPolicyRequest(
            fairsharePolicy: fairsharePolicy, 
            name: name, 
            tags: tags
        )
        return try await self.createSchedulingPolicy(input, logger: logger)
    }

    /// Deletes an Batch compute environment. Before you can delete a compute environment, you must set its state to DISABLED with the UpdateComputeEnvironment API operation and disassociate it from any job queues with the UpdateJobQueue API operation. Compute environments that use Fargate resources must terminate all active jobs on that compute environment before deleting the compute environment. If this isn't done, the compute environment enters an invalid state.
    @Sendable
    @inlinable
    public func deleteComputeEnvironment(_ input: DeleteComputeEnvironmentRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteComputeEnvironmentResponse {
        try await self.client.execute(
            operation: "DeleteComputeEnvironment", 
            path: "/v1/deletecomputeenvironment", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes an Batch compute environment. Before you can delete a compute environment, you must set its state to DISABLED with the UpdateComputeEnvironment API operation and disassociate it from any job queues with the UpdateJobQueue API operation. Compute environments that use Fargate resources must terminate all active jobs on that compute environment before deleting the compute environment. If this isn't done, the compute environment enters an invalid state.
    ///
    /// Parameters:
    ///   - computeEnvironment: The name or Amazon Resource Name (ARN) of the compute environment to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteComputeEnvironment(
        computeEnvironment: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteComputeEnvironmentResponse {
        let input = DeleteComputeEnvironmentRequest(
            computeEnvironment: computeEnvironment
        )
        return try await self.deleteComputeEnvironment(input, logger: logger)
    }

    /// Deletes the specified consumable resource.
    @Sendable
    @inlinable
    public func deleteConsumableResource(_ input: DeleteConsumableResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteConsumableResourceResponse {
        try await self.client.execute(
            operation: "DeleteConsumableResource", 
            path: "/v1/deleteconsumableresource", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified consumable resource.
    ///
    /// Parameters:
    ///   - consumableResource: The name or ARN of the consumable resource that will be deleted.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteConsumableResource(
        consumableResource: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteConsumableResourceResponse {
        let input = DeleteConsumableResourceRequest(
            consumableResource: consumableResource
        )
        return try await self.deleteConsumableResource(input, logger: logger)
    }

    /// Deletes the specified job queue. You must first disable submissions for a queue with the UpdateJobQueue operation. All jobs in the queue are eventually terminated when you delete a job queue. The jobs are terminated at a rate of about 16 jobs each second. It's not necessary to disassociate compute environments from a queue before submitting a DeleteJobQueue request.
    @Sendable
    @inlinable
    public func deleteJobQueue(_ input: DeleteJobQueueRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteJobQueueResponse {
        try await self.client.execute(
            operation: "DeleteJobQueue", 
            path: "/v1/deletejobqueue", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified job queue. You must first disable submissions for a queue with the UpdateJobQueue operation. All jobs in the queue are eventually terminated when you delete a job queue. The jobs are terminated at a rate of about 16 jobs each second. It's not necessary to disassociate compute environments from a queue before submitting a DeleteJobQueue request.
    ///
    /// Parameters:
    ///   - jobQueue: The short name or full Amazon Resource Name (ARN) of the queue to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteJobQueue(
        jobQueue: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteJobQueueResponse {
        let input = DeleteJobQueueRequest(
            jobQueue: jobQueue
        )
        return try await self.deleteJobQueue(input, logger: logger)
    }

    /// Deletes the specified scheduling policy. You can't delete a scheduling policy that's used in any job queues.
    @Sendable
    @inlinable
    public func deleteSchedulingPolicy(_ input: DeleteSchedulingPolicyRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteSchedulingPolicyResponse {
        try await self.client.execute(
            operation: "DeleteSchedulingPolicy", 
            path: "/v1/deleteschedulingpolicy", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified scheduling policy. You can't delete a scheduling policy that's used in any job queues.
    ///
    /// Parameters:
    ///   - arn: The Amazon Resource Name (ARN) of the scheduling policy to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteSchedulingPolicy(
        arn: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteSchedulingPolicyResponse {
        let input = DeleteSchedulingPolicyRequest(
            arn: arn
        )
        return try await self.deleteSchedulingPolicy(input, logger: logger)
    }

    /// Deregisters an Batch job definition. Job definitions are permanently deleted after 180 days.
    @Sendable
    @inlinable
    public func deregisterJobDefinition(_ input: DeregisterJobDefinitionRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DeregisterJobDefinitionResponse {
        try await self.client.execute(
            operation: "DeregisterJobDefinition", 
            path: "/v1/deregisterjobdefinition", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deregisters an Batch job definition. Job definitions are permanently deleted after 180 days.
    ///
    /// Parameters:
    ///   - jobDefinition: The name and revision (name:revision) or full Amazon Resource Name (ARN) of the job definition to deregister.
    ///   - logger: Logger use during operation
    @inlinable
    public func deregisterJobDefinition(
        jobDefinition: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeregisterJobDefinitionResponse {
        let input = DeregisterJobDefinitionRequest(
            jobDefinition: jobDefinition
        )
        return try await self.deregisterJobDefinition(input, logger: logger)
    }

    /// Describes one or more of your compute environments. If you're using an unmanaged compute environment, you can use the DescribeComputeEnvironment operation to determine the ecsClusterArn that you launch your Amazon ECS container instances into.
    @Sendable
    @inlinable
    public func describeComputeEnvironments(_ input: DescribeComputeEnvironmentsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeComputeEnvironmentsResponse {
        try await self.client.execute(
            operation: "DescribeComputeEnvironments", 
            path: "/v1/describecomputeenvironments", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes one or more of your compute environments. If you're using an unmanaged compute environment, you can use the DescribeComputeEnvironment operation to determine the ecsClusterArn that you launch your Amazon ECS container instances into.
    ///
    /// Parameters:
    ///   - computeEnvironments: A list of up to 100 compute environment names or full Amazon Resource Name (ARN) entries.
    ///   - maxResults: The maximum number of cluster results returned by DescribeComputeEnvironments in paginated output. When this parameter is used, DescribeComputeEnvironments only returns maxResults results in a single page along with a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeComputeEnvironments request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeComputeEnvironments returns up to 100 results and a nextToken value if applicable.
    ///   - nextToken: The nextToken value returned from a previous paginated DescribeComputeEnvironments request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value. This value is null when there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeComputeEnvironments(
        computeEnvironments: [String]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeComputeEnvironmentsResponse {
        let input = DescribeComputeEnvironmentsRequest(
            computeEnvironments: computeEnvironments, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.describeComputeEnvironments(input, logger: logger)
    }

    /// Returns a description of the specified consumable resource.
    @Sendable
    @inlinable
    public func describeConsumableResource(_ input: DescribeConsumableResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeConsumableResourceResponse {
        try await self.client.execute(
            operation: "DescribeConsumableResource", 
            path: "/v1/describeconsumableresource", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a description of the specified consumable resource.
    ///
    /// Parameters:
    ///   - consumableResource: The name or ARN of the consumable resource whose description will be returned.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeConsumableResource(
        consumableResource: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeConsumableResourceResponse {
        let input = DescribeConsumableResourceRequest(
            consumableResource: consumableResource
        )
        return try await self.describeConsumableResource(input, logger: logger)
    }

    /// Describes a list of job definitions. You can specify a status (such as ACTIVE) to only return job definitions that match that status.
    @Sendable
    @inlinable
    public func describeJobDefinitions(_ input: DescribeJobDefinitionsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeJobDefinitionsResponse {
        try await self.client.execute(
            operation: "DescribeJobDefinitions", 
            path: "/v1/describejobdefinitions", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a list of job definitions. You can specify a status (such as ACTIVE) to only return job definitions that match that status.
    ///
    /// Parameters:
    ///   - jobDefinitionName: The name of the job definition to describe.
    ///   - jobDefinitions: A list of up to 100 job definitions. Each entry in the list can either be an ARN in the format arn:aws:batch:${Region}:${Account}:job-definition/${JobDefinitionName}:${Revision} or a short version using the form ${JobDefinitionName}:${Revision}. This parameter can't be used with other parameters.
    ///   - maxResults: The maximum number of results returned by DescribeJobDefinitions in paginated output. When this parameter is used, DescribeJobDefinitions only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeJobDefinitions request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeJobDefinitions returns up to 100 results and a nextToken value if applicable.
    ///   - nextToken: The nextToken value returned from a previous paginated DescribeJobDefinitions request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value. This value is null when there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - status: The status used to filter job definitions.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeJobDefinitions(
        jobDefinitionName: String? = nil,
        jobDefinitions: [String]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        status: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeJobDefinitionsResponse {
        let input = DescribeJobDefinitionsRequest(
            jobDefinitionName: jobDefinitionName, 
            jobDefinitions: jobDefinitions, 
            maxResults: maxResults, 
            nextToken: nextToken, 
            status: status
        )
        return try await self.describeJobDefinitions(input, logger: logger)
    }

    /// Describes one or more of your job queues.
    @Sendable
    @inlinable
    public func describeJobQueues(_ input: DescribeJobQueuesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeJobQueuesResponse {
        try await self.client.execute(
            operation: "DescribeJobQueues", 
            path: "/v1/describejobqueues", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes one or more of your job queues.
    ///
    /// Parameters:
    ///   - jobQueues: A list of up to 100 queue names or full queue Amazon Resource Name (ARN) entries.
    ///   - maxResults: The maximum number of results returned by DescribeJobQueues in paginated output. When this parameter is used, DescribeJobQueues only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeJobQueues request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeJobQueues returns up to 100 results and a nextToken value if applicable.
    ///   - nextToken: The nextToken value returned from a previous paginated DescribeJobQueues request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value. This value is null when there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeJobQueues(
        jobQueues: [String]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeJobQueuesResponse {
        let input = DescribeJobQueuesRequest(
            jobQueues: jobQueues, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.describeJobQueues(input, logger: logger)
    }

    /// Describes a list of Batch jobs.
    @Sendable
    @inlinable
    public func describeJobs(_ input: DescribeJobsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeJobsResponse {
        try await self.client.execute(
            operation: "DescribeJobs", 
            path: "/v1/describejobs", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a list of Batch jobs.
    ///
    /// Parameters:
    ///   - jobs: A list of up to 100 job IDs.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeJobs(
        jobs: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeJobsResponse {
        let input = DescribeJobsRequest(
            jobs: jobs
        )
        return try await self.describeJobs(input, logger: logger)
    }

    /// Describes one or more of your scheduling policies.
    @Sendable
    @inlinable
    public func describeSchedulingPolicies(_ input: DescribeSchedulingPoliciesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeSchedulingPoliciesResponse {
        try await self.client.execute(
            operation: "DescribeSchedulingPolicies", 
            path: "/v1/describeschedulingpolicies", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes one or more of your scheduling policies.
    ///
    /// Parameters:
    ///   - arns: A list of up to 100 scheduling policy Amazon Resource Name (ARN) entries.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeSchedulingPolicies(
        arns: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeSchedulingPoliciesResponse {
        let input = DescribeSchedulingPoliciesRequest(
            arns: arns
        )
        return try await self.describeSchedulingPolicies(input, logger: logger)
    }

    /// Provides a list of the first 100 RUNNABLE jobs associated to a single job queue.
    @Sendable
    @inlinable
    public func getJobQueueSnapshot(_ input: GetJobQueueSnapshotRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> GetJobQueueSnapshotResponse {
        try await self.client.execute(
            operation: "GetJobQueueSnapshot", 
            path: "/v1/getjobqueuesnapshot", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Provides a list of the first 100 RUNNABLE jobs associated to a single job queue.
    ///
    /// Parameters:
    ///   - jobQueue: The job queues name or full queue Amazon Resource Name (ARN).
    ///   - logger: Logger use during operation
    @inlinable
    public func getJobQueueSnapshot(
        jobQueue: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> GetJobQueueSnapshotResponse {
        let input = GetJobQueueSnapshotRequest(
            jobQueue: jobQueue
        )
        return try await self.getJobQueueSnapshot(input, logger: logger)
    }

    /// Returns a list of Batch consumable resources.
    @Sendable
    @inlinable
    public func listConsumableResources(_ input: ListConsumableResourcesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListConsumableResourcesResponse {
        try await self.client.execute(
            operation: "ListConsumableResources", 
            path: "/v1/listconsumableresources", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Batch consumable resources.
    ///
    /// Parameters:
    ///   - filters: The filters to apply to the consumable resource list query. If used, only those consumable  resources that match the filter are listed. Filter names and values can be:   name: CONSUMABLE_RESOURCE_NAME   values: case-insensitive matches for the consumable resource name. If a filter  value ends with an asterisk (*), it matches any consumable resource name that begins  with the string before the '*'.
    ///   - maxResults: The maximum number of results returned by ListConsumableResources in paginated output. When this parameter is used, ListConsumableResources only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another ListConsumableResources request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then ListConsumableResources returns up to 100 results and a nextToken value if applicable.
    ///   - nextToken: The nextToken value returned from a previous paginated  ListConsumableResources request where maxResults was used and the  results exceeded the value of that parameter. Pagination continues from the end of the previous  results that returned the nextToken value. This value is null when  there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func listConsumableResources(
        filters: [KeyValuesPair]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListConsumableResourcesResponse {
        let input = ListConsumableResourcesRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listConsumableResources(input, logger: logger)
    }

    /// Returns a list of Batch jobs. You must specify only one of the following items:   A job queue ID to return a list of jobs in that job queue   A multi-node parallel job ID to return a list of nodes for that job   An array job ID to return a list of the children for that job   You can filter the results by job status with the jobStatus parameter. If you don't specify a status, only RUNNING jobs are returned.
    @Sendable
    @inlinable
    public func listJobs(_ input: ListJobsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListJobsResponse {
        try await self.client.execute(
            operation: "ListJobs", 
            path: "/v1/listjobs", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Batch jobs. You must specify only one of the following items:   A job queue ID to return a list of jobs in that job queue   A multi-node parallel job ID to return a list of nodes for that job   An array job ID to return a list of the children for that job   You can filter the results by job status with the jobStatus parameter. If you don't specify a status, only RUNNING jobs are returned.
    ///
    /// Parameters:
    ///   - arrayJobId: The job ID for an array job. Specifying an array job ID with this parameter lists all child jobs from within the specified array.
    ///   - filters: The filter to apply to the query. Only one filter can be used at a time. When the filter is used, jobStatus is ignored. The filter doesn't apply to child jobs in an array or multi-node parallel (MNP) jobs. The results are sorted by the createdAt field, with the most recent jobs being first.  JOB_NAME  The value of the filter is a case-insensitive match for the job name. If the value ends with an asterisk (*), the filter matches any job name that begins with the string before the '*'. This corresponds to the jobName value. For example, test1 matches both Test1 and test1, and test1* matches both test1 and Test10. When the JOB_NAME filter is used, the results are grouped by the job name and version.  JOB_DEFINITION  The value for the filter is the name or Amazon Resource Name (ARN) of the job definition. This corresponds to the jobDefinition value. The value is case sensitive. When the value for the filter is the job definition name, the results include all the jobs that used any revision of that job definition name. If the value ends with an asterisk (*), the filter matches any job definition name that begins with the string before the '*'. For example, jd1 matches only jd1, and jd1* matches both jd1 and jd1A. The version of the job definition that's used doesn't affect the sort order. When the JOB_DEFINITION filter is used and the ARN is used (which is in the form arn:${Partition}:batch:${Region}:${Account}:job-definition/${JobDefinitionName}:${Revision}), the results include jobs that used the specified revision of the job definition. Asterisk (*) isn't supported when the ARN is used.  BEFORE_CREATED_AT  The value for the filter is the time that's before the job was created. This corresponds to the createdAt value. The value is a string representation of the number of milliseconds since 00:00:00 UTC (midnight) on January 1, 1970.  AFTER_CREATED_AT  The value for the filter is the time that's after the job was created. This corresponds to the createdAt value. The value is a string representation of the number of milliseconds since 00:00:00 UTC (midnight) on January 1, 1970.
    ///   - jobQueue: The name or full Amazon Resource Name (ARN) of the job queue used to list jobs.
    ///   - jobStatus: The job status used to filter jobs in the specified queue. If the filters parameter is specified, the jobStatus parameter is ignored and jobs with any status are returned. If you don't specify a status, only RUNNING jobs are returned.
    ///   - maxResults: The maximum number of results returned by ListJobs in a paginated output. When this parameter is used, ListJobs returns up to maxResults results in a single page and a nextToken response element, if applicable. The remaining results of the initial request can be seen by sending another ListJobs request with the returned nextToken value. The following outlines key parameters and limitations:   The minimum value is 1.    When --job-status is used, Batch returns up to 1000 values.    When --filters is used, Batch returns up to 100 values.   If neither parameter is used, then ListJobs returns up to 1000 results (jobs that are in the RUNNING status) and a nextToken value, if applicable.
    ///   - multiNodeJobId: The job ID for a multi-node parallel job. Specifying a multi-node parallel job ID with this parameter lists all nodes that are associated with the specified job.
    ///   - nextToken: The nextToken value returned from a previous paginated ListJobs request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value. This value is null when there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func listJobs(
        arrayJobId: String? = nil,
        filters: [KeyValuesPair]? = nil,
        jobQueue: String? = nil,
        jobStatus: JobStatus? = nil,
        maxResults: Int? = nil,
        multiNodeJobId: String? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListJobsResponse {
        let input = ListJobsRequest(
            arrayJobId: arrayJobId, 
            filters: filters, 
            jobQueue: jobQueue, 
            jobStatus: jobStatus, 
            maxResults: maxResults, 
            multiNodeJobId: multiNodeJobId, 
            nextToken: nextToken
        )
        return try await self.listJobs(input, logger: logger)
    }

    /// Returns a list of Batch jobs that require a specific consumable resource.
    @Sendable
    @inlinable
    public func listJobsByConsumableResource(_ input: ListJobsByConsumableResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListJobsByConsumableResourceResponse {
        try await self.client.execute(
            operation: "ListJobsByConsumableResource", 
            path: "/v1/listjobsbyconsumableresource", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Batch jobs that require a specific consumable resource.
    ///
    /// Parameters:
    ///   - consumableResource: The name or ARN of the consumable resource.
    ///   - filters: The filters to apply to the job list query. If used, only those jobs requiring the specified  consumable resource (consumableResource) and that match the value of the filters are listed. The filter names and values can be:   name: JOB_STATUS  values: SUBMITTED | PENDING | RUNNABLE | STARTING | RUNNING | SUCCEEDED | FAILED    name: JOB_NAME   The values are case-insensitive matches for the job name. If a filter value ends  with an asterisk (*), it matches any job name that begins with the string before  the '*'.
    ///   - maxResults: The maximum number of results returned by ListJobsByConsumableResource in paginated output. When this parameter is used, ListJobsByConsumableResource only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another ListJobsByConsumableResource request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then ListJobsByConsumableResource returns up to 100 results  and a nextToken value if applicable.
    ///   - nextToken: The nextToken value returned from a previous paginated  ListJobsByConsumableResource request where maxResults was used and the  results exceeded the value of that parameter. Pagination continues from the end of the previous  results that returned the nextToken value. This value is null when  there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func listJobsByConsumableResource(
        consumableResource: String? = nil,
        filters: [KeyValuesPair]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListJobsByConsumableResourceResponse {
        let input = ListJobsByConsumableResourceRequest(
            consumableResource: consumableResource, 
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listJobsByConsumableResource(input, logger: logger)
    }

    /// Returns a list of Batch scheduling policies.
    @Sendable
    @inlinable
    public func listSchedulingPolicies(_ input: ListSchedulingPoliciesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListSchedulingPoliciesResponse {
        try await self.client.execute(
            operation: "ListSchedulingPolicies", 
            path: "/v1/listschedulingpolicies", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Batch scheduling policies.
    ///
    /// Parameters:
    ///   - maxResults: The maximum number of results that's returned by ListSchedulingPolicies in paginated output. When this parameter is used, ListSchedulingPolicies only returns maxResults results in a single page and a nextToken response element. You can see the remaining results of the initial request by sending another ListSchedulingPolicies request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, ListSchedulingPolicies returns up to 100 results and a nextToken value if applicable.
    ///   - nextToken: The nextToken value that's returned from a previous paginated ListSchedulingPolicies request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value. This value is null when there are no more results to return.  Treat this token as an opaque identifier that's only used to retrieve the next items in a list and not for other programmatic purposes.
    ///   - logger: Logger use during operation
    @inlinable
    public func listSchedulingPolicies(
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListSchedulingPoliciesResponse {
        let input = ListSchedulingPoliciesRequest(
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listSchedulingPolicies(input, logger: logger)
    }

    /// Lists the tags for an Batch resource. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    @Sendable
    @inlinable
    public func listTagsForResource(_ input: ListTagsForResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListTagsForResourceResponse {
        try await self.client.execute(
            operation: "ListTagsForResource", 
            path: "/v1/tags/{resourceArn}", 
            httpMethod: .GET, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Lists the tags for an Batch resource. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) that identifies the resource that tags are listed for. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    ///   - logger: Logger use during operation
    @inlinable
    public func listTagsForResource(
        resourceArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListTagsForResourceResponse {
        let input = ListTagsForResourceRequest(
            resourceArn: resourceArn
        )
        return try await self.listTagsForResource(input, logger: logger)
    }

    /// Registers an Batch job definition.
    @Sendable
    @inlinable
    public func registerJobDefinition(_ input: RegisterJobDefinitionRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> RegisterJobDefinitionResponse {
        try await self.client.execute(
            operation: "RegisterJobDefinition", 
            path: "/v1/registerjobdefinition", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Registers an Batch job definition.
    ///
    /// Parameters:
    ///   - consumableResourceProperties: Contains a list of consumable resources required by the job.
    ///   - containerProperties: An object with properties specific to Amazon ECS-based single-node container-based jobs. If the job definition's type parameter is container, then you must specify either containerProperties or nodeProperties. This must not be specified for Amazon EKS-based job definitions.  If the job runs on Fargate resources, then you must not specify nodeProperties; use only containerProperties.
    ///   - ecsProperties: An object with properties that are specific to Amazon ECS-based jobs. This must not be specified for Amazon EKS-based job definitions.
    ///   - eksProperties: An object with properties that are specific to Amazon EKS-based jobs. This must not be specified for Amazon ECS based job definitions.
    ///   - jobDefinitionName: The name of the job definition to register. It can be up to 128 letters long. It can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
    ///   - nodeProperties: An object with properties specific to multi-node parallel jobs. If you specify node properties for a job, it becomes a multi-node parallel job. For more information, see Multi-node Parallel Jobs in the Batch User Guide.  If the job runs on Fargate resources, then you must not specify nodeProperties; use containerProperties instead.   If the job runs on Amazon EKS resources, then you must not specify nodeProperties.
    ///   - parameters: Default parameter substitution placeholders to set in the job definition. Parameters are specified as a key-value pair mapping. Parameters in a SubmitJob request override any corresponding parameter defaults from the job definition.
    ///   - platformCapabilities: The platform capabilities required by the job definition. If no value is specified, it defaults to EC2. To run the job on Fargate resources, specify FARGATE.  If the job runs on Amazon EKS resources, then you must not specify platformCapabilities.
    ///   - propagateTags: Specifies whether to propagate the tags from the job or job definition to the corresponding Amazon ECS task. If no value is specified, the tags are not propagated. Tags can only be propagated to the tasks during task creation. For tags with the same name, job tags are given priority over job definitions tags. If the total number of combined tags from the job and job definition is over 50, the job is moved to the FAILED state.  If the job runs on Amazon EKS resources, then you must not specify propagateTags.
    ///   - retryStrategy: The retry strategy to use for failed jobs that are submitted with this job definition. Any retry strategy that's specified during a SubmitJob operation overrides the retry strategy defined here. If a job is terminated due to a timeout, it isn't retried.
    ///   - schedulingPriority: The scheduling priority for jobs that are submitted with this job definition. This only affects jobs in job queues with a fair-share policy. Jobs with a higher scheduling priority are scheduled before jobs with a lower scheduling priority. The minimum supported value is 0 and the maximum supported value is 9999.
    ///   - tags: The tags that you apply to the job definition to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging Amazon Web Services Resources in Batch User Guide.
    ///   - timeout: The timeout configuration for jobs that are submitted with this job definition, after which Batch terminates your jobs if they have not finished. If a job is terminated due to a timeout, it isn't retried. The minimum value for the timeout is 60 seconds. Any timeout configuration that's specified during a SubmitJob operation overrides the timeout configuration defined here. For more information, see Job Timeouts in the Batch User Guide.
    ///   - type: The type of job definition. For more information about multi-node parallel jobs, see Creating a multi-node parallel job definition in the Batch User Guide.   If the value is container, then one of the following is required: containerProperties, ecsProperties, or eksProperties.   If the value is multinode, then nodeProperties is required.    If the job is run on Fargate resources, then multinode isn't supported.
    ///   - logger: Logger use during operation
    @inlinable
    public func registerJobDefinition(
        consumableResourceProperties: ConsumableResourceProperties? = nil,
        containerProperties: ContainerProperties? = nil,
        ecsProperties: EcsProperties? = nil,
        eksProperties: EksProperties? = nil,
        jobDefinitionName: String? = nil,
        nodeProperties: NodeProperties? = nil,
        parameters: [String: String]? = nil,
        platformCapabilities: [PlatformCapability]? = nil,
        propagateTags: Bool? = nil,
        retryStrategy: RetryStrategy? = nil,
        schedulingPriority: Int? = nil,
        tags: [String: String]? = nil,
        timeout: JobTimeout? = nil,
        type: JobDefinitionType? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> RegisterJobDefinitionResponse {
        let input = RegisterJobDefinitionRequest(
            consumableResourceProperties: consumableResourceProperties, 
            containerProperties: containerProperties, 
            ecsProperties: ecsProperties, 
            eksProperties: eksProperties, 
            jobDefinitionName: jobDefinitionName, 
            nodeProperties: nodeProperties, 
            parameters: parameters, 
            platformCapabilities: platformCapabilities, 
            propagateTags: propagateTags, 
            retryStrategy: retryStrategy, 
            schedulingPriority: schedulingPriority, 
            tags: tags, 
            timeout: timeout, 
            type: type
        )
        return try await self.registerJobDefinition(input, logger: logger)
    }

    /// Submits an Batch job from a job definition. Parameters that are specified during SubmitJob override parameters defined in the job definition. vCPU and memory requirements that are specified in the resourceRequirements objects in the job definition are the exception. They can't be overridden this way using the memory and vcpus parameters. Rather, you must specify updates to job definition parameters in a resourceRequirements object that's included in the containerOverrides parameter.  Job queues with a scheduling policy are limited to 500 active share identifiers at a time.    Jobs that run on Fargate resources can't be guaranteed to run for more than 14 days. This is because, after 14 days, Fargate resources might become unavailable and job might be terminated.
    @Sendable
    @inlinable
    public func submitJob(_ input: SubmitJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> SubmitJobResponse {
        try await self.client.execute(
            operation: "SubmitJob", 
            path: "/v1/submitjob", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Submits an Batch job from a job definition. Parameters that are specified during SubmitJob override parameters defined in the job definition. vCPU and memory requirements that are specified in the resourceRequirements objects in the job definition are the exception. They can't be overridden this way using the memory and vcpus parameters. Rather, you must specify updates to job definition parameters in a resourceRequirements object that's included in the containerOverrides parameter.  Job queues with a scheduling policy are limited to 500 active share identifiers at a time.    Jobs that run on Fargate resources can't be guaranteed to run for more than 14 days. This is because, after 14 days, Fargate resources might become unavailable and job might be terminated.
    ///
    /// Parameters:
    ///   - arrayProperties: The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. For more information, see Array Jobs in the Batch User Guide.
    ///   - consumableResourcePropertiesOverride: An object that contains overrides for the consumable resources of a job.
    ///   - containerOverrides: An object with properties that override the defaults for the job definition that specify the name of a container in the specified job definition and the overrides it should receive. You can override the default command for a container, which is specified in the job definition or the Docker image, with a command override. You can also override existing environment variables on a container or add new environment variables to it with an environment override.
    ///   - dependsOn: A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a SEQUENTIAL type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an N_TO_N type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.
    ///   - ecsPropertiesOverride: An object, with properties that override defaults for the job definition, can only be specified for jobs that are run on Amazon ECS resources.
    ///   - eksPropertiesOverride: An object, with properties that override defaults for the job definition, can only be specified for jobs that are run on Amazon EKS resources.
    ///   - jobDefinition: The job definition used by this job. This value can be one of definition-name, definition-name:revision, or the Amazon Resource Name (ARN) for the job definition, with or without the revision (arn:aws:batch:region:account:job-definition/definition-name:revision , or arn:aws:batch:region:account:job-definition/definition-name ). If the revision is not specified, then the latest active revision is used.
    ///   - jobName: The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
    ///   - jobQueue: The job queue where the job is submitted. You can specify either the name or the Amazon Resource Name (ARN) of the queue.
    ///   - nodeOverrides: A list of node overrides in JSON format that specify the node range to target and the container overrides for that node range.  This parameter isn't applicable to jobs that are running on Fargate resources; use containerOverrides instead.
    ///   - parameters: Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters in a SubmitJob request override any corresponding parameter defaults from the job definition.
    ///   - propagateTags: Specifies whether to propagate the tags from the job or job definition to the corresponding Amazon ECS task. If no value is specified, the tags aren't propagated. Tags can only be propagated to the tasks during task creation. For tags with the same name, job tags are given priority over job definitions tags. If the total number of combined tags from the job and job definition is over 50, the job is moved to the FAILED state. When specified, this overrides the tag propagation setting in the job definition.
    ///   - retryStrategy: The retry strategy to use for failed jobs from this SubmitJob operation. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.
    ///   - schedulingPriorityOverride: The scheduling priority for the job. This only affects jobs in job queues with a  fair-share policy. Jobs with a higher scheduling priority are scheduled before jobs with a lower scheduling priority. This overrides any scheduling priority in the job definition and works only  within a single share identifier. The minimum supported value is 0 and the maximum supported value is 9999.
    ///   - shareIdentifier: The share identifier for the job. Don't specify this parameter if the job queue doesn't have a fair-share scheduling policy. If the job queue has a fair-share scheduling policy, then this parameter must be specified. This string is limited to 255 alphanumeric characters, and can be followed by an asterisk (*).
    ///   - tags: The tags that you apply to the job request to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging Amazon Web Services Resources in Amazon Web Services General Reference.
    ///   - timeout: The timeout configuration for this SubmitJob operation. You can specify a timeout duration after which Batch terminates your jobs if they haven't finished. If a job is terminated due to a timeout, it isn't retried. The minimum value for the timeout is 60 seconds. This configuration overrides any timeout configuration specified in the job definition. For array jobs, child jobs have the same timeout configuration as the parent job. For more information, see Job Timeouts in the Amazon Elastic Container Service Developer Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func submitJob(
        arrayProperties: ArrayProperties? = nil,
        consumableResourcePropertiesOverride: ConsumableResourceProperties? = nil,
        containerOverrides: ContainerOverrides? = nil,
        dependsOn: [JobDependency]? = nil,
        ecsPropertiesOverride: EcsPropertiesOverride? = nil,
        eksPropertiesOverride: EksPropertiesOverride? = nil,
        jobDefinition: String? = nil,
        jobName: String? = nil,
        jobQueue: String? = nil,
        nodeOverrides: NodeOverrides? = nil,
        parameters: [String: String]? = nil,
        propagateTags: Bool? = nil,
        retryStrategy: RetryStrategy? = nil,
        schedulingPriorityOverride: Int? = nil,
        shareIdentifier: String? = nil,
        tags: [String: String]? = nil,
        timeout: JobTimeout? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> SubmitJobResponse {
        let input = SubmitJobRequest(
            arrayProperties: arrayProperties, 
            consumableResourcePropertiesOverride: consumableResourcePropertiesOverride, 
            containerOverrides: containerOverrides, 
            dependsOn: dependsOn, 
            ecsPropertiesOverride: ecsPropertiesOverride, 
            eksPropertiesOverride: eksPropertiesOverride, 
            jobDefinition: jobDefinition, 
            jobName: jobName, 
            jobQueue: jobQueue, 
            nodeOverrides: nodeOverrides, 
            parameters: parameters, 
            propagateTags: propagateTags, 
            retryStrategy: retryStrategy, 
            schedulingPriorityOverride: schedulingPriorityOverride, 
            shareIdentifier: shareIdentifier, 
            tags: tags, 
            timeout: timeout
        )
        return try await self.submitJob(input, logger: logger)
    }

    /// Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource aren't specified in the request parameters, they aren't changed. When a resource is deleted, the tags that are associated with that resource are deleted as well. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    @Sendable
    @inlinable
    public func tagResource(_ input: TagResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> TagResourceResponse {
        try await self.client.execute(
            operation: "TagResource", 
            path: "/v1/tags/{resourceArn}", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource aren't specified in the request parameters, they aren't changed. When a resource is deleted, the tags that are associated with that resource are deleted as well. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) of the resource that tags are added to. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    ///   - tags: The tags that you apply to the resource to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see Tagging Amazon Web Services Resources in Amazon Web Services General Reference.
    ///   - logger: Logger use during operation
    @inlinable
    public func tagResource(
        resourceArn: String,
        tags: [String: String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> TagResourceResponse {
        let input = TagResourceRequest(
            resourceArn: resourceArn, 
            tags: tags
        )
        return try await self.tagResource(input, logger: logger)
    }

    /// Terminates a job in a job queue. Jobs that are in the STARTING or RUNNING state are terminated, which causes them to transition to FAILED. Jobs that have not progressed to the STARTING state are cancelled.
    @Sendable
    @inlinable
    public func terminateJob(_ input: TerminateJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> TerminateJobResponse {
        try await self.client.execute(
            operation: "TerminateJob", 
            path: "/v1/terminatejob", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Terminates a job in a job queue. Jobs that are in the STARTING or RUNNING state are terminated, which causes them to transition to FAILED. Jobs that have not progressed to the STARTING state are cancelled.
    ///
    /// Parameters:
    ///   - jobId: The Batch job ID of the job to terminate.
    ///   - reason: A message to attach to the job that explains the reason for canceling it. This message is returned by future DescribeJobs operations on the job. It is also recorded in the Batch activity logs. This parameter has as limit of 1024 characters.
    ///   - logger: Logger use during operation
    @inlinable
    public func terminateJob(
        jobId: String? = nil,
        reason: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> TerminateJobResponse {
        let input = TerminateJobRequest(
            jobId: jobId, 
            reason: reason
        )
        return try await self.terminateJob(input, logger: logger)
    }

    /// Deletes specified tags from an Batch resource.
    @Sendable
    @inlinable
    public func untagResource(_ input: UntagResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UntagResourceResponse {
        try await self.client.execute(
            operation: "UntagResource", 
            path: "/v1/tags/{resourceArn}", 
            httpMethod: .DELETE, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes specified tags from an Batch resource.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) of the resource from which to delete tags. Batch resources that support tags are compute environments, jobs, job definitions, job queues, and scheduling policies. ARNs for child jobs of array and multi-node parallel (MNP) jobs aren't supported.
    ///   - tagKeys: The keys of the tags to be removed.
    ///   - logger: Logger use during operation
    @inlinable
    public func untagResource(
        resourceArn: String,
        tagKeys: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UntagResourceResponse {
        let input = UntagResourceRequest(
            resourceArn: resourceArn, 
            tagKeys: tagKeys
        )
        return try await self.untagResource(input, logger: logger)
    }

    /// Updates an Batch compute environment.
    @Sendable
    @inlinable
    public func updateComputeEnvironment(_ input: UpdateComputeEnvironmentRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UpdateComputeEnvironmentResponse {
        try await self.client.execute(
            operation: "UpdateComputeEnvironment", 
            path: "/v1/updatecomputeenvironment", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Updates an Batch compute environment.
    ///
    /// Parameters:
    ///   - computeEnvironment: The name or full Amazon Resource Name (ARN) of the compute environment to update.
    ///   - computeResources: Details of the compute resources managed by the compute environment. Required for a managed compute environment. For more information, see Compute Environments in the Batch User Guide.
    ///   - context: Reserved.
    ///   - serviceRole: The full Amazon Resource Name (ARN) of the IAM role that allows Batch to make calls to other Amazon Web Services services on your behalf. For more information, see Batch service IAM role in the Batch User Guide.  If the compute environment has a service-linked role, it can't be changed to use a regular IAM role. Likewise, if the compute environment has a regular IAM role, it can't be changed to use a service-linked role. To update the parameters for the compute environment that require an infrastructure update to change, the AWSServiceRoleForBatch service-linked role must be used. For more information, see Updating compute environments in the Batch User Guide.  If your specified role has a path other than /, then you must either specify the full role ARN (recommended) or prefix the role name with the path.  Depending on how you created your Batch service role, its ARN might contain the service-role path prefix. When you only specify the name of the service role, Batch assumes that your ARN doesn't use the service-role path prefix. Because of this, we recommend that you specify the full ARN of your service role when you create compute environments.
    ///   - state: The state of the compute environment. Compute environments in the ENABLED state can accept jobs from a queue and scale in or out automatically based on the workload demand of its associated queues. If the state is ENABLED, then the Batch scheduler can attempt to place jobs from an associated job queue on the compute resources within the environment. If the compute environment is managed, then it can scale its instances out or in automatically, based on the job queue demand. If the state is DISABLED, then the Batch scheduler doesn't attempt to place jobs within the environment. Jobs in a STARTING or RUNNING state continue to progress normally. Managed compute environments in the DISABLED state don't scale out.   Compute environments in a DISABLED state may continue to incur billing charges. To prevent additional charges, turn off and then delete the compute environment. For more information, see State in the Batch User Guide.  When an instance is idle, the instance scales down to the minvCpus value. However, the instance size doesn't change. For example, consider a c5.8xlarge instance with a minvCpus value of 4 and a desiredvCpus value of 36. This instance doesn't scale down to a c5.large instance.
    ///   - unmanagedvCpus: The maximum number of vCPUs expected to be used for an unmanaged compute environment. Don't specify this parameter for a managed compute environment. This parameter is only used for fair-share scheduling to reserve vCPU capacity for new share identifiers. If this parameter isn't provided for a fair-share job queue, no vCPU capacity is reserved.
    ///   - updatePolicy: Specifies the updated infrastructure update policy for the compute environment. For more information about infrastructure updates, see Updating compute environments in the Batch User Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateComputeEnvironment(
        computeEnvironment: String? = nil,
        computeResources: ComputeResourceUpdate? = nil,
        context: String? = nil,
        serviceRole: String? = nil,
        state: CEState? = nil,
        unmanagedvCpus: Int? = nil,
        updatePolicy: UpdatePolicy? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UpdateComputeEnvironmentResponse {
        let input = UpdateComputeEnvironmentRequest(
            computeEnvironment: computeEnvironment, 
            computeResources: computeResources, 
            context: context, 
            serviceRole: serviceRole, 
            state: state, 
            unmanagedvCpus: unmanagedvCpus, 
            updatePolicy: updatePolicy
        )
        return try await self.updateComputeEnvironment(input, logger: logger)
    }

    /// Updates a consumable resource.
    @Sendable
    @inlinable
    public func updateConsumableResource(_ input: UpdateConsumableResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UpdateConsumableResourceResponse {
        try await self.client.execute(
            operation: "UpdateConsumableResource", 
            path: "/v1/updateconsumableresource", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Updates a consumable resource.
    ///
    /// Parameters:
    ///   - clientToken: If this parameter is specified and two update requests with identical payloads and  clientTokens are received, these requests are considered the same request and  the second request is rejected. A clientToken is valid for 8 hours or until one hour after the consumable resource is deleted, whichever is less.
    ///   - consumableResource: The name or ARN of the consumable resource to be updated.
    ///   - operation: Indicates how the quantity of the consumable resource will be updated. Must be one of:    SET  Sets the quantity of the resource to the value specified by the quantity parameter.    ADD  Increases the quantity of the resource by the value specified by the quantity parameter.    REMOVE  Reduces the quantity of the resource by the value specified by the quantity parameter.
    ///   - quantity: The change in the total quantity of the consumable resource. The operation parameter determines whether the value specified here will be the new total quantity, or the amount by which the total quantity will be increased or reduced. Must be a non-negative  value.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateConsumableResource(
        clientToken: String? = UpdateConsumableResourceRequest.idempotencyToken(),
        consumableResource: String? = nil,
        operation: String? = nil,
        quantity: Int64? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UpdateConsumableResourceResponse {
        let input = UpdateConsumableResourceRequest(
            clientToken: clientToken, 
            consumableResource: consumableResource, 
            operation: operation, 
            quantity: quantity
        )
        return try await self.updateConsumableResource(input, logger: logger)
    }

    /// Updates a job queue.
    @Sendable
    @inlinable
    public func updateJobQueue(_ input: UpdateJobQueueRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UpdateJobQueueResponse {
        try await self.client.execute(
            operation: "UpdateJobQueue", 
            path: "/v1/updatejobqueue", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Updates a job queue.
    ///
    /// Parameters:
    ///   - computeEnvironmentOrder: Details the set of compute environments mapped to a job queue and their order relative to each other. This is one of the parameters used by the job scheduler to determine which compute environment runs a given job. Compute environments must be in the VALID state before you can associate them with a job queue. All of the compute environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT). EC2 and Fargate compute environments can't be mixed.  All compute environments that are associated with a job queue must share the same architecture. Batch doesn't support mixing compute environment architecture types in a single job queue.
    ///   - jobQueue: The name or the Amazon Resource Name (ARN) of the job queue.
    ///   - jobStateTimeLimitActions: The set of actions that Batch perform on jobs that remain at the head of the job queue in the specified state longer than specified times. Batch will perform each action after maxTimeSeconds has passed. (Note: The minimum value for maxTimeSeconds is 600 (10 minutes) and its maximum value is 86,400 (24 hours).)
    ///   - priority: The priority of the job queue. Job queues with a higher priority (or a higher integer value for the priority parameter) are evaluated first when associated with the same compute environment. Priority is determined in descending order. For example, a job queue with a priority value of 10 is given scheduling preference over a job queue with a priority value of 1. All of the compute environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT). EC2 and Fargate compute environments can't be mixed.
    ///   - schedulingPolicyArn: Amazon Resource Name (ARN) of the fair-share scheduling policy. Once a job queue is created, the fair-share scheduling policy can be replaced but not removed. The format is aws:Partition:batch:Region:Account:scheduling-policy/Name . For example, aws:aws:batch:us-west-2:123456789012:scheduling-policy/MySchedulingPolicy.
    ///   - state: Describes the queue's ability to accept new jobs. If the job queue state is ENABLED, it can accept jobs. If the job queue state is DISABLED, new jobs can't be added to the queue, but jobs already in the queue can finish.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateJobQueue(
        computeEnvironmentOrder: [ComputeEnvironmentOrder]? = nil,
        jobQueue: String? = nil,
        jobStateTimeLimitActions: [JobStateTimeLimitAction]? = nil,
        priority: Int? = nil,
        schedulingPolicyArn: String? = nil,
        state: JQState? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UpdateJobQueueResponse {
        let input = UpdateJobQueueRequest(
            computeEnvironmentOrder: computeEnvironmentOrder, 
            jobQueue: jobQueue, 
            jobStateTimeLimitActions: jobStateTimeLimitActions, 
            priority: priority, 
            schedulingPolicyArn: schedulingPolicyArn, 
            state: state
        )
        return try await self.updateJobQueue(input, logger: logger)
    }

    /// Updates a scheduling policy.
    @Sendable
    @inlinable
    public func updateSchedulingPolicy(_ input: UpdateSchedulingPolicyRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UpdateSchedulingPolicyResponse {
        try await self.client.execute(
            operation: "UpdateSchedulingPolicy", 
            path: "/v1/updateschedulingpolicy", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Updates a scheduling policy.
    ///
    /// Parameters:
    ///   - arn: The Amazon Resource Name (ARN) of the scheduling policy to update.
    ///   - fairsharePolicy: The fair-share policy scheduling details.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateSchedulingPolicy(
        arn: String? = nil,
        fairsharePolicy: FairsharePolicy? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UpdateSchedulingPolicyResponse {
        let input = UpdateSchedulingPolicyRequest(
            arn: arn, 
            fairsharePolicy: fairsharePolicy
        )
        return try await self.updateSchedulingPolicy(input, logger: logger)
    }
}

extension Batch {
    /// Initializer required by `AWSService.with(middlewares:timeout:byteBufferAllocator:options)`. You are not able to use this initializer directly as there are not public
    /// initializers for `AWSServiceConfig.Patch`. Please use `AWSService.with(middlewares:timeout:byteBufferAllocator:options)` instead.
    public init(from: Batch, patch: AWSServiceConfig.Patch) {
        self.client = from.client
        self.config = from.config.with(patch: patch)
    }
}

// MARK: Paginators

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension Batch {
    /// Return PaginatorSequence for operation ``describeComputeEnvironments(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeComputeEnvironmentsPaginator(
        _ input: DescribeComputeEnvironmentsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeComputeEnvironmentsRequest, DescribeComputeEnvironmentsResponse> {
        return .init(
            input: input,
            command: self.describeComputeEnvironments,
            inputKey: \DescribeComputeEnvironmentsRequest.nextToken,
            outputKey: \DescribeComputeEnvironmentsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeComputeEnvironments(_:logger:)``.
    ///
    /// - Parameters:
    ///   - computeEnvironments: A list of up to 100 compute environment names or full Amazon Resource Name (ARN) entries.
    ///   - maxResults: The maximum number of cluster results returned by DescribeComputeEnvironments in paginated output. When this parameter is used, DescribeComputeEnvironments only returns maxResults results in a single page along with a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeComputeEnvironments request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeComputeEnvironments returns up to 100 results and a nextToken value if applicable.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeComputeEnvironmentsPaginator(
        computeEnvironments: [String]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeComputeEnvironmentsRequest, DescribeComputeEnvironmentsResponse> {
        let input = DescribeComputeEnvironmentsRequest(
            computeEnvironments: computeEnvironments, 
            maxResults: maxResults
        )
        return self.describeComputeEnvironmentsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeJobDefinitions(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeJobDefinitionsPaginator(
        _ input: DescribeJobDefinitionsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeJobDefinitionsRequest, DescribeJobDefinitionsResponse> {
        return .init(
            input: input,
            command: self.describeJobDefinitions,
            inputKey: \DescribeJobDefinitionsRequest.nextToken,
            outputKey: \DescribeJobDefinitionsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeJobDefinitions(_:logger:)``.
    ///
    /// - Parameters:
    ///   - jobDefinitionName: The name of the job definition to describe.
    ///   - jobDefinitions: A list of up to 100 job definitions. Each entry in the list can either be an ARN in the format arn:aws:batch:${Region}:${Account}:job-definition/${JobDefinitionName}:${Revision} or a short version using the form ${JobDefinitionName}:${Revision}. This parameter can't be used with other parameters.
    ///   - maxResults: The maximum number of results returned by DescribeJobDefinitions in paginated output. When this parameter is used, DescribeJobDefinitions only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeJobDefinitions request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeJobDefinitions returns up to 100 results and a nextToken value if applicable.
    ///   - status: The status used to filter job definitions.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeJobDefinitionsPaginator(
        jobDefinitionName: String? = nil,
        jobDefinitions: [String]? = nil,
        maxResults: Int? = nil,
        status: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeJobDefinitionsRequest, DescribeJobDefinitionsResponse> {
        let input = DescribeJobDefinitionsRequest(
            jobDefinitionName: jobDefinitionName, 
            jobDefinitions: jobDefinitions, 
            maxResults: maxResults, 
            status: status
        )
        return self.describeJobDefinitionsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeJobQueues(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeJobQueuesPaginator(
        _ input: DescribeJobQueuesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeJobQueuesRequest, DescribeJobQueuesResponse> {
        return .init(
            input: input,
            command: self.describeJobQueues,
            inputKey: \DescribeJobQueuesRequest.nextToken,
            outputKey: \DescribeJobQueuesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeJobQueues(_:logger:)``.
    ///
    /// - Parameters:
    ///   - jobQueues: A list of up to 100 queue names or full queue Amazon Resource Name (ARN) entries.
    ///   - maxResults: The maximum number of results returned by DescribeJobQueues in paginated output. When this parameter is used, DescribeJobQueues only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeJobQueues request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then DescribeJobQueues returns up to 100 results and a nextToken value if applicable.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeJobQueuesPaginator(
        jobQueues: [String]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeJobQueuesRequest, DescribeJobQueuesResponse> {
        let input = DescribeJobQueuesRequest(
            jobQueues: jobQueues, 
            maxResults: maxResults
        )
        return self.describeJobQueuesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listConsumableResources(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listConsumableResourcesPaginator(
        _ input: ListConsumableResourcesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListConsumableResourcesRequest, ListConsumableResourcesResponse> {
        return .init(
            input: input,
            command: self.listConsumableResources,
            inputKey: \ListConsumableResourcesRequest.nextToken,
            outputKey: \ListConsumableResourcesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listConsumableResources(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: The filters to apply to the consumable resource list query. If used, only those consumable  resources that match the filter are listed. Filter names and values can be:   name: CONSUMABLE_RESOURCE_NAME   values: case-insensitive matches for the consumable resource name. If a filter  value ends with an asterisk (*), it matches any consumable resource name that begins  with the string before the '*'.
    ///   - maxResults: The maximum number of results returned by ListConsumableResources in paginated output. When this parameter is used, ListConsumableResources only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another ListConsumableResources request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then ListConsumableResources returns up to 100 results and a nextToken value if applicable.
    ///   - logger: Logger used for logging
    @inlinable
    public func listConsumableResourcesPaginator(
        filters: [KeyValuesPair]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListConsumableResourcesRequest, ListConsumableResourcesResponse> {
        let input = ListConsumableResourcesRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listConsumableResourcesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listJobsPaginator(
        _ input: ListJobsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListJobsRequest, ListJobsResponse> {
        return .init(
            input: input,
            command: self.listJobs,
            inputKey: \ListJobsRequest.nextToken,
            outputKey: \ListJobsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - arrayJobId: The job ID for an array job. Specifying an array job ID with this parameter lists all child jobs from within the specified array.
    ///   - filters: The filter to apply to the query. Only one filter can be used at a time. When the filter is used, jobStatus is ignored. The filter doesn't apply to child jobs in an array or multi-node parallel (MNP) jobs. The results are sorted by the createdAt field, with the most recent jobs being first.  JOB_NAME  The value of the filter is a case-insensitive match for the job name. If the value ends with an asterisk (*), the filter matches any job name that begins with the string before the '*'. This corresponds to the jobName value. For example, test1 matches both Test1 and test1, and test1* matches both test1 and Test10. When the JOB_NAME filter is used, the results are grouped by the job name and version.  JOB_DEFINITION  The value for the filter is the name or Amazon Resource Name (ARN) of the job definition. This corresponds to the jobDefinition value. The value is case sensitive. When the value for the filter is the job definition name, the results include all the jobs that used any revision of that job definition name. If the value ends with an asterisk (*), the filter matches any job definition name that begins with the string before the '*'. For example, jd1 matches only jd1, and jd1* matches both jd1 and jd1A. The version of the job definition that's used doesn't affect the sort order. When the JOB_DEFINITION filter is used and the ARN is used (which is in the form arn:${Partition}:batch:${Region}:${Account}:job-definition/${JobDefinitionName}:${Revision}), the results include jobs that used the specified revision of the job definition. Asterisk (*) isn't supported when the ARN is used.  BEFORE_CREATED_AT  The value for the filter is the time that's before the job was created. This corresponds to the createdAt value. The value is a string representation of the number of milliseconds since 00:00:00 UTC (midnight) on January 1, 1970.  AFTER_CREATED_AT  The value for the filter is the time that's after the job was created. This corresponds to the createdAt value. The value is a string representation of the number of milliseconds since 00:00:00 UTC (midnight) on January 1, 1970.
    ///   - jobQueue: The name or full Amazon Resource Name (ARN) of the job queue used to list jobs.
    ///   - jobStatus: The job status used to filter jobs in the specified queue. If the filters parameter is specified, the jobStatus parameter is ignored and jobs with any status are returned. If you don't specify a status, only RUNNING jobs are returned.
    ///   - maxResults: The maximum number of results returned by ListJobs in a paginated output. When this parameter is used, ListJobs returns up to maxResults results in a single page and a nextToken response element, if applicable. The remaining results of the initial request can be seen by sending another ListJobs request with the returned nextToken value. The following outlines key parameters and limitations:   The minimum value is 1.    When --job-status is used, Batch returns up to 1000 values.    When --filters is used, Batch returns up to 100 values.   If neither parameter is used, then ListJobs returns up to 1000 results (jobs that are in the RUNNING status) and a nextToken value, if applicable.
    ///   - multiNodeJobId: The job ID for a multi-node parallel job. Specifying a multi-node parallel job ID with this parameter lists all nodes that are associated with the specified job.
    ///   - logger: Logger used for logging
    @inlinable
    public func listJobsPaginator(
        arrayJobId: String? = nil,
        filters: [KeyValuesPair]? = nil,
        jobQueue: String? = nil,
        jobStatus: JobStatus? = nil,
        maxResults: Int? = nil,
        multiNodeJobId: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListJobsRequest, ListJobsResponse> {
        let input = ListJobsRequest(
            arrayJobId: arrayJobId, 
            filters: filters, 
            jobQueue: jobQueue, 
            jobStatus: jobStatus, 
            maxResults: maxResults, 
            multiNodeJobId: multiNodeJobId
        )
        return self.listJobsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listJobsByConsumableResource(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listJobsByConsumableResourcePaginator(
        _ input: ListJobsByConsumableResourceRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListJobsByConsumableResourceRequest, ListJobsByConsumableResourceResponse> {
        return .init(
            input: input,
            command: self.listJobsByConsumableResource,
            inputKey: \ListJobsByConsumableResourceRequest.nextToken,
            outputKey: \ListJobsByConsumableResourceResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listJobsByConsumableResource(_:logger:)``.
    ///
    /// - Parameters:
    ///   - consumableResource: The name or ARN of the consumable resource.
    ///   - filters: The filters to apply to the job list query. If used, only those jobs requiring the specified  consumable resource (consumableResource) and that match the value of the filters are listed. The filter names and values can be:   name: JOB_STATUS  values: SUBMITTED | PENDING | RUNNABLE | STARTING | RUNNING | SUCCEEDED | FAILED    name: JOB_NAME   The values are case-insensitive matches for the job name. If a filter value ends  with an asterisk (*), it matches any job name that begins with the string before  the '*'.
    ///   - maxResults: The maximum number of results returned by ListJobsByConsumableResource in paginated output. When this parameter is used, ListJobsByConsumableResource only returns maxResults results in a single page and a nextToken response element. The remaining results of the initial request can be seen by sending another ListJobsByConsumableResource request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, then ListJobsByConsumableResource returns up to 100 results  and a nextToken value if applicable.
    ///   - logger: Logger used for logging
    @inlinable
    public func listJobsByConsumableResourcePaginator(
        consumableResource: String? = nil,
        filters: [KeyValuesPair]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListJobsByConsumableResourceRequest, ListJobsByConsumableResourceResponse> {
        let input = ListJobsByConsumableResourceRequest(
            consumableResource: consumableResource, 
            filters: filters, 
            maxResults: maxResults
        )
        return self.listJobsByConsumableResourcePaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listSchedulingPolicies(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listSchedulingPoliciesPaginator(
        _ input: ListSchedulingPoliciesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListSchedulingPoliciesRequest, ListSchedulingPoliciesResponse> {
        return .init(
            input: input,
            command: self.listSchedulingPolicies,
            inputKey: \ListSchedulingPoliciesRequest.nextToken,
            outputKey: \ListSchedulingPoliciesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listSchedulingPolicies(_:logger:)``.
    ///
    /// - Parameters:
    ///   - maxResults: The maximum number of results that's returned by ListSchedulingPolicies in paginated output. When this parameter is used, ListSchedulingPolicies only returns maxResults results in a single page and a nextToken response element. You can see the remaining results of the initial request by sending another ListSchedulingPolicies request with the returned nextToken value. This value can be between 1 and 100. If this parameter isn't used, ListSchedulingPolicies returns up to 100 results and a nextToken value if applicable.
    ///   - logger: Logger used for logging
    @inlinable
    public func listSchedulingPoliciesPaginator(
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListSchedulingPoliciesRequest, ListSchedulingPoliciesResponse> {
        let input = ListSchedulingPoliciesRequest(
            maxResults: maxResults
        )
        return self.listSchedulingPoliciesPaginator(input, logger: logger)
    }
}

extension Batch.DescribeComputeEnvironmentsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.DescribeComputeEnvironmentsRequest {
        return .init(
            computeEnvironments: self.computeEnvironments,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Batch.DescribeJobDefinitionsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.DescribeJobDefinitionsRequest {
        return .init(
            jobDefinitionName: self.jobDefinitionName,
            jobDefinitions: self.jobDefinitions,
            maxResults: self.maxResults,
            nextToken: token,
            status: self.status
        )
    }
}

extension Batch.DescribeJobQueuesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.DescribeJobQueuesRequest {
        return .init(
            jobQueues: self.jobQueues,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Batch.ListConsumableResourcesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.ListConsumableResourcesRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Batch.ListJobsByConsumableResourceRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.ListJobsByConsumableResourceRequest {
        return .init(
            consumableResource: self.consumableResource,
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Batch.ListJobsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.ListJobsRequest {
        return .init(
            arrayJobId: self.arrayJobId,
            filters: self.filters,
            jobQueue: self.jobQueue,
            jobStatus: self.jobStatus,
            maxResults: self.maxResults,
            multiNodeJobId: self.multiNodeJobId,
            nextToken: token
        )
    }
}

extension Batch.ListSchedulingPoliciesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Batch.ListSchedulingPoliciesRequest {
        return .init(
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}
