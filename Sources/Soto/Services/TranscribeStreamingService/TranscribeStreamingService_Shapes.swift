//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2021 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto/tree/main/CodeGenerator. DO NOT EDIT.

import Foundation
import SotoCore

extension TranscribeStreamingService {
    // MARK: Enums

    public enum ContentIdentificationType: String, CustomStringConvertible, Codable {
        case pii = "PII"
        public var description: String { return self.rawValue }
    }

    public enum ContentRedactionType: String, CustomStringConvertible, Codable {
        case pii = "PII"
        public var description: String { return self.rawValue }
    }

    public enum ItemType: String, CustomStringConvertible, Codable {
        case pronunciation
        case punctuation
        public var description: String { return self.rawValue }
    }

    public enum LanguageCode: String, CustomStringConvertible, Codable {
        case deDe = "de-DE"
        case enAu = "en-AU"
        case enGb = "en-GB"
        case enUs = "en-US"
        case esUs = "es-US"
        case frCa = "fr-CA"
        case frFr = "fr-FR"
        case itIt = "it-IT"
        case jaJp = "ja-JP"
        case koKr = "ko-KR"
        case ptBr = "pt-BR"
        case zhCn = "zh-CN"
        public var description: String { return self.rawValue }
    }

    public enum MediaEncoding: String, CustomStringConvertible, Codable {
        case flac
        case oggOpus = "ogg-opus"
        case pcm
        public var description: String { return self.rawValue }
    }

    public enum MedicalContentIdentificationType: String, CustomStringConvertible, Codable {
        case phi = "PHI"
        public var description: String { return self.rawValue }
    }

    public enum PartialResultsStability: String, CustomStringConvertible, Codable {
        case high
        case low
        case medium
        public var description: String { return self.rawValue }
    }

    public enum Specialty: String, CustomStringConvertible, Codable {
        case cardiology = "CARDIOLOGY"
        case neurology = "NEUROLOGY"
        case oncology = "ONCOLOGY"
        case primarycare = "PRIMARYCARE"
        case radiology = "RADIOLOGY"
        case urology = "UROLOGY"
        public var description: String { return self.rawValue }
    }

    public enum `Type`: String, CustomStringConvertible, Codable {
        case conversation = "CONVERSATION"
        case dictation = "DICTATION"
        public var description: String { return self.rawValue }
    }

    public enum VocabularyFilterMethod: String, CustomStringConvertible, Codable {
        case mask
        case remove
        case tag
        public var description: String { return self.rawValue }
    }

    // MARK: Shapes

    public struct Alternative: AWSDecodableShape {
        /// Contains the entities identified as personally identifiable information (PII) in the transcription output.
        public let entities: [Entity]?
        /// One or more alternative interpretations of the input audio.
        public let items: [Item]?
        /// The text that was transcribed from the audio.
        public let transcript: String?

        public init(entities: [Entity]? = nil, items: [Item]? = nil, transcript: String? = nil) {
            self.entities = entities
            self.items = items
            self.transcript = transcript
        }

        private enum CodingKeys: String, CodingKey {
            case entities = "Entities"
            case items = "Items"
            case transcript = "Transcript"
        }
    }

    public struct AudioEvent: AWSEncodableShape {
        /// An audio blob that contains the next part of the audio that you want to transcribe. The maximum audio chunk size is 32 KB.
        public let audioChunk: Data?

        public init(audioChunk: Data? = nil) {
            self.audioChunk = audioChunk
        }

        private enum CodingKeys: String, CodingKey {
            case audioChunk = "AudioChunk"
        }
    }

    public struct AudioStream: AWSEncodableShape {
        /// A blob of audio from your application. You audio stream consists of one or more audio events. For information on audio encoding formats in Amazon Transcribe, see Speech input. For information on audio encoding formats in Amazon Transcribe Medical, see Speech input. For more information on stream encoding in Amazon Transcribe, see Event stream encoding. For information on stream encoding in Amazon Transcribe Medical, see Event stream encoding.
        public let audioEvent: AudioEvent?

        public init(audioEvent: AudioEvent? = nil) {
            self.audioEvent = audioEvent
        }

        private enum CodingKeys: String, CodingKey {
            case audioEvent = "AudioEvent"
        }
    }

    public struct BadRequestException: AWSDecodableShape {
        public let message: String?

        public init(message: String? = nil) {
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case message = "Message"
        }
    }

    public struct ConflictException: AWSDecodableShape {
        public let message: String?

        public init(message: String? = nil) {
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case message = "Message"
        }
    }

    public struct Entity: AWSDecodableShape {
        /// The category of of information identified in this entity; for example, PII.
        public let category: String?
        /// A value between zero and one that Amazon Transcribe assigns to PII identified in the source audio. Larger values indicate a higher confidence in PII identification.
        public let confidence: Double?
        /// The words in the transcription output that have been identified as a PII entity.
        public let content: String?
        /// The end time of speech that was identified as PII.
        public let endTime: Double?
        /// The start time of speech that was identified as PII.
        public let startTime: Double?
        /// The type of PII identified in this entity; for example, name or credit card number.
        public let type: String?

        public init(category: String? = nil, confidence: Double? = nil, content: String? = nil, endTime: Double? = nil, startTime: Double? = nil, type: String? = nil) {
            self.category = category
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.startTime = startTime
            self.type = type
        }

        private enum CodingKeys: String, CodingKey {
            case category = "Category"
            case confidence = "Confidence"
            case content = "Content"
            case endTime = "EndTime"
            case startTime = "StartTime"
            case type = "Type"
        }
    }

    public struct InternalFailureException: AWSDecodableShape {
        public let message: String?

        public init(message: String? = nil) {
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case message = "Message"
        }
    }

    public struct Item: AWSDecodableShape {
        /// A value between 0 and 1 for an item that is a confidence score that Amazon Transcribe assigns to each word or phrase that it transcribes.
        public let confidence: Double?
        /// The word or punctuation that was recognized in the input audio.
        public let content: String?
        /// The offset from the beginning of the audio stream to the end of the audio that resulted in the item.
        public let endTime: Double?
        /// If speaker identification is enabled, shows the speakers identified in the real-time stream.
        public let speaker: String?
        /// If partial result stabilization has been enabled, indicates whether the word or phrase in the item is stable. If Stable is true, the result is stable.
        public let stable: Bool?
        /// The offset from the beginning of the audio stream to the beginning of the audio that resulted in the item.
        public let startTime: Double?
        /// The type of the item. PRONUNCIATION indicates that the item is a word that was recognized in the input audio. PUNCTUATION indicates that the item was interpreted as a pause in the input audio.
        public let type: ItemType?
        /// Indicates whether a word in the item matches a word in the vocabulary filter you've chosen for your real-time stream. If true then a word in the item matches your vocabulary filter.
        public let vocabularyFilterMatch: Bool?

        public init(confidence: Double? = nil, content: String? = nil, endTime: Double? = nil, speaker: String? = nil, stable: Bool? = nil, startTime: Double? = nil, type: ItemType? = nil, vocabularyFilterMatch: Bool? = nil) {
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.speaker = speaker
            self.stable = stable
            self.startTime = startTime
            self.type = type
            self.vocabularyFilterMatch = vocabularyFilterMatch
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case content = "Content"
            case endTime = "EndTime"
            case speaker = "Speaker"
            case stable = "Stable"
            case startTime = "StartTime"
            case type = "Type"
            case vocabularyFilterMatch = "VocabularyFilterMatch"
        }
    }

    public struct LimitExceededException: AWSDecodableShape {
        public let message: String?

        public init(message: String? = nil) {
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case message = "Message"
        }
    }

    public struct MedicalAlternative: AWSDecodableShape {
        /// Contains the medical entities identified as personal health information in the transcription output.
        public let entities: [MedicalEntity]?
        /// A list of objects that contains words and punctuation marks that represents one or more interpretations of the input audio.
        public let items: [MedicalItem]?
        /// The text that was transcribed from the audio.
        public let transcript: String?

        public init(entities: [MedicalEntity]? = nil, items: [MedicalItem]? = nil, transcript: String? = nil) {
            self.entities = entities
            self.items = items
            self.transcript = transcript
        }

        private enum CodingKeys: String, CodingKey {
            case entities = "Entities"
            case items = "Items"
            case transcript = "Transcript"
        }
    }

    public struct MedicalEntity: AWSDecodableShape {
        /// The type of personal health information of the medical entity.
        public let category: String?
        /// A value between zero and one that Amazon Transcribe Medical assigned to the personal health information that it identified in the source audio. Larger values indicate that Amazon Transcribe Medical has higher confidence in the personal health information that it identified.
        public let confidence: Double?
        /// The word or words in the transcription output that have been identified as a medical entity.
        public let content: String?
        /// The end time of the speech that was identified as a medical entity.
        public let endTime: Double?
        /// The start time of the speech that was identified as a medical entity.
        public let startTime: Double?

        public init(category: String? = nil, confidence: Double? = nil, content: String? = nil, endTime: Double? = nil, startTime: Double? = nil) {
            self.category = category
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.startTime = startTime
        }

        private enum CodingKeys: String, CodingKey {
            case category = "Category"
            case confidence = "Confidence"
            case content = "Content"
            case endTime = "EndTime"
            case startTime = "StartTime"
        }
    }

    public struct MedicalItem: AWSDecodableShape {
        /// A value between 0 and 1 for an item that is a confidence score that Amazon Transcribe Medical assigns to each word that it transcribes.
        public let confidence: Double?
        /// The word or punctuation mark that was recognized in the input audio.
        public let content: String?
        /// The number of seconds into an audio stream that indicates the creation time of an item.
        public let endTime: Double?
        /// If speaker identification is enabled, shows the integer values that correspond to the different speakers identified in the stream. For example, if the value of Speaker in the stream is either a 0 or a 1, that indicates that Amazon Transcribe Medical has identified two speakers in the stream. The value of 0 corresponds to one speaker and the value of 1 corresponds to the other speaker.
        public let speaker: String?
        /// The number of seconds into an audio stream that indicates the creation time of an item.
        public let startTime: Double?
        /// The type of the item. PRONUNCIATION indicates that the item is a word that was recognized in the input audio. PUNCTUATION indicates that the item was interpreted as a pause in the input audio, such as a period to indicate the end of a sentence.
        public let type: ItemType?

        public init(confidence: Double? = nil, content: String? = nil, endTime: Double? = nil, speaker: String? = nil, startTime: Double? = nil, type: ItemType? = nil) {
            self.confidence = confidence
            self.content = content
            self.endTime = endTime
            self.speaker = speaker
            self.startTime = startTime
            self.type = type
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case content = "Content"
            case endTime = "EndTime"
            case speaker = "Speaker"
            case startTime = "StartTime"
            case type = "Type"
        }
    }

    public struct MedicalResult: AWSDecodableShape {
        /// A list of possible transcriptions of the audio. Each alternative typically contains one Item that contains the result of the transcription.
        public let alternatives: [MedicalAlternative]?
        /// When channel identification is enabled, Amazon Transcribe Medical transcribes the speech from each audio channel separately. You can use ChannelId to retrieve the transcription results for a single channel in your audio stream.
        public let channelId: String?
        /// The time, in seconds, from the beginning of the audio stream to the end of the result.
        public let endTime: Double?
        /// Amazon Transcribe Medical divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments. The IsPartial field is true to indicate that Amazon Transcribe Medical has additional transcription data to send. The IsPartial field is false to indicate that this is the last transcription result for the segment.
        public let isPartial: Bool?
        /// A unique identifier for the result.
        public let resultId: String?
        /// The time, in seconds, from the beginning of the audio stream to the beginning of the result.
        public let startTime: Double?

        public init(alternatives: [MedicalAlternative]? = nil, channelId: String? = nil, endTime: Double? = nil, isPartial: Bool? = nil, resultId: String? = nil, startTime: Double? = nil) {
            self.alternatives = alternatives
            self.channelId = channelId
            self.endTime = endTime
            self.isPartial = isPartial
            self.resultId = resultId
            self.startTime = startTime
        }

        private enum CodingKeys: String, CodingKey {
            case alternatives = "Alternatives"
            case channelId = "ChannelId"
            case endTime = "EndTime"
            case isPartial = "IsPartial"
            case resultId = "ResultId"
            case startTime = "StartTime"
        }
    }

    public struct MedicalTranscript: AWSDecodableShape {
        ///  MedicalResult objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.
        public let results: [MedicalResult]?

        public init(results: [MedicalResult]? = nil) {
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case results = "Results"
        }
    }

    public struct MedicalTranscriptEvent: AWSDecodableShape {
        /// The transcription of the audio stream. The transcription is composed of all of the items in the results list.
        public let transcript: MedicalTranscript?

        public init(transcript: MedicalTranscript? = nil) {
            self.transcript = transcript
        }

        private enum CodingKeys: String, CodingKey {
            case transcript = "Transcript"
        }
    }

    public struct MedicalTranscriptResultStream: AWSDecodableShape {
        public let badRequestException: BadRequestException?
        public let conflictException: ConflictException?
        public let internalFailureException: InternalFailureException?
        public let limitExceededException: LimitExceededException?
        public let serviceUnavailableException: ServiceUnavailableException?
        /// A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe Medical to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream.
        public let transcriptEvent: MedicalTranscriptEvent?

        public init(badRequestException: BadRequestException? = nil, conflictException: ConflictException? = nil, internalFailureException: InternalFailureException? = nil, limitExceededException: LimitExceededException? = nil, serviceUnavailableException: ServiceUnavailableException? = nil, transcriptEvent: MedicalTranscriptEvent? = nil) {
            self.badRequestException = badRequestException
            self.conflictException = conflictException
            self.internalFailureException = internalFailureException
            self.limitExceededException = limitExceededException
            self.serviceUnavailableException = serviceUnavailableException
            self.transcriptEvent = transcriptEvent
        }

        private enum CodingKeys: String, CodingKey {
            case badRequestException = "BadRequestException"
            case conflictException = "ConflictException"
            case internalFailureException = "InternalFailureException"
            case limitExceededException = "LimitExceededException"
            case serviceUnavailableException = "ServiceUnavailableException"
            case transcriptEvent = "TranscriptEvent"
        }
    }

    public struct Result: AWSDecodableShape {
        /// A list of possible transcriptions for the audio. Each alternative typically contains one item that contains the result of the transcription.
        public let alternatives: [Alternative]?
        /// When channel identification is enabled, Amazon Transcribe transcribes the speech from each audio channel separately. You can use ChannelId to retrieve the transcription results for a single channel in your audio stream.
        public let channelId: String?
        /// The offset in seconds from the beginning of the audio stream to the end of the result.
        public let endTime: Double?
        /// Amazon Transcribe divides the incoming audio stream into segments at natural points in the audio. Transcription results are returned based on these segments.  The IsPartial field is true to indicate that Amazon Transcribe has additional transcription data to send, false to indicate that this is the last transcription result for the segment.
        public let isPartial: Bool?
        /// A unique identifier for the result.
        public let resultId: String?
        /// The offset in seconds from the beginning of the audio stream to the beginning of the result.
        public let startTime: Double?

        public init(alternatives: [Alternative]? = nil, channelId: String? = nil, endTime: Double? = nil, isPartial: Bool? = nil, resultId: String? = nil, startTime: Double? = nil) {
            self.alternatives = alternatives
            self.channelId = channelId
            self.endTime = endTime
            self.isPartial = isPartial
            self.resultId = resultId
            self.startTime = startTime
        }

        private enum CodingKeys: String, CodingKey {
            case alternatives = "Alternatives"
            case channelId = "ChannelId"
            case endTime = "EndTime"
            case isPartial = "IsPartial"
            case resultId = "ResultId"
            case startTime = "StartTime"
        }
    }

    public struct ServiceUnavailableException: AWSDecodableShape {
        public let message: String?

        public init(message: String? = nil) {
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case message = "Message"
        }
    }

    public struct StartMedicalStreamTranscriptionRequest: AWSEncodableShape & AWSShapeWithPayload {
        /// The key for the payload
        public static let _payloadPath: String = "audioStream"
        public static var _encoding = [
            AWSMemberEncoding(label: "audioStream", location: .body(locationName: "AudioStream")),
            AWSMemberEncoding(label: "contentIdentificationType", location: .header(locationName: "x-amzn-transcribe-content-identification-type")),
            AWSMemberEncoding(label: "enableChannelIdentification", location: .header(locationName: "x-amzn-transcribe-enable-channel-identification")),
            AWSMemberEncoding(label: "languageCode", location: .header(locationName: "x-amzn-transcribe-language-code")),
            AWSMemberEncoding(label: "mediaEncoding", location: .header(locationName: "x-amzn-transcribe-media-encoding")),
            AWSMemberEncoding(label: "mediaSampleRateHertz", location: .header(locationName: "x-amzn-transcribe-sample-rate")),
            AWSMemberEncoding(label: "numberOfChannels", location: .header(locationName: "x-amzn-transcribe-number-of-channels")),
            AWSMemberEncoding(label: "sessionId", location: .header(locationName: "x-amzn-transcribe-session-id")),
            AWSMemberEncoding(label: "showSpeakerLabel", location: .header(locationName: "x-amzn-transcribe-show-speaker-label")),
            AWSMemberEncoding(label: "specialty", location: .header(locationName: "x-amzn-transcribe-specialty")),
            AWSMemberEncoding(label: "type", location: .header(locationName: "x-amzn-transcribe-type")),
            AWSMemberEncoding(label: "vocabularyName", location: .header(locationName: "x-amzn-transcribe-vocabulary-name"))
        ]

        public let audioStream: AudioStream
        /// Set this field to PHI to identify personal health information in the transcription output.
        public let contentIdentificationType: MedicalContentIdentificationType?
        /// When true, instructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription. Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions. You can't set both ShowSpeakerLabel and EnableChannelIdentification in the same request. If you set both, your request returns a BadRequestException.
        public let enableChannelIdentification: Bool?
        ///  Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US English (en-US).
        public let languageCode: LanguageCode
        /// The encoding used for the input audio.
        public let mediaEncoding: MediaEncoding
        /// The sample rate of the input audio in Hertz.
        public let mediaSampleRateHertz: Int
        /// The number of channels that are in your audio stream.
        public let numberOfChannels: Int?
        ///  Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.
        public let sessionId: String?
        /// When true, enables speaker identification in your real-time stream.
        public let showSpeakerLabel: Bool?
        /// The medical specialty of the clinician or provider.
        public let specialty: Specialty
        /// The type of input audio. Choose DICTATION for a provider dictating patient notes. Choose CONVERSATION for a dialogue between a patient and one or more medical professionanls.
        public let type: `Type`
        /// The name of the medical custom vocabulary to use when processing the real-time stream.
        public let vocabularyName: String?

        public init(audioStream: AudioStream, contentIdentificationType: MedicalContentIdentificationType? = nil, enableChannelIdentification: Bool? = nil, languageCode: LanguageCode, mediaEncoding: MediaEncoding, mediaSampleRateHertz: Int, numberOfChannels: Int? = nil, sessionId: String? = nil, showSpeakerLabel: Bool? = nil, specialty: Specialty, type: `Type`, vocabularyName: String? = nil) {
            self.audioStream = audioStream
            self.contentIdentificationType = contentIdentificationType
            self.enableChannelIdentification = enableChannelIdentification
            self.languageCode = languageCode
            self.mediaEncoding = mediaEncoding
            self.mediaSampleRateHertz = mediaSampleRateHertz
            self.numberOfChannels = numberOfChannels
            self.sessionId = sessionId
            self.showSpeakerLabel = showSpeakerLabel
            self.specialty = specialty
            self.type = type
            self.vocabularyName = vocabularyName
        }

        public func validate(name: String) throws {
            try self.validate(self.mediaSampleRateHertz, name: "mediaSampleRateHertz", parent: name, max: 48000)
            try self.validate(self.mediaSampleRateHertz, name: "mediaSampleRateHertz", parent: name, min: 8000)
            try self.validate(self.numberOfChannels, name: "numberOfChannels", parent: name, min: 2)
            try self.validate(self.sessionId, name: "sessionId", parent: name, max: 36)
            try self.validate(self.sessionId, name: "sessionId", parent: name, min: 36)
            try self.validate(self.sessionId, name: "sessionId", parent: name, pattern: "[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}")
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, max: 200)
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, min: 1)
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, pattern: "^[0-9a-zA-Z._-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case audioStream = "AudioStream"
        }
    }

    public struct StartMedicalStreamTranscriptionResponse: AWSDecodableShape & AWSShapeWithPayload {
        /// The key for the payload
        public static let _payloadPath: String = "transcriptResultStream"
        public static var _encoding = [
            AWSMemberEncoding(label: "contentIdentificationType", location: .header(locationName: "x-amzn-transcribe-content-identification-type")),
            AWSMemberEncoding(label: "enableChannelIdentification", location: .header(locationName: "x-amzn-transcribe-enable-channel-identification")),
            AWSMemberEncoding(label: "languageCode", location: .header(locationName: "x-amzn-transcribe-language-code")),
            AWSMemberEncoding(label: "mediaEncoding", location: .header(locationName: "x-amzn-transcribe-media-encoding")),
            AWSMemberEncoding(label: "mediaSampleRateHertz", location: .header(locationName: "x-amzn-transcribe-sample-rate")),
            AWSMemberEncoding(label: "numberOfChannels", location: .header(locationName: "x-amzn-transcribe-number-of-channels")),
            AWSMemberEncoding(label: "requestId", location: .header(locationName: "x-amzn-request-id")),
            AWSMemberEncoding(label: "sessionId", location: .header(locationName: "x-amzn-transcribe-session-id")),
            AWSMemberEncoding(label: "showSpeakerLabel", location: .header(locationName: "x-amzn-transcribe-show-speaker-label")),
            AWSMemberEncoding(label: "specialty", location: .header(locationName: "x-amzn-transcribe-specialty")),
            AWSMemberEncoding(label: "transcriptResultStream", location: .body(locationName: "TranscriptResultStream")),
            AWSMemberEncoding(label: "type", location: .header(locationName: "x-amzn-transcribe-type")),
            AWSMemberEncoding(label: "vocabularyName", location: .header(locationName: "x-amzn-transcribe-vocabulary-name"))
        ]

        /// If the value is PHI, indicates that you've configured your stream to identify personal health information.
        public let contentIdentificationType: MedicalContentIdentificationType?
        /// Shows whether channel identification has been enabled in the stream.
        public let enableChannelIdentification: Bool?
        /// The language code for the response transcript. For Amazon Transcribe Medical, this is US English (en-US).
        public let languageCode: LanguageCode?
        /// The encoding used for the input audio stream.
        public let mediaEncoding: MediaEncoding?
        /// The sample rate of the input audio in Hertz.
        public let mediaSampleRateHertz: Int?
        /// The number of channels identified in the stream.
        public let numberOfChannels: Int?
        /// An identifier for the streaming transcription.
        public let requestId: String?
        /// Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.
        public let sessionId: String?
        /// Shows whether speaker identification was enabled in the stream.
        public let showSpeakerLabel: Bool?
        /// The specialty in the medical domain.
        public let specialty: Specialty?
        /// Represents the stream of transcription events from Amazon Transcribe Medical to your application.
        public let transcriptResultStream: MedicalTranscriptResultStream?
        /// The type of audio that was transcribed.
        public let type: `Type`?
        /// The name of the vocabulary used when processing the stream.
        public let vocabularyName: String?

        public init(contentIdentificationType: MedicalContentIdentificationType? = nil, enableChannelIdentification: Bool? = nil, languageCode: LanguageCode? = nil, mediaEncoding: MediaEncoding? = nil, mediaSampleRateHertz: Int? = nil, numberOfChannels: Int? = nil, requestId: String? = nil, sessionId: String? = nil, showSpeakerLabel: Bool? = nil, specialty: Specialty? = nil, transcriptResultStream: MedicalTranscriptResultStream? = nil, type: `Type`? = nil, vocabularyName: String? = nil) {
            self.contentIdentificationType = contentIdentificationType
            self.enableChannelIdentification = enableChannelIdentification
            self.languageCode = languageCode
            self.mediaEncoding = mediaEncoding
            self.mediaSampleRateHertz = mediaSampleRateHertz
            self.numberOfChannels = numberOfChannels
            self.requestId = requestId
            self.sessionId = sessionId
            self.showSpeakerLabel = showSpeakerLabel
            self.specialty = specialty
            self.transcriptResultStream = transcriptResultStream
            self.type = type
            self.vocabularyName = vocabularyName
        }

        private enum CodingKeys: String, CodingKey {
            case contentIdentificationType = "x-amzn-transcribe-content-identification-type"
            case enableChannelIdentification = "x-amzn-transcribe-enable-channel-identification"
            case languageCode = "x-amzn-transcribe-language-code"
            case mediaEncoding = "x-amzn-transcribe-media-encoding"
            case mediaSampleRateHertz = "x-amzn-transcribe-sample-rate"
            case numberOfChannels = "x-amzn-transcribe-number-of-channels"
            case requestId = "x-amzn-request-id"
            case sessionId = "x-amzn-transcribe-session-id"
            case showSpeakerLabel = "x-amzn-transcribe-show-speaker-label"
            case specialty = "x-amzn-transcribe-specialty"
            case transcriptResultStream = "TranscriptResultStream"
            case type = "x-amzn-transcribe-type"
            case vocabularyName = "x-amzn-transcribe-vocabulary-name"
        }
    }

    public struct StartStreamTranscriptionRequest: AWSEncodableShape & AWSShapeWithPayload {
        /// The key for the payload
        public static let _payloadPath: String = "audioStream"
        public static var _encoding = [
            AWSMemberEncoding(label: "audioStream", location: .body(locationName: "AudioStream")),
            AWSMemberEncoding(label: "contentIdentificationType", location: .header(locationName: "x-amzn-transcribe-content-identification-type")),
            AWSMemberEncoding(label: "contentRedactionType", location: .header(locationName: "x-amzn-transcribe-content-redaction-type")),
            AWSMemberEncoding(label: "enableChannelIdentification", location: .header(locationName: "x-amzn-transcribe-enable-channel-identification")),
            AWSMemberEncoding(label: "enablePartialResultsStabilization", location: .header(locationName: "x-amzn-transcribe-enable-partial-results-stabilization")),
            AWSMemberEncoding(label: "languageCode", location: .header(locationName: "x-amzn-transcribe-language-code")),
            AWSMemberEncoding(label: "mediaEncoding", location: .header(locationName: "x-amzn-transcribe-media-encoding")),
            AWSMemberEncoding(label: "mediaSampleRateHertz", location: .header(locationName: "x-amzn-transcribe-sample-rate")),
            AWSMemberEncoding(label: "numberOfChannels", location: .header(locationName: "x-amzn-transcribe-number-of-channels")),
            AWSMemberEncoding(label: "partialResultsStability", location: .header(locationName: "x-amzn-transcribe-partial-results-stability")),
            AWSMemberEncoding(label: "piiEntityTypes", location: .header(locationName: "x-amzn-transcribe-pii-entity-types")),
            AWSMemberEncoding(label: "sessionId", location: .header(locationName: "x-amzn-transcribe-session-id")),
            AWSMemberEncoding(label: "showSpeakerLabel", location: .header(locationName: "x-amzn-transcribe-show-speaker-label")),
            AWSMemberEncoding(label: "vocabularyFilterMethod", location: .header(locationName: "x-amzn-transcribe-vocabulary-filter-method")),
            AWSMemberEncoding(label: "vocabularyFilterName", location: .header(locationName: "x-amzn-transcribe-vocabulary-filter-name")),
            AWSMemberEncoding(label: "vocabularyName", location: .header(locationName: "x-amzn-transcribe-vocabulary-name"))
        ]

        /// PCM-encoded stream of audio blobs. The audio stream is encoded as an HTTP/2 data frame.
        public let audioStream: AudioStream
        /// Set this field to PII to identify personally identifiable information (PII) in the transcription output. Content identification is performed only upon complete transcription of the audio segments. You can’t set both ContentIdentificationType and ContentRedactionType in the same request. If you set both, your request returns a BadRequestException.
        public let contentIdentificationType: ContentIdentificationType?
        /// Set this field to PII to redact personally identifiable information (PII) in the transcription output. Content redaction is performed only upon complete transcription of the audio segments. You can’t set both ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a BadRequestException.
        public let contentRedactionType: ContentRedactionType?
        /// When true, instructs Amazon Transcribe to process each audio channel separately and then merge the transcription output of each channel into a single transcription. Amazon Transcribe also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions. You can't set both ShowSpeakerLabel and EnableChannelIdentification in the same request. If you set both, your request returns a BadRequestException.
        public let enableChannelIdentification: Bool?
        /// When true, instructs Amazon Transcribe to present transcription results that have the partial results stabilized. Normally, any word or phrase from one partial result can change in a subsequent partial result. With partial results stabilization enabled, only the last few words of one partial result can change in another partial result.
        public let enablePartialResultsStabilization: Bool?
        /// Indicates the source language used in the input audio stream.
        public let languageCode: LanguageCode
        /// The encoding used for the input audio.
        public let mediaEncoding: MediaEncoding
        /// The sample rate, in Hertz, of the input audio. We suggest that you use 8,000 Hz for low quality audio and 16,000 Hz for high quality audio.
        public let mediaSampleRateHertz: Int
        /// The number of channels that are in your audio stream.
        public let numberOfChannels: Int?
        /// You can use this field to set the stability level of the transcription results. A higher stability level means that the transcription results are less likely to change. Higher stability levels can come with lower overall transcription accuracy.
        public let partialResultsStability: PartialResultsStability?
        /// List the PII entity types you want to identify or redact. In order to specify entity types, you must have either ContentIdentificationType or ContentRedactionType enabled.  PIIEntityTypes must be comma-separated; the available values are: BANK_ACCOUNT_NUMBER, BANK_ROUTING, CREDIT_DEBIT_NUMBER, CREDIT_DEBIT_CVV, CREDIT_DEBIT_EXPIRY, PIN, EMAIL, ADDRESS, NAME, PHONE, SSN, and ALL.  PiiEntityTypes is an optional parameter with a default value of ALL.
        public let piiEntityTypes: String?
        /// A identifier for the transcription session. Use this parameter when you want to retry a session. If you don't provide a session ID, Amazon Transcribe will generate one for you and return it in the response.
        public let sessionId: String?
        /// When true, enables speaker identification in your real-time stream.
        public let showSpeakerLabel: Bool?
        /// The manner in which you use your vocabulary filter to filter words in your transcript. Remove removes filtered words from your transcription results. Mask masks filtered words with a *** in your transcription results. Tag keeps the filtered words in your transcription results and tags them. The tag appears as VocabularyFilterMatch equal to True
        public let vocabularyFilterMethod: VocabularyFilterMethod?
        /// The name of the vocabulary filter you've created that is unique to your account. Provide the name in this field to successfully use it in a stream.
        public let vocabularyFilterName: String?
        /// The name of the vocabulary to use when processing the transcription job.
        public let vocabularyName: String?

        public init(audioStream: AudioStream, contentIdentificationType: ContentIdentificationType? = nil, contentRedactionType: ContentRedactionType? = nil, enableChannelIdentification: Bool? = nil, enablePartialResultsStabilization: Bool? = nil, languageCode: LanguageCode, mediaEncoding: MediaEncoding, mediaSampleRateHertz: Int, numberOfChannels: Int? = nil, partialResultsStability: PartialResultsStability? = nil, piiEntityTypes: String? = nil, sessionId: String? = nil, showSpeakerLabel: Bool? = nil, vocabularyFilterMethod: VocabularyFilterMethod? = nil, vocabularyFilterName: String? = nil, vocabularyName: String? = nil) {
            self.audioStream = audioStream
            self.contentIdentificationType = contentIdentificationType
            self.contentRedactionType = contentRedactionType
            self.enableChannelIdentification = enableChannelIdentification
            self.enablePartialResultsStabilization = enablePartialResultsStabilization
            self.languageCode = languageCode
            self.mediaEncoding = mediaEncoding
            self.mediaSampleRateHertz = mediaSampleRateHertz
            self.numberOfChannels = numberOfChannels
            self.partialResultsStability = partialResultsStability
            self.piiEntityTypes = piiEntityTypes
            self.sessionId = sessionId
            self.showSpeakerLabel = showSpeakerLabel
            self.vocabularyFilterMethod = vocabularyFilterMethod
            self.vocabularyFilterName = vocabularyFilterName
            self.vocabularyName = vocabularyName
        }

        public func validate(name: String) throws {
            try self.validate(self.mediaSampleRateHertz, name: "mediaSampleRateHertz", parent: name, max: 48000)
            try self.validate(self.mediaSampleRateHertz, name: "mediaSampleRateHertz", parent: name, min: 8000)
            try self.validate(self.numberOfChannels, name: "numberOfChannels", parent: name, min: 2)
            try self.validate(self.piiEntityTypes, name: "piiEntityTypes", parent: name, max: 300)
            try self.validate(self.piiEntityTypes, name: "piiEntityTypes", parent: name, min: 1)
            try self.validate(self.piiEntityTypes, name: "piiEntityTypes", parent: name, pattern: "^[A-Z_, ]+")
            try self.validate(self.sessionId, name: "sessionId", parent: name, max: 36)
            try self.validate(self.sessionId, name: "sessionId", parent: name, min: 36)
            try self.validate(self.sessionId, name: "sessionId", parent: name, pattern: "[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}")
            try self.validate(self.vocabularyFilterName, name: "vocabularyFilterName", parent: name, max: 200)
            try self.validate(self.vocabularyFilterName, name: "vocabularyFilterName", parent: name, min: 1)
            try self.validate(self.vocabularyFilterName, name: "vocabularyFilterName", parent: name, pattern: "^[0-9a-zA-Z._-]+")
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, max: 200)
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, min: 1)
            try self.validate(self.vocabularyName, name: "vocabularyName", parent: name, pattern: "^[0-9a-zA-Z._-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case audioStream = "AudioStream"
        }
    }

    public struct StartStreamTranscriptionResponse: AWSDecodableShape & AWSShapeWithPayload {
        /// The key for the payload
        public static let _payloadPath: String = "transcriptResultStream"
        public static var _encoding = [
            AWSMemberEncoding(label: "contentIdentificationType", location: .header(locationName: "x-amzn-transcribe-content-identification-type")),
            AWSMemberEncoding(label: "contentRedactionType", location: .header(locationName: "x-amzn-transcribe-content-redaction-type")),
            AWSMemberEncoding(label: "enableChannelIdentification", location: .header(locationName: "x-amzn-transcribe-enable-channel-identification")),
            AWSMemberEncoding(label: "enablePartialResultsStabilization", location: .header(locationName: "x-amzn-transcribe-enable-partial-results-stabilization")),
            AWSMemberEncoding(label: "languageCode", location: .header(locationName: "x-amzn-transcribe-language-code")),
            AWSMemberEncoding(label: "mediaEncoding", location: .header(locationName: "x-amzn-transcribe-media-encoding")),
            AWSMemberEncoding(label: "mediaSampleRateHertz", location: .header(locationName: "x-amzn-transcribe-sample-rate")),
            AWSMemberEncoding(label: "numberOfChannels", location: .header(locationName: "x-amzn-transcribe-number-of-channels")),
            AWSMemberEncoding(label: "partialResultsStability", location: .header(locationName: "x-amzn-transcribe-partial-results-stability")),
            AWSMemberEncoding(label: "piiEntityTypes", location: .header(locationName: "x-amzn-transcribe-pii-entity-types")),
            AWSMemberEncoding(label: "requestId", location: .header(locationName: "x-amzn-request-id")),
            AWSMemberEncoding(label: "sessionId", location: .header(locationName: "x-amzn-transcribe-session-id")),
            AWSMemberEncoding(label: "showSpeakerLabel", location: .header(locationName: "x-amzn-transcribe-show-speaker-label")),
            AWSMemberEncoding(label: "transcriptResultStream", location: .body(locationName: "TranscriptResultStream")),
            AWSMemberEncoding(label: "vocabularyFilterMethod", location: .header(locationName: "x-amzn-transcribe-vocabulary-filter-method")),
            AWSMemberEncoding(label: "vocabularyFilterName", location: .header(locationName: "x-amzn-transcribe-vocabulary-filter-name")),
            AWSMemberEncoding(label: "vocabularyName", location: .header(locationName: "x-amzn-transcribe-vocabulary-name"))
        ]

        /// Shows whether content identification was enabled in this stream.
        public let contentIdentificationType: ContentIdentificationType?
        /// Shows whether content redaction was enabled in this stream.
        public let contentRedactionType: ContentRedactionType?
        /// Shows whether channel identification has been enabled in the stream.
        public let enableChannelIdentification: Bool?
        /// Shows whether partial results stabilization has been enabled in the stream.
        public let enablePartialResultsStabilization: Bool?
        /// The language code for the input audio stream.
        public let languageCode: LanguageCode?
        /// The encoding used for the input audio stream.
        public let mediaEncoding: MediaEncoding?
        /// The sample rate for the input audio stream. Use 8,000 Hz for low quality audio and 16,000 Hz for high quality audio.
        public let mediaSampleRateHertz: Int?
        /// The number of channels identified in the stream.
        public let numberOfChannels: Int?
        /// If partial results stabilization has been enabled in the stream, shows the stability level.
        public let partialResultsStability: PartialResultsStability?
        /// Lists the PII entity types you specified in your request.
        public let piiEntityTypes: String?
        /// An identifier for the streaming transcription.
        public let requestId: String?
        /// An identifier for a specific transcription session.
        public let sessionId: String?
        /// Shows whether speaker identification was enabled in the stream.
        public let showSpeakerLabel: Bool?
        /// Represents the stream of transcription events from Amazon Transcribe to your application.
        public let transcriptResultStream: TranscriptResultStream?
        /// The vocabulary filtering method used in the real-time stream.
        public let vocabularyFilterMethod: VocabularyFilterMethod?
        /// The name of the vocabulary filter used in your real-time stream.
        public let vocabularyFilterName: String?
        /// The name of the vocabulary used when processing the stream.
        public let vocabularyName: String?

        public init(contentIdentificationType: ContentIdentificationType? = nil, contentRedactionType: ContentRedactionType? = nil, enableChannelIdentification: Bool? = nil, enablePartialResultsStabilization: Bool? = nil, languageCode: LanguageCode? = nil, mediaEncoding: MediaEncoding? = nil, mediaSampleRateHertz: Int? = nil, numberOfChannels: Int? = nil, partialResultsStability: PartialResultsStability? = nil, piiEntityTypes: String? = nil, requestId: String? = nil, sessionId: String? = nil, showSpeakerLabel: Bool? = nil, transcriptResultStream: TranscriptResultStream? = nil, vocabularyFilterMethod: VocabularyFilterMethod? = nil, vocabularyFilterName: String? = nil, vocabularyName: String? = nil) {
            self.contentIdentificationType = contentIdentificationType
            self.contentRedactionType = contentRedactionType
            self.enableChannelIdentification = enableChannelIdentification
            self.enablePartialResultsStabilization = enablePartialResultsStabilization
            self.languageCode = languageCode
            self.mediaEncoding = mediaEncoding
            self.mediaSampleRateHertz = mediaSampleRateHertz
            self.numberOfChannels = numberOfChannels
            self.partialResultsStability = partialResultsStability
            self.piiEntityTypes = piiEntityTypes
            self.requestId = requestId
            self.sessionId = sessionId
            self.showSpeakerLabel = showSpeakerLabel
            self.transcriptResultStream = transcriptResultStream
            self.vocabularyFilterMethod = vocabularyFilterMethod
            self.vocabularyFilterName = vocabularyFilterName
            self.vocabularyName = vocabularyName
        }

        private enum CodingKeys: String, CodingKey {
            case contentIdentificationType = "x-amzn-transcribe-content-identification-type"
            case contentRedactionType = "x-amzn-transcribe-content-redaction-type"
            case enableChannelIdentification = "x-amzn-transcribe-enable-channel-identification"
            case enablePartialResultsStabilization = "x-amzn-transcribe-enable-partial-results-stabilization"
            case languageCode = "x-amzn-transcribe-language-code"
            case mediaEncoding = "x-amzn-transcribe-media-encoding"
            case mediaSampleRateHertz = "x-amzn-transcribe-sample-rate"
            case numberOfChannels = "x-amzn-transcribe-number-of-channels"
            case partialResultsStability = "x-amzn-transcribe-partial-results-stability"
            case piiEntityTypes = "x-amzn-transcribe-pii-entity-types"
            case requestId = "x-amzn-request-id"
            case sessionId = "x-amzn-transcribe-session-id"
            case showSpeakerLabel = "x-amzn-transcribe-show-speaker-label"
            case transcriptResultStream = "TranscriptResultStream"
            case vocabularyFilterMethod = "x-amzn-transcribe-vocabulary-filter-method"
            case vocabularyFilterName = "x-amzn-transcribe-vocabulary-filter-name"
            case vocabularyName = "x-amzn-transcribe-vocabulary-name"
        }
    }

    public struct Transcript: AWSDecodableShape {
        ///  Result objects that contain the results of transcribing a portion of the input audio stream. The array can be empty.
        public let results: [Result]?

        public init(results: [Result]? = nil) {
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case results = "Results"
        }
    }

    public struct TranscriptEvent: AWSDecodableShape {
        /// The transcription of the audio stream. The transcription is composed of all of the items in the results list.
        public let transcript: Transcript?

        public init(transcript: Transcript? = nil) {
            self.transcript = transcript
        }

        private enum CodingKeys: String, CodingKey {
            case transcript = "Transcript"
        }
    }

    public struct TranscriptResultStream: AWSDecodableShape {
        /// A client error occurred when the stream was created. Check the parameters of the request and try your request again.
        public let badRequestException: BadRequestException?
        /// A new stream started with the same session ID. The current stream has been terminated.
        public let conflictException: ConflictException?
        /// A problem occurred while processing the audio. Amazon Transcribe terminated processing.
        public let internalFailureException: InternalFailureException?
        /// Your client has exceeded one of the Amazon Transcribe limits, typically the limit on audio length. Break your audio stream into smaller chunks and try your request again.
        public let limitExceededException: LimitExceededException?
        /// Service is currently unavailable. Try your request later.
        public let serviceUnavailableException: ServiceUnavailableException?
        /// A portion of the transcription of the audio stream. Events are sent periodically from Amazon Transcribe to your application. The event can be a partial transcription of a section of the audio stream, or it can be the entire transcription of that portion of the audio stream.
        public let transcriptEvent: TranscriptEvent?

        public init(badRequestException: BadRequestException? = nil, conflictException: ConflictException? = nil, internalFailureException: InternalFailureException? = nil, limitExceededException: LimitExceededException? = nil, serviceUnavailableException: ServiceUnavailableException? = nil, transcriptEvent: TranscriptEvent? = nil) {
            self.badRequestException = badRequestException
            self.conflictException = conflictException
            self.internalFailureException = internalFailureException
            self.limitExceededException = limitExceededException
            self.serviceUnavailableException = serviceUnavailableException
            self.transcriptEvent = transcriptEvent
        }

        private enum CodingKeys: String, CodingKey {
            case badRequestException = "BadRequestException"
            case conflictException = "ConflictException"
            case internalFailureException = "InternalFailureException"
            case limitExceededException = "LimitExceededException"
            case serviceUnavailableException = "ServiceUnavailableException"
            case transcriptEvent = "TranscriptEvent"
        }
    }
}
