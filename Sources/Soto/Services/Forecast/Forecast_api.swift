//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2024 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

#if os(Linux) && compiler(<5.10)
// swift-corelibs-foundation hasn't been updated with Sendable conformances
@preconcurrency import Foundation
#else
import Foundation
#endif
@_exported import SotoCore

/// Service object for interacting with AWS Forecast service.
///
/// Provides APIs for creating and managing Amazon Forecast resources.
public struct Forecast: AWSService {
    // MARK: Member variables

    /// Client used for communication with AWS
    public let client: AWSClient
    /// Service configuration
    public let config: AWSServiceConfig

    // MARK: Initialization

    /// Initialize the Forecast client
    /// - parameters:
    ///     - client: AWSClient used to process requests
    ///     - region: Region of server you want to communicate with. This will override the partition parameter.
    ///     - partition: AWS partition where service resides, standard (.aws), china (.awscn), government (.awsusgov).
    ///     - endpoint: Custom endpoint URL to use instead of standard AWS servers
    ///     - middleware: Middleware chain used to edit requests before they are sent and responses before they are decoded 
    ///     - timeout: Timeout value for HTTP requests
    ///     - byteBufferAllocator: Allocator for ByteBuffers
    ///     - options: Service options
    public init(
        client: AWSClient,
        region: SotoCore.Region? = nil,
        partition: AWSPartition = .aws,
        endpoint: String? = nil,
        middleware: AWSMiddlewareProtocol? = nil,
        timeout: TimeAmount? = nil,
        byteBufferAllocator: ByteBufferAllocator = ByteBufferAllocator(),
        options: AWSServiceConfig.Options = []
    ) {
        self.client = client
        self.config = AWSServiceConfig(
            region: region,
            partition: region?.partition ?? partition,
            amzTarget: "AmazonForecast",
            serviceName: "Forecast",
            serviceIdentifier: "forecast",
            serviceProtocol: .json(version: "1.1"),
            apiVersion: "2018-06-26",
            endpoint: endpoint,
            variantEndpoints: Self.variantEndpoints,
            errorType: ForecastErrorType.self,
            middleware: middleware,
            timeout: timeout,
            byteBufferAllocator: byteBufferAllocator,
            options: options
        )
    }




    /// FIPS and dualstack endpoints
    static var variantEndpoints: [EndpointVariantType: AWSServiceConfig.EndpointVariant] {[
        [.fips]: .init(endpoints: [
            "us-east-1": "forecast-fips.us-east-1.amazonaws.com",
            "us-east-2": "forecast-fips.us-east-2.amazonaws.com",
            "us-west-2": "forecast-fips.us-west-2.amazonaws.com"
        ])
    ]}

    // MARK: API Calls

    /// Creates an Amazon Forecast predictor. Amazon Forecast creates predictors with AutoPredictor, which involves applying the optimal combination of algorithms to each time series in your datasets. You can use CreateAutoPredictor to create new predictors or upgrade/retrain existing predictors.  Creating new predictors  The following parameters are required when creating a new predictor:    PredictorName - A unique name for the predictor.    DatasetGroupArn - The ARN of the dataset group used to train the predictor.    ForecastFrequency - The granularity of your forecasts (hourly, daily, weekly, etc).    ForecastHorizon - The number of time-steps that the model predicts. The forecast horizon is also called the prediction length.   When creating a new predictor, do not specify a value for ReferencePredictorArn.  Upgrading and retraining predictors  The following parameters are required when retraining or upgrading a predictor:    PredictorName - A unique name for the predictor.    ReferencePredictorArn - The ARN of the predictor to retrain or upgrade.   When upgrading or retraining a predictor, only specify values for the ReferencePredictorArn and PredictorName.
    @Sendable
    @inlinable
    public func createAutoPredictor(_ input: CreateAutoPredictorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateAutoPredictorResponse {
        try await self.client.execute(
            operation: "CreateAutoPredictor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Amazon Forecast predictor. Amazon Forecast creates predictors with AutoPredictor, which involves applying the optimal combination of algorithms to each time series in your datasets. You can use CreateAutoPredictor to create new predictors or upgrade/retrain existing predictors.  Creating new predictors  The following parameters are required when creating a new predictor:    PredictorName - A unique name for the predictor.    DatasetGroupArn - The ARN of the dataset group used to train the predictor.    ForecastFrequency - The granularity of your forecasts (hourly, daily, weekly, etc).    ForecastHorizon - The number of time-steps that the model predicts. The forecast horizon is also called the prediction length.   When creating a new predictor, do not specify a value for ReferencePredictorArn.  Upgrading and retraining predictors  The following parameters are required when retraining or upgrading a predictor:    PredictorName - A unique name for the predictor.    ReferencePredictorArn - The ARN of the predictor to retrain or upgrade.   When upgrading or retraining a predictor, only specify values for the ReferencePredictorArn and PredictorName.
    ///
    /// Parameters:
    ///   - dataConfig: The data configuration for your dataset group and any additional datasets.
    ///   - encryptionConfig: 
    ///   - explainPredictor: Create an Explainability resource for the predictor.
    ///   - forecastDimensions: An array of dimension (field) names that specify how to group the generated forecast. For example, if you are generating forecasts for item sales across all your stores, and your dataset contains a store_id field, you would specify store_id as a dimension to group sales forecasts for each store.
    ///   - forecastFrequency: The frequency of predictions in a forecast. Valid intervals are an integer followed by Y (Year), M (Month), W (Week), D (Day), H (Hour), and min (Minute). For example, "1D" indicates every day and "15min" indicates every 15 minutes. You cannot specify a value that would overlap with the next larger frequency. That means, for example, you cannot specify a frequency of 60 minutes, because that is equivalent to 1 hour. The valid values for each frequency are the following:   Minute - 1-59   Hour - 1-23   Day - 1-6   Week - 1-4   Month - 1-11   Year - 1   Thus, if you want every other week forecasts, specify "2W". Or, if you want quarterly forecasts, you specify "3M". The frequency must be greater than or equal to the TARGET_TIME_SERIES dataset frequency. When a RELATED_TIME_SERIES dataset is provided, the frequency must be equal to the RELATED_TIME_SERIES dataset frequency.
    ///   - forecastHorizon: The number of time-steps that the model predicts. The forecast horizon is also called the prediction length. The maximum forecast horizon is the lesser of 500 time-steps or 1/4 of the TARGET_TIME_SERIES dataset length. If you are retraining an existing AutoPredictor, then the maximum forecast horizon is the lesser of 500 time-steps or 1/3 of the TARGET_TIME_SERIES dataset length. If you are upgrading to an AutoPredictor or retraining an existing AutoPredictor, you cannot update the forecast horizon parameter. You can meet this requirement by providing longer time-series in the dataset.
    ///   - forecastTypes: The forecast types used to train a predictor. You can specify up to five forecast types. Forecast types can be quantiles from 0.01 to 0.99, by increments of 0.01 or higher. You can also specify the mean forecast with mean.
    ///   - monitorConfig: The configuration details for predictor monitoring. Provide a name for the monitor resource to enable predictor monitoring. Predictor monitoring allows you to see how your predictor's performance changes over time. For more information, see Predictor Monitoring.
    ///   - optimizationMetric: The accuracy metric used to optimize the predictor.
    ///   - predictorName: A unique name for the predictor
    ///   - referencePredictorArn: The ARN of the predictor to retrain or upgrade. This parameter is only used when retraining or upgrading a predictor. When creating a new predictor, do not specify a value for this parameter. When upgrading or retraining a predictor, only specify values for the ReferencePredictorArn and PredictorName. The value for PredictorName must be a unique predictor name.
    ///   - tags: Optional metadata to help you categorize and organize your predictors. Each tag consists of a key and an optional value, both of which you define. Tag keys and values are case sensitive. The following restrictions apply to tags:   For each resource, each tag key must be unique and each tag key must have one value.   Maximum number of tags per resource: 50.   Maximum key length: 128 Unicode characters in UTF-8.   Maximum value length: 256 Unicode characters in UTF-8.   Accepted characters: all letters and numbers, spaces representable in UTF-8, and + - = . _ : / @. If your tagging schema is used across other services and resources, the character restrictions of those services also apply.    Key prefixes cannot include any upper or lowercase combination of aws: or AWS:. Values can have this prefix. If a tag value has aws as its prefix but the key does not, Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit. You cannot edit or delete tag keys with this prefix.
    ///   - timeAlignmentBoundary: The time boundary Forecast uses to align and aggregate any data that doesn't align with your forecast frequency. Provide the unit of time and the time boundary as a key value pair.  For more information on specifying a time boundary, see Specifying a Time Boundary. If you don't provide a time boundary, Forecast uses a set of Default Time Boundaries.
    ///   - logger: Logger use during operation
    @inlinable
    public func createAutoPredictor(
        dataConfig: DataConfig? = nil,
        encryptionConfig: EncryptionConfig? = nil,
        explainPredictor: Bool? = nil,
        forecastDimensions: [String]? = nil,
        forecastFrequency: String? = nil,
        forecastHorizon: Int? = nil,
        forecastTypes: [String]? = nil,
        monitorConfig: MonitorConfig? = nil,
        optimizationMetric: OptimizationMetric? = nil,
        predictorName: String,
        referencePredictorArn: String? = nil,
        tags: [Tag]? = nil,
        timeAlignmentBoundary: TimeAlignmentBoundary? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateAutoPredictorResponse {
        let input = CreateAutoPredictorRequest(
            dataConfig: dataConfig, 
            encryptionConfig: encryptionConfig, 
            explainPredictor: explainPredictor, 
            forecastDimensions: forecastDimensions, 
            forecastFrequency: forecastFrequency, 
            forecastHorizon: forecastHorizon, 
            forecastTypes: forecastTypes, 
            monitorConfig: monitorConfig, 
            optimizationMetric: optimizationMetric, 
            predictorName: predictorName, 
            referencePredictorArn: referencePredictorArn, 
            tags: tags, 
            timeAlignmentBoundary: timeAlignmentBoundary
        )
        return try await self.createAutoPredictor(input, logger: logger)
    }

    /// Creates an Amazon Forecast dataset. The information about the dataset that you provide helps Forecast understand how to consume the data for model training. This includes the following:     DataFrequency - How frequently your historical time-series data is collected.     Domain and  DatasetType - Each dataset has an associated dataset domain and a type within the domain. Amazon Forecast provides a list of predefined domains and types within each domain. For each unique dataset domain and type within the domain, Amazon Forecast requires your data to include a minimum set of predefined fields.     Schema - A schema specifies the fields in the dataset, including the field name and data type.   After creating a dataset, you import your training data into it and add the dataset to a dataset group. You use the dataset group to create a predictor. For more information, see Importing datasets. To get a list of all your datasets, use the ListDatasets operation. For example Forecast datasets, see the Amazon Forecast Sample GitHub repository.  The Status of a dataset must be ACTIVE before you can import training data. Use the DescribeDataset operation to get the status.
    @Sendable
    @inlinable
    public func createDataset(_ input: CreateDatasetRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateDatasetResponse {
        try await self.client.execute(
            operation: "CreateDataset", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates an Amazon Forecast dataset. The information about the dataset that you provide helps Forecast understand how to consume the data for model training. This includes the following:     DataFrequency - How frequently your historical time-series data is collected.     Domain and  DatasetType - Each dataset has an associated dataset domain and a type within the domain. Amazon Forecast provides a list of predefined domains and types within each domain. For each unique dataset domain and type within the domain, Amazon Forecast requires your data to include a minimum set of predefined fields.     Schema - A schema specifies the fields in the dataset, including the field name and data type.   After creating a dataset, you import your training data into it and add the dataset to a dataset group. You use the dataset group to create a predictor. For more information, see Importing datasets. To get a list of all your datasets, use the ListDatasets operation. For example Forecast datasets, see the Amazon Forecast Sample GitHub repository.  The Status of a dataset must be ACTIVE before you can import training data. Use the DescribeDataset operation to get the status.
    ///
    /// Parameters:
    ///   - dataFrequency: The frequency of data collection. This parameter is required for RELATED_TIME_SERIES datasets. Valid intervals are an integer followed by Y (Year), M (Month), W (Week), D (Day), H (Hour), and min (Minute). For example, "1D" indicates every day and "15min" indicates every 15 minutes. You cannot specify a value that would overlap with the next larger frequency. That means, for example, you cannot specify a frequency of 60 minutes, because that is equivalent to 1 hour. The valid values for each frequency are the following:   Minute - 1-59   Hour - 1-23   Day - 1-6   Week - 1-4   Month - 1-11   Year - 1   Thus, if you want every other week forecasts, specify "2W". Or, if you want quarterly forecasts, you specify "3M".
    ///   - datasetName: A name for the dataset.
    ///   - datasetType: The dataset type. Valid values depend on the chosen Domain.
    ///   - domain: The domain associated with the dataset. When you add a dataset to a dataset group, this value and the value specified for the Domain parameter of the CreateDatasetGroup operation must match. The Domain and DatasetType that you choose determine the fields that must be present in the training data that you import to the dataset. For example, if you choose the RETAIL domain and TARGET_TIME_SERIES as the DatasetType, Amazon Forecast requires item_id, timestamp, and demand fields to be present in your data. For more information, see Importing datasets.
    ///   - encryptionConfig: An Key Management Service (KMS) key and the Identity and Access Management (IAM) role that Amazon Forecast can assume to access the key.
    ///   - schema: The schema for the dataset. The schema attributes and their order must match the fields in your data. The dataset Domain and DatasetType that you choose determine the minimum required fields in your training data. For information about the required fields for a specific dataset domain and type, see Dataset Domains and Dataset Types.
    ///   - tags: The optional metadata that you apply to the dataset to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - logger: Logger use during operation
    @inlinable
    public func createDataset(
        dataFrequency: String? = nil,
        datasetName: String,
        datasetType: DatasetType,
        domain: Domain,
        encryptionConfig: EncryptionConfig? = nil,
        schema: Schema,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateDatasetResponse {
        let input = CreateDatasetRequest(
            dataFrequency: dataFrequency, 
            datasetName: datasetName, 
            datasetType: datasetType, 
            domain: domain, 
            encryptionConfig: encryptionConfig, 
            schema: schema, 
            tags: tags
        )
        return try await self.createDataset(input, logger: logger)
    }

    /// Creates a dataset group, which holds a collection of related datasets. You can add datasets to the dataset group when you create the dataset group, or later by using the UpdateDatasetGroup operation. After creating a dataset group and adding datasets, you use the dataset group when you create a predictor. For more information, see Dataset groups. To get a list of all your datasets groups, use the ListDatasetGroups operation.  The Status of a dataset group must be ACTIVE before you can use the dataset group to create a predictor. To get the status, use the DescribeDatasetGroup operation.
    @Sendable
    @inlinable
    public func createDatasetGroup(_ input: CreateDatasetGroupRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateDatasetGroupResponse {
        try await self.client.execute(
            operation: "CreateDatasetGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates a dataset group, which holds a collection of related datasets. You can add datasets to the dataset group when you create the dataset group, or later by using the UpdateDatasetGroup operation. After creating a dataset group and adding datasets, you use the dataset group when you create a predictor. For more information, see Dataset groups. To get a list of all your datasets groups, use the ListDatasetGroups operation.  The Status of a dataset group must be ACTIVE before you can use the dataset group to create a predictor. To get the status, use the DescribeDatasetGroup operation.
    ///
    /// Parameters:
    ///   - datasetArns: An array of Amazon Resource Names (ARNs) of the datasets that you want to include in the dataset group.
    ///   - datasetGroupName: A name for the dataset group.
    ///   - domain: The domain associated with the dataset group. When you add a dataset to a dataset group, this value and the value specified for the Domain parameter of the CreateDataset operation must match. The Domain and DatasetType that you choose determine the fields that must be present in training data that you import to a dataset. For example, if you choose the RETAIL domain and TARGET_TIME_SERIES as the DatasetType, Amazon Forecast requires that item_id, timestamp, and demand fields are present in your data. For more information, see Dataset groups.
    ///   - tags: The optional metadata that you apply to the dataset group to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - logger: Logger use during operation
    @inlinable
    public func createDatasetGroup(
        datasetArns: [String]? = nil,
        datasetGroupName: String,
        domain: Domain,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateDatasetGroupResponse {
        let input = CreateDatasetGroupRequest(
            datasetArns: datasetArns, 
            datasetGroupName: datasetGroupName, 
            domain: domain, 
            tags: tags
        )
        return try await self.createDatasetGroup(input, logger: logger)
    }

    /// Imports your training data to an Amazon Forecast dataset. You provide the location of your training data in an Amazon Simple Storage Service (Amazon S3) bucket and the Amazon Resource Name (ARN) of the dataset that you want to import the data to. You must specify a DataSource object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the data, as Amazon Forecast makes a copy of your data and processes it in an internal Amazon Web Services system. For more information, see Set up permissions. The training data must be in CSV or Parquet format. The delimiter must be a comma (,). You can specify the path to a specific file, the S3 bucket, or to a folder in the S3 bucket. For the latter two cases, Amazon Forecast imports all files up to the limit of 10,000 files. Because dataset imports are not aggregated, your most recent dataset import is the one that is used when training a predictor or generating a forecast. Make sure that your most recent dataset import contains all of the data you want to model off of, and not just the new data collected since the previous import. To get a list of all your dataset import jobs, filtered by specified criteria, use the ListDatasetImportJobs operation.
    @Sendable
    @inlinable
    public func createDatasetImportJob(_ input: CreateDatasetImportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateDatasetImportJobResponse {
        try await self.client.execute(
            operation: "CreateDatasetImportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Imports your training data to an Amazon Forecast dataset. You provide the location of your training data in an Amazon Simple Storage Service (Amazon S3) bucket and the Amazon Resource Name (ARN) of the dataset that you want to import the data to. You must specify a DataSource object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the data, as Amazon Forecast makes a copy of your data and processes it in an internal Amazon Web Services system. For more information, see Set up permissions. The training data must be in CSV or Parquet format. The delimiter must be a comma (,). You can specify the path to a specific file, the S3 bucket, or to a folder in the S3 bucket. For the latter two cases, Amazon Forecast imports all files up to the limit of 10,000 files. Because dataset imports are not aggregated, your most recent dataset import is the one that is used when training a predictor or generating a forecast. Make sure that your most recent dataset import contains all of the data you want to model off of, and not just the new data collected since the previous import. To get a list of all your dataset import jobs, filtered by specified criteria, use the ListDatasetImportJobs operation.
    ///
    /// Parameters:
    ///   - datasetArn: The Amazon Resource Name (ARN) of the Amazon Forecast dataset that you want to import data to.
    ///   - datasetImportJobName: The name for the dataset import job. We recommend including the current timestamp in the name, for example, 20190721DatasetImport. This can help you avoid getting a ResourceAlreadyExistsException exception.
    ///   - dataSource: The location of the training data to import and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the data. The training data must be stored in an Amazon S3 bucket. If encryption is used, DataSource must include an Key Management Service (KMS) key and the IAM role must allow Amazon Forecast permission to access the key. The KMS key and IAM role must match those specified in the EncryptionConfig parameter of the CreateDataset operation.
    ///   - format: The format of the imported data, CSV or PARQUET. The default value is CSV.
    ///   - geolocationFormat: The format of the geolocation attribute. The geolocation attribute can be formatted in one of two ways:    LAT_LONG - the latitude and longitude in decimal format (Example: 47.61_-122.33).    CC_POSTALCODE (US Only) - the country code (US), followed by the 5-digit ZIP code (Example: US_98121).
    ///   - importMode: Specifies whether the dataset import job is a FULL or INCREMENTAL import. A FULL dataset import replaces all of the existing data with the newly imported data. An INCREMENTAL import appends the imported data to the existing data.
    ///   - tags: The optional metadata that you apply to the dataset import job to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - timestampFormat: The format of timestamps in the dataset. The format that you specify depends on the DataFrequency specified when the dataset was created. The following formats are supported   "yyyy-MM-dd" For the following data frequencies: Y, M, W, and D   "yyyy-MM-dd HH:mm:ss" For the following data frequencies: H, 30min, 15min, and 1min; and optionally, for: Y, M, W, and D   If the format isn't specified, Amazon Forecast expects the format to be "yyyy-MM-dd HH:mm:ss".
    ///   - timeZone: A single time zone for every item in your dataset. This option is ideal for datasets with all timestamps within a single time zone, or if all timestamps are normalized to a single time zone.  Refer to the Joda-Time API for a complete list of valid time zone names.
    ///   - useGeolocationForTimeZone: Automatically derive time zone information from the geolocation attribute. This option is ideal for datasets that contain timestamps in multiple time zones and those timestamps are expressed in local time.
    ///   - logger: Logger use during operation
    @inlinable
    public func createDatasetImportJob(
        datasetArn: String,
        datasetImportJobName: String,
        dataSource: DataSource,
        format: String? = nil,
        geolocationFormat: String? = nil,
        importMode: ImportMode? = nil,
        tags: [Tag]? = nil,
        timestampFormat: String? = nil,
        timeZone: String? = nil,
        useGeolocationForTimeZone: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateDatasetImportJobResponse {
        let input = CreateDatasetImportJobRequest(
            datasetArn: datasetArn, 
            datasetImportJobName: datasetImportJobName, 
            dataSource: dataSource, 
            format: format, 
            geolocationFormat: geolocationFormat, 
            importMode: importMode, 
            tags: tags, 
            timestampFormat: timestampFormat, 
            timeZone: timeZone, 
            useGeolocationForTimeZone: useGeolocationForTimeZone
        )
        return try await self.createDatasetImportJob(input, logger: logger)
    }

    ///  Explainability is only available for Forecasts and Predictors generated from an AutoPredictor (CreateAutoPredictor)  Creates an Amazon Forecast Explainability. Explainability helps you better understand how the attributes in your datasets impact forecast. Amazon Forecast uses a metric called Impact scores to quantify the relative impact of each attribute and determine whether they increase or decrease forecast values. To enable Forecast Explainability, your predictor must include at least one of the following: related time series, item metadata, or additional datasets like Holidays and the Weather Index. CreateExplainability accepts either a Predictor ARN or Forecast ARN. To receive aggregated Impact scores for all time series and time points in your datasets, provide a Predictor ARN. To receive Impact scores for specific time series and time points, provide a Forecast ARN.  CreateExplainability with a Predictor ARN   You can only have one Explainability resource per predictor. If you already enabled ExplainPredictor in CreateAutoPredictor, that predictor already has an Explainability resource.  The following parameters are required when providing a Predictor ARN:    ExplainabilityName - A unique name for the Explainability.    ResourceArn - The Arn of the predictor.    TimePointGranularity - Must be set to “ALL”.    TimeSeriesGranularity - Must be set to “ALL”.   Do not specify a value for the following parameters:    DataSource - Only valid when TimeSeriesGranularity is “SPECIFIC”.    Schema - Only valid when TimeSeriesGranularity is “SPECIFIC”.    StartDateTime - Only valid when TimePointGranularity is “SPECIFIC”.    EndDateTime - Only valid when TimePointGranularity is “SPECIFIC”.    CreateExplainability with a Forecast ARN   You can specify a maximum of 50 time series and 500 time points.  The following parameters are required when providing a Predictor ARN:    ExplainabilityName - A unique name for the Explainability.    ResourceArn - The Arn of the forecast.    TimePointGranularity - Either “ALL” or “SPECIFIC”.    TimeSeriesGranularity - Either “ALL” or “SPECIFIC”.   If you set TimeSeriesGranularity to “SPECIFIC”, you must also provide the following:    DataSource - The S3 location of the CSV file specifying your time series.    Schema - The Schema defines the attributes and attribute types listed in the Data Source.   If you set TimePointGranularity to “SPECIFIC”, you must also provide the following:    StartDateTime - The first timestamp in the range of time points.    EndDateTime - The last timestamp in the range of time points.
    @Sendable
    @inlinable
    public func createExplainability(_ input: CreateExplainabilityRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateExplainabilityResponse {
        try await self.client.execute(
            operation: "CreateExplainability", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  Explainability is only available for Forecasts and Predictors generated from an AutoPredictor (CreateAutoPredictor)  Creates an Amazon Forecast Explainability. Explainability helps you better understand how the attributes in your datasets impact forecast. Amazon Forecast uses a metric called Impact scores to quantify the relative impact of each attribute and determine whether they increase or decrease forecast values. To enable Forecast Explainability, your predictor must include at least one of the following: related time series, item metadata, or additional datasets like Holidays and the Weather Index. CreateExplainability accepts either a Predictor ARN or Forecast ARN. To receive aggregated Impact scores for all time series and time points in your datasets, provide a Predictor ARN. To receive Impact scores for specific time series and time points, provide a Forecast ARN.  CreateExplainability with a Predictor ARN   You can only have one Explainability resource per predictor. If you already enabled ExplainPredictor in CreateAutoPredictor, that predictor already has an Explainability resource.  The following parameters are required when providing a Predictor ARN:    ExplainabilityName - A unique name for the Explainability.    ResourceArn - The Arn of the predictor.    TimePointGranularity - Must be set to “ALL”.    TimeSeriesGranularity - Must be set to “ALL”.   Do not specify a value for the following parameters:    DataSource - Only valid when TimeSeriesGranularity is “SPECIFIC”.    Schema - Only valid when TimeSeriesGranularity is “SPECIFIC”.    StartDateTime - Only valid when TimePointGranularity is “SPECIFIC”.    EndDateTime - Only valid when TimePointGranularity is “SPECIFIC”.    CreateExplainability with a Forecast ARN   You can specify a maximum of 50 time series and 500 time points.  The following parameters are required when providing a Predictor ARN:    ExplainabilityName - A unique name for the Explainability.    ResourceArn - The Arn of the forecast.    TimePointGranularity - Either “ALL” or “SPECIFIC”.    TimeSeriesGranularity - Either “ALL” or “SPECIFIC”.   If you set TimeSeriesGranularity to “SPECIFIC”, you must also provide the following:    DataSource - The S3 location of the CSV file specifying your time series.    Schema - The Schema defines the attributes and attribute types listed in the Data Source.   If you set TimePointGranularity to “SPECIFIC”, you must also provide the following:    StartDateTime - The first timestamp in the range of time points.    EndDateTime - The last timestamp in the range of time points.
    ///
    /// Parameters:
    ///   - dataSource: 
    ///   - enableVisualization: Create an Explainability visualization that is viewable within the Amazon Web Services console.
    ///   - endDateTime: If TimePointGranularity is set to SPECIFIC, define the last time point for the Explainability. Use the following timestamp format: yyyy-MM-ddTHH:mm:ss (example: 2015-01-01T20:00:00)
    ///   - explainabilityConfig: The configuration settings that define the granularity of time series and time points for the Explainability.
    ///   - explainabilityName: A unique name for the Explainability.
    ///   - resourceArn: The Amazon Resource Name (ARN) of the Predictor or Forecast used to create the Explainability.
    ///   - schema: 
    ///   - startDateTime: If TimePointGranularity is set to SPECIFIC, define the first point for the Explainability. Use the following timestamp format: yyyy-MM-ddTHH:mm:ss (example: 2015-01-01T20:00:00)
    ///   - tags: Optional metadata to help you categorize and organize your resources. Each tag consists of a key and an optional value, both of which you define. Tag keys and values are case sensitive. The following restrictions apply to tags:   For each resource, each tag key must be unique and each tag key must have one value.   Maximum number of tags per resource: 50.   Maximum key length: 128 Unicode characters in UTF-8.   Maximum value length: 256 Unicode characters in UTF-8.   Accepted characters: all letters and numbers, spaces representable in UTF-8, and + - = . _ : / @. If your tagging schema is used across other services and resources, the character restrictions of those services also apply.    Key prefixes cannot include any upper or lowercase combination of aws: or AWS:. Values can have this prefix. If a tag value has aws as its prefix but the key does not, Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit. You cannot edit or delete tag keys with this prefix.
    ///   - logger: Logger use during operation
    @inlinable
    public func createExplainability(
        dataSource: DataSource? = nil,
        enableVisualization: Bool? = nil,
        endDateTime: String? = nil,
        explainabilityConfig: ExplainabilityConfig,
        explainabilityName: String,
        resourceArn: String,
        schema: Schema? = nil,
        startDateTime: String? = nil,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateExplainabilityResponse {
        let input = CreateExplainabilityRequest(
            dataSource: dataSource, 
            enableVisualization: enableVisualization, 
            endDateTime: endDateTime, 
            explainabilityConfig: explainabilityConfig, 
            explainabilityName: explainabilityName, 
            resourceArn: resourceArn, 
            schema: schema, 
            startDateTime: startDateTime, 
            tags: tags
        )
        return try await self.createExplainability(input, logger: logger)
    }

    /// Exports an Explainability resource created by the CreateExplainability operation. Exported files are exported to an Amazon Simple Storage Service (Amazon S3) bucket. You must specify a DataDestination object that includes an Amazon S3 bucket and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles.  The Status of the export job must be ACTIVE before you can access the export in your Amazon S3 bucket. To get the status, use the DescribeExplainabilityExport operation.
    @Sendable
    @inlinable
    public func createExplainabilityExport(_ input: CreateExplainabilityExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateExplainabilityExportResponse {
        try await self.client.execute(
            operation: "CreateExplainabilityExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Exports an Explainability resource created by the CreateExplainability operation. Exported files are exported to an Amazon Simple Storage Service (Amazon S3) bucket. You must specify a DataDestination object that includes an Amazon S3 bucket and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles.  The Status of the export job must be ACTIVE before you can access the export in your Amazon S3 bucket. To get the status, use the DescribeExplainabilityExport operation.
    ///
    /// Parameters:
    ///   - destination: 
    ///   - explainabilityArn: The Amazon Resource Name (ARN) of the Explainability to export.
    ///   - explainabilityExportName: A unique name for the Explainability export.
    ///   - format: The format of the exported data, CSV or PARQUET.
    ///   - tags: Optional metadata to help you categorize and organize your resources. Each tag consists of a key and an optional value, both of which you define. Tag keys and values are case sensitive. The following restrictions apply to tags:   For each resource, each tag key must be unique and each tag key must have one value.   Maximum number of tags per resource: 50.   Maximum key length: 128 Unicode characters in UTF-8.   Maximum value length: 256 Unicode characters in UTF-8.   Accepted characters: all letters and numbers, spaces representable in UTF-8, and + - = . _ : / @. If your tagging schema is used across other services and resources, the character restrictions of those services also apply.    Key prefixes cannot include any upper or lowercase combination of aws: or AWS:. Values can have this prefix. If a tag value has aws as its prefix but the key does not, Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit. You cannot edit or delete tag keys with this prefix.
    ///   - logger: Logger use during operation
    @inlinable
    public func createExplainabilityExport(
        destination: DataDestination,
        explainabilityArn: String,
        explainabilityExportName: String,
        format: String? = nil,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateExplainabilityExportResponse {
        let input = CreateExplainabilityExportRequest(
            destination: destination, 
            explainabilityArn: explainabilityArn, 
            explainabilityExportName: explainabilityExportName, 
            format: format, 
            tags: tags
        )
        return try await self.createExplainabilityExport(input, logger: logger)
    }

    /// Creates a forecast for each item in the TARGET_TIME_SERIES dataset that was used to train the predictor. This is known as inference. To retrieve the forecast for a single item at low latency, use the  operation. To export the complete forecast into your Amazon Simple Storage Service (Amazon S3) bucket, use the CreateForecastExportJob operation. The range of the forecast is determined by the ForecastHorizon value, which you specify in the CreatePredictor request. When you query a forecast, you can request a specific date range within the forecast. To get a list of all your forecasts, use the ListForecasts operation.  The forecasts generated by Amazon Forecast are in the same time zone as the dataset that was used to create the predictor.  For more information, see howitworks-forecast.  The Status of the forecast must be ACTIVE before you can query or export the forecast. Use the DescribeForecast operation to get the status.  By default, a forecast includes predictions for every item (item_id) in the dataset group that was used to train the predictor. However, you can use the TimeSeriesSelector object to generate a forecast on a subset of time series. Forecast creation is skipped for any time series that you specify that are not in the input dataset. The forecast export file will not contain these time series or their forecasted values.
    @Sendable
    @inlinable
    public func createForecast(_ input: CreateForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateForecastResponse {
        try await self.client.execute(
            operation: "CreateForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates a forecast for each item in the TARGET_TIME_SERIES dataset that was used to train the predictor. This is known as inference. To retrieve the forecast for a single item at low latency, use the  operation. To export the complete forecast into your Amazon Simple Storage Service (Amazon S3) bucket, use the CreateForecastExportJob operation. The range of the forecast is determined by the ForecastHorizon value, which you specify in the CreatePredictor request. When you query a forecast, you can request a specific date range within the forecast. To get a list of all your forecasts, use the ListForecasts operation.  The forecasts generated by Amazon Forecast are in the same time zone as the dataset that was used to create the predictor.  For more information, see howitworks-forecast.  The Status of the forecast must be ACTIVE before you can query or export the forecast. Use the DescribeForecast operation to get the status.  By default, a forecast includes predictions for every item (item_id) in the dataset group that was used to train the predictor. However, you can use the TimeSeriesSelector object to generate a forecast on a subset of time series. Forecast creation is skipped for any time series that you specify that are not in the input dataset. The forecast export file will not contain these time series or their forecasted values.
    ///
    /// Parameters:
    ///   - forecastName: A name for the forecast.
    ///   - forecastTypes: The quantiles at which probabilistic forecasts are generated. You can currently specify up to 5 quantiles per forecast. Accepted values include 0.01 to 0.99 (increments of .01 only) and mean. The mean forecast is different from the median (0.50) when the distribution is not symmetric (for example, Beta and Negative Binomial).  The default quantiles are the quantiles you specified during predictor creation. If you didn't specify quantiles, the default values are ["0.1", "0.5", "0.9"].
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor to use to generate the forecast.
    ///   - tags: The optional metadata that you apply to the forecast to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - timeSeriesSelector: Defines the set of time series that are used to create the forecasts in a TimeSeriesIdentifiers object. The TimeSeriesIdentifiers object needs the following information:    DataSource     Format     Schema
    ///   - logger: Logger use during operation
    @inlinable
    public func createForecast(
        forecastName: String,
        forecastTypes: [String]? = nil,
        predictorArn: String,
        tags: [Tag]? = nil,
        timeSeriesSelector: TimeSeriesSelector? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateForecastResponse {
        let input = CreateForecastRequest(
            forecastName: forecastName, 
            forecastTypes: forecastTypes, 
            predictorArn: predictorArn, 
            tags: tags, 
            timeSeriesSelector: timeSeriesSelector
        )
        return try await self.createForecast(input, logger: logger)
    }

    /// Exports a forecast created by the CreateForecast operation to your Amazon Simple Storage Service (Amazon S3) bucket. The forecast file name will match the following conventions: __ where the  component is in Java SimpleDateFormat (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles. For more information, see howitworks-forecast. To get a list of all your forecast export jobs, use the ListForecastExportJobs operation.  The Status of the forecast export job must be ACTIVE before you can access the forecast in your Amazon S3 bucket. To get the status, use the DescribeForecastExportJob operation.
    @Sendable
    @inlinable
    public func createForecastExportJob(_ input: CreateForecastExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateForecastExportJobResponse {
        try await self.client.execute(
            operation: "CreateForecastExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Exports a forecast created by the CreateForecast operation to your Amazon Simple Storage Service (Amazon S3) bucket. The forecast file name will match the following conventions: __ where the  component is in Java SimpleDateFormat (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles. For more information, see howitworks-forecast. To get a list of all your forecast export jobs, use the ListForecastExportJobs operation.  The Status of the forecast export job must be ACTIVE before you can access the forecast in your Amazon S3 bucket. To get the status, use the DescribeForecastExportJob operation.
    ///
    /// Parameters:
    ///   - destination: The location where you want to save the forecast and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the location. The forecast must be exported to an Amazon S3 bucket. If encryption is used, Destination must include an Key Management Service (KMS) key. The IAM role must allow Amazon Forecast permission to access the key.
    ///   - forecastArn: The Amazon Resource Name (ARN) of the forecast that you want to export.
    ///   - forecastExportJobName: The name for the forecast export job.
    ///   - format: The format of the exported data, CSV or PARQUET. The default value is CSV.
    ///   - tags: The optional metadata that you apply to the forecast export job to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - logger: Logger use during operation
    @inlinable
    public func createForecastExportJob(
        destination: DataDestination,
        forecastArn: String,
        forecastExportJobName: String,
        format: String? = nil,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateForecastExportJobResponse {
        let input = CreateForecastExportJobRequest(
            destination: destination, 
            forecastArn: forecastArn, 
            forecastExportJobName: forecastExportJobName, 
            format: format, 
            tags: tags
        )
        return try await self.createForecastExportJob(input, logger: logger)
    }

    /// Creates a predictor monitor resource for an existing auto predictor. Predictor monitoring allows you to see how your predictor's performance changes over time. For more information, see Predictor Monitoring.
    @Sendable
    @inlinable
    public func createMonitor(_ input: CreateMonitorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateMonitorResponse {
        try await self.client.execute(
            operation: "CreateMonitor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates a predictor monitor resource for an existing auto predictor. Predictor monitoring allows you to see how your predictor's performance changes over time. For more information, see Predictor Monitoring.
    ///
    /// Parameters:
    ///   - monitorName: The name of the monitor resource.
    ///   - resourceArn: The Amazon Resource Name (ARN) of the predictor to monitor.
    ///   - tags: A list of tags to apply to the monitor resource.
    ///   - logger: Logger use during operation
    @inlinable
    public func createMonitor(
        monitorName: String,
        resourceArn: String,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateMonitorResponse {
        let input = CreateMonitorRequest(
            monitorName: monitorName, 
            resourceArn: resourceArn, 
            tags: tags
        )
        return try await self.createMonitor(input, logger: logger)
    }

    ///  This operation creates a legacy predictor that does not include all the predictor functionalities provided by Amazon Forecast. To create a predictor that is compatible with all aspects of Forecast, use CreateAutoPredictor.  Creates an Amazon Forecast predictor. In the request, provide a dataset group and either specify an algorithm or let Amazon Forecast choose an algorithm for you using AutoML. If you specify an algorithm, you also can override algorithm-specific hyperparameters. Amazon Forecast uses the algorithm to train a predictor using the latest version of the datasets in the specified dataset group. You can then generate a forecast using the CreateForecast operation. To see the evaluation metrics, use the GetAccuracyMetrics operation.  You can specify a featurization configuration to fill and aggregate the data fields in the TARGET_TIME_SERIES dataset to improve model training. For more information, see FeaturizationConfig. For RELATED_TIME_SERIES datasets, CreatePredictor verifies that the DataFrequency specified when the dataset was created matches the ForecastFrequency. TARGET_TIME_SERIES datasets don't have this restriction. Amazon Forecast also verifies the delimiter and timestamp format. For more information, see howitworks-datasets-groups. By default, predictors are trained and evaluated at the 0.1 (P10), 0.5 (P50), and 0.9 (P90) quantiles. You can choose custom forecast types to train and evaluate your predictor by setting the ForecastTypes.   AutoML  If you want Amazon Forecast to evaluate each algorithm and choose the one that minimizes the objective function, set PerformAutoML to true. The objective function is defined as the mean of the weighted losses over the forecast types. By default, these are the p10, p50, and p90 quantile losses. For more information, see EvaluationResult. When AutoML is enabled, the following properties are disallowed:    AlgorithmArn     HPOConfig     PerformHPO     TrainingParameters    To get a list of all of your predictors, use the ListPredictors operation.  Before you can use the predictor to create a forecast, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation.
    @Sendable
    @inlinable
    public func createPredictor(_ input: CreatePredictorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreatePredictorResponse {
        try await self.client.execute(
            operation: "CreatePredictor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This operation creates a legacy predictor that does not include all the predictor functionalities provided by Amazon Forecast. To create a predictor that is compatible with all aspects of Forecast, use CreateAutoPredictor.  Creates an Amazon Forecast predictor. In the request, provide a dataset group and either specify an algorithm or let Amazon Forecast choose an algorithm for you using AutoML. If you specify an algorithm, you also can override algorithm-specific hyperparameters. Amazon Forecast uses the algorithm to train a predictor using the latest version of the datasets in the specified dataset group. You can then generate a forecast using the CreateForecast operation. To see the evaluation metrics, use the GetAccuracyMetrics operation.  You can specify a featurization configuration to fill and aggregate the data fields in the TARGET_TIME_SERIES dataset to improve model training. For more information, see FeaturizationConfig. For RELATED_TIME_SERIES datasets, CreatePredictor verifies that the DataFrequency specified when the dataset was created matches the ForecastFrequency. TARGET_TIME_SERIES datasets don't have this restriction. Amazon Forecast also verifies the delimiter and timestamp format. For more information, see howitworks-datasets-groups. By default, predictors are trained and evaluated at the 0.1 (P10), 0.5 (P50), and 0.9 (P90) quantiles. You can choose custom forecast types to train and evaluate your predictor by setting the ForecastTypes.   AutoML  If you want Amazon Forecast to evaluate each algorithm and choose the one that minimizes the objective function, set PerformAutoML to true. The objective function is defined as the mean of the weighted losses over the forecast types. By default, these are the p10, p50, and p90 quantile losses. For more information, see EvaluationResult. When AutoML is enabled, the following properties are disallowed:    AlgorithmArn     HPOConfig     PerformHPO     TrainingParameters    To get a list of all of your predictors, use the ListPredictors operation.  Before you can use the predictor to create a forecast, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation.
    ///
    /// Parameters:
    ///   - algorithmArn: The Amazon Resource Name (ARN) of the algorithm to use for model training. Required if PerformAutoML is not set to true.  Supported algorithms:     arn:aws:forecast:::algorithm/ARIMA     arn:aws:forecast:::algorithm/CNN-QR     arn:aws:forecast:::algorithm/Deep_AR_Plus     arn:aws:forecast:::algorithm/ETS     arn:aws:forecast:::algorithm/NPTS     arn:aws:forecast:::algorithm/Prophet
    ///   - autoMLOverrideStrategy:  The LatencyOptimized AutoML override strategy is only available in private beta. Contact Amazon Web Services Support or your account manager to learn more about access privileges.   Used to overide the default AutoML strategy, which is to optimize predictor accuracy. To apply an AutoML strategy that minimizes training time, use LatencyOptimized. This parameter is only valid for predictors trained using AutoML.
    ///   - encryptionConfig: An Key Management Service (KMS) key and the Identity and Access Management (IAM) role that Amazon Forecast can assume to access the key.
    ///   - evaluationParameters: Used to override the default evaluation parameters of the specified algorithm. Amazon Forecast evaluates a predictor by splitting a dataset into training data and testing data. The evaluation parameters define how to perform the split and the number of iterations.
    ///   - featurizationConfig: The featurization configuration.
    ///   - forecastHorizon: Specifies the number of time-steps that the model is trained to predict. The forecast horizon is also called the prediction length. For example, if you configure a dataset for daily data collection (using the DataFrequency parameter of the CreateDataset operation) and set the forecast horizon to 10, the model returns predictions for 10 days. The maximum forecast horizon is the lesser of 500 time-steps or 1/3 of the TARGET_TIME_SERIES dataset length.
    ///   - forecastTypes: Specifies the forecast types used to train a predictor. You can specify up to five forecast types. Forecast types can be quantiles from 0.01 to 0.99, by increments of 0.01 or higher. You can also specify the mean forecast with mean.  The default value is ["0.10", "0.50", "0.9"].
    ///   - hpoConfig: Provides hyperparameter override values for the algorithm. If you don't provide this parameter, Amazon Forecast uses default values. The individual algorithms specify which hyperparameters support hyperparameter optimization (HPO). For more information, see aws-forecast-choosing-recipes. If you included the HPOConfig object, you must set PerformHPO to true.
    ///   - inputDataConfig: Describes the dataset group that contains the data to use to train the predictor.
    ///   - optimizationMetric: The accuracy metric used to optimize the predictor.
    ///   - performAutoML: Whether to perform AutoML. When Amazon Forecast performs AutoML, it evaluates the algorithms it provides and chooses the best algorithm and configuration for your training dataset. The default value is false. In this case, you are required to specify an algorithm. Set PerformAutoML to true to have Amazon Forecast perform AutoML. This is a good option if you aren't sure which algorithm is suitable for your training data. In this case, PerformHPO must be false.
    ///   - performHPO: Whether to perform hyperparameter optimization (HPO). HPO finds optimal hyperparameter values for your training data. The process of performing HPO is known as running a hyperparameter tuning job. The default value is false. In this case, Amazon Forecast uses default hyperparameter values from the chosen algorithm. To override the default values, set PerformHPO to true and, optionally, supply the HyperParameterTuningJobConfig object. The tuning job specifies a metric to optimize, which hyperparameters participate in tuning, and the valid range for each tunable hyperparameter. In this case, you are required to specify an algorithm and PerformAutoML must be false. The following algorithms support HPO:   DeepAR+   CNN-QR
    ///   - predictorName: A name for the predictor.
    ///   - tags: The optional metadata that you apply to the predictor to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - trainingParameters: The hyperparameters to override for model training. The hyperparameters that you can override are listed in the individual algorithms. For the list of supported algorithms, see aws-forecast-choosing-recipes.
    ///   - logger: Logger use during operation
    @inlinable
    public func createPredictor(
        algorithmArn: String? = nil,
        autoMLOverrideStrategy: AutoMLOverrideStrategy? = nil,
        encryptionConfig: EncryptionConfig? = nil,
        evaluationParameters: EvaluationParameters? = nil,
        featurizationConfig: FeaturizationConfig,
        forecastHorizon: Int,
        forecastTypes: [String]? = nil,
        hpoConfig: HyperParameterTuningJobConfig? = nil,
        inputDataConfig: InputDataConfig,
        optimizationMetric: OptimizationMetric? = nil,
        performAutoML: Bool? = nil,
        performHPO: Bool? = nil,
        predictorName: String,
        tags: [Tag]? = nil,
        trainingParameters: [String: String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreatePredictorResponse {
        let input = CreatePredictorRequest(
            algorithmArn: algorithmArn, 
            autoMLOverrideStrategy: autoMLOverrideStrategy, 
            encryptionConfig: encryptionConfig, 
            evaluationParameters: evaluationParameters, 
            featurizationConfig: featurizationConfig, 
            forecastHorizon: forecastHorizon, 
            forecastTypes: forecastTypes, 
            hpoConfig: hpoConfig, 
            inputDataConfig: inputDataConfig, 
            optimizationMetric: optimizationMetric, 
            performAutoML: performAutoML, 
            performHPO: performHPO, 
            predictorName: predictorName, 
            tags: tags, 
            trainingParameters: trainingParameters
        )
        return try await self.createPredictor(input, logger: logger)
    }

    /// Exports backtest forecasts and accuracy metrics generated by the CreateAutoPredictor or CreatePredictor operations. Two folders containing CSV or Parquet files are exported to your specified S3 bucket. The export file names will match the following conventions:  __.csv  The  component is in Java SimpleDate format (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Amazon S3 bucket and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles.  The Status of the export job must be ACTIVE before you can access the export in your Amazon S3 bucket. To get the status, use the DescribePredictorBacktestExportJob operation.
    @Sendable
    @inlinable
    public func createPredictorBacktestExportJob(_ input: CreatePredictorBacktestExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreatePredictorBacktestExportJobResponse {
        try await self.client.execute(
            operation: "CreatePredictorBacktestExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Exports backtest forecasts and accuracy metrics generated by the CreateAutoPredictor or CreatePredictor operations. Two folders containing CSV or Parquet files are exported to your specified S3 bucket. The export file names will match the following conventions:  __.csv  The  component is in Java SimpleDate format (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Amazon S3 bucket and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles.  The Status of the export job must be ACTIVE before you can access the export in your Amazon S3 bucket. To get the status, use the DescribePredictorBacktestExportJob operation.
    ///
    /// Parameters:
    ///   - destination: 
    ///   - format: The format of the exported data, CSV or PARQUET. The default value is CSV.
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor that you want to export.
    ///   - predictorBacktestExportJobName: The name for the backtest export job.
    ///   - tags: Optional metadata to help you categorize and organize your backtests. Each tag consists of a key and an optional value, both of which you define. Tag keys and values are case sensitive. The following restrictions apply to tags:   For each resource, each tag key must be unique and each tag key must have one value.   Maximum number of tags per resource: 50.   Maximum key length: 128 Unicode characters in UTF-8.   Maximum value length: 256 Unicode characters in UTF-8.   Accepted characters: all letters and numbers, spaces representable in UTF-8, and + - = . _ : / @. If your tagging schema is used across other services and resources, the character restrictions of those services also apply.    Key prefixes cannot include any upper or lowercase combination of aws: or AWS:. Values can have this prefix. If a tag value has aws as its prefix but the key does not, Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit. You cannot edit or delete tag keys with this prefix.
    ///   - logger: Logger use during operation
    @inlinable
    public func createPredictorBacktestExportJob(
        destination: DataDestination,
        format: String? = nil,
        predictorArn: String,
        predictorBacktestExportJobName: String,
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreatePredictorBacktestExportJobResponse {
        let input = CreatePredictorBacktestExportJobRequest(
            destination: destination, 
            format: format, 
            predictorArn: predictorArn, 
            predictorBacktestExportJobName: predictorBacktestExportJobName, 
            tags: tags
        )
        return try await self.createPredictorBacktestExportJob(input, logger: logger)
    }

    /// What-if analysis is a scenario modeling technique where you make a hypothetical change to a time series and compare the forecasts generated by these changes against the baseline, unchanged time series. It is important to remember that the purpose of a what-if analysis is to understand how a forecast can change given different modifications to the baseline time series. For example, imagine you are a clothing retailer who is considering an end of season sale to clear space for new styles. After creating a baseline forecast, you can use a what-if analysis to investigate how different sales tactics might affect your goals. You could create a scenario where everything is given a 25% markdown, and another where everything is given a fixed dollar markdown. You could create a scenario where the sale lasts for one week and another where the sale lasts for one month. With a what-if analysis, you can compare many different scenarios against each other. Note that a what-if analysis is meant to display what the forecasting model has learned and how it will behave in the scenarios that you are evaluating. Do not blindly use the results of the what-if analysis to make business decisions. For instance, forecasts might not be accurate for novel scenarios where there is no reference available to determine whether a forecast is good. The TimeSeriesSelector object defines the items that you want in the what-if analysis.
    @Sendable
    @inlinable
    public func createWhatIfAnalysis(_ input: CreateWhatIfAnalysisRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateWhatIfAnalysisResponse {
        try await self.client.execute(
            operation: "CreateWhatIfAnalysis", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// What-if analysis is a scenario modeling technique where you make a hypothetical change to a time series and compare the forecasts generated by these changes against the baseline, unchanged time series. It is important to remember that the purpose of a what-if analysis is to understand how a forecast can change given different modifications to the baseline time series. For example, imagine you are a clothing retailer who is considering an end of season sale to clear space for new styles. After creating a baseline forecast, you can use a what-if analysis to investigate how different sales tactics might affect your goals. You could create a scenario where everything is given a 25% markdown, and another where everything is given a fixed dollar markdown. You could create a scenario where the sale lasts for one week and another where the sale lasts for one month. With a what-if analysis, you can compare many different scenarios against each other. Note that a what-if analysis is meant to display what the forecasting model has learned and how it will behave in the scenarios that you are evaluating. Do not blindly use the results of the what-if analysis to make business decisions. For instance, forecasts might not be accurate for novel scenarios where there is no reference available to determine whether a forecast is good. The TimeSeriesSelector object defines the items that you want in the what-if analysis.
    ///
    /// Parameters:
    ///   - forecastArn: The Amazon Resource Name (ARN) of the baseline forecast.
    ///   - tags: A list of tags to apply to the what if forecast.
    ///   - timeSeriesSelector: Defines the set of time series that are used in the what-if analysis with a TimeSeriesIdentifiers object. What-if analyses are performed only for the time series in this object. The TimeSeriesIdentifiers object needs the following information:    DataSource     Format     Schema
    ///   - whatIfAnalysisName: The name of the what-if analysis. Each name must be unique.
    ///   - logger: Logger use during operation
    @inlinable
    public func createWhatIfAnalysis(
        forecastArn: String,
        tags: [Tag]? = nil,
        timeSeriesSelector: TimeSeriesSelector? = nil,
        whatIfAnalysisName: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateWhatIfAnalysisResponse {
        let input = CreateWhatIfAnalysisRequest(
            forecastArn: forecastArn, 
            tags: tags, 
            timeSeriesSelector: timeSeriesSelector, 
            whatIfAnalysisName: whatIfAnalysisName
        )
        return try await self.createWhatIfAnalysis(input, logger: logger)
    }

    /// A what-if forecast is a forecast that is created from a modified version of the baseline forecast. Each what-if forecast incorporates either a replacement dataset or a set of transformations to the original dataset.
    @Sendable
    @inlinable
    public func createWhatIfForecast(_ input: CreateWhatIfForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateWhatIfForecastResponse {
        try await self.client.execute(
            operation: "CreateWhatIfForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// A what-if forecast is a forecast that is created from a modified version of the baseline forecast. Each what-if forecast incorporates either a replacement dataset or a set of transformations to the original dataset.
    ///
    /// Parameters:
    ///   - tags: A list of tags to apply to the what if forecast.
    ///   - timeSeriesReplacementsDataSource: The replacement time series dataset, which contains the rows that you want to change in the related time series dataset. A replacement time series does not need to contain all rows that are in the baseline related time series. Include only the rows (measure-dimension combinations) that you want to include in the what-if forecast. This dataset is merged with the original time series to create a transformed dataset that is used for the what-if analysis. This dataset should contain the items to modify (such as item_id or workforce_type), any relevant dimensions, the timestamp column, and at least one of the related time series columns. This file should not contain duplicate timestamps for the same time series. Timestamps and item_ids not included in this dataset are not included in the what-if analysis.
    ///   - timeSeriesTransformations: The transformations that are applied to the baseline time series. Each transformation contains an action and a set of conditions. An action is applied only when all conditions are met. If no conditions are provided, the action is applied to all items.
    ///   - whatIfAnalysisArn: The Amazon Resource Name (ARN) of the what-if analysis.
    ///   - whatIfForecastName: The name of the what-if forecast. Names must be unique within each what-if analysis.
    ///   - logger: Logger use during operation
    @inlinable
    public func createWhatIfForecast(
        tags: [Tag]? = nil,
        timeSeriesReplacementsDataSource: TimeSeriesReplacementsDataSource? = nil,
        timeSeriesTransformations: [TimeSeriesTransformation]? = nil,
        whatIfAnalysisArn: String,
        whatIfForecastName: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateWhatIfForecastResponse {
        let input = CreateWhatIfForecastRequest(
            tags: tags, 
            timeSeriesReplacementsDataSource: timeSeriesReplacementsDataSource, 
            timeSeriesTransformations: timeSeriesTransformations, 
            whatIfAnalysisArn: whatIfAnalysisArn, 
            whatIfForecastName: whatIfForecastName
        )
        return try await self.createWhatIfForecast(input, logger: logger)
    }

    /// Exports a forecast created by the CreateWhatIfForecast operation to your Amazon Simple Storage Service (Amazon S3) bucket. The forecast file name will match the following conventions:  ≈__  The  component is in Java SimpleDateFormat (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles. For more information, see howitworks-forecast. To get a list of all your what-if forecast export jobs, use the ListWhatIfForecastExports operation.  The Status of the forecast export job must be ACTIVE before you can access the forecast in your Amazon S3 bucket. To get the status, use the DescribeWhatIfForecastExport operation.
    @Sendable
    @inlinable
    public func createWhatIfForecastExport(_ input: CreateWhatIfForecastExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> CreateWhatIfForecastExportResponse {
        try await self.client.execute(
            operation: "CreateWhatIfForecastExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Exports a forecast created by the CreateWhatIfForecast operation to your Amazon Simple Storage Service (Amazon S3) bucket. The forecast file name will match the following conventions:  ≈__  The  component is in Java SimpleDateFormat (yyyy-MM-ddTHH-mm-ssZ). You must specify a DataDestination object that includes an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see aws-forecast-iam-roles. For more information, see howitworks-forecast. To get a list of all your what-if forecast export jobs, use the ListWhatIfForecastExports operation.  The Status of the forecast export job must be ACTIVE before you can access the forecast in your Amazon S3 bucket. To get the status, use the DescribeWhatIfForecastExport operation.
    ///
    /// Parameters:
    ///   - destination: The location where you want to save the forecast and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the location. The forecast must be exported to an Amazon S3 bucket. If encryption is used, Destination must include an Key Management Service (KMS) key. The IAM role must allow Amazon Forecast permission to access the key.
    ///   - format: The format of the exported data, CSV or PARQUET.
    ///   - tags: A list of tags to apply to the what if forecast.
    ///   - whatIfForecastArns: The list of what-if forecast Amazon Resource Names (ARNs) to export.
    ///   - whatIfForecastExportName: The name of the what-if forecast to export.
    ///   - logger: Logger use during operation
    @inlinable
    public func createWhatIfForecastExport(
        destination: DataDestination,
        format: String? = nil,
        tags: [Tag]? = nil,
        whatIfForecastArns: [String],
        whatIfForecastExportName: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CreateWhatIfForecastExportResponse {
        let input = CreateWhatIfForecastExportRequest(
            destination: destination, 
            format: format, 
            tags: tags, 
            whatIfForecastArns: whatIfForecastArns, 
            whatIfForecastExportName: whatIfForecastExportName
        )
        return try await self.createWhatIfForecastExport(input, logger: logger)
    }

    /// Deletes an Amazon Forecast dataset that was created using the CreateDataset operation. You can only delete datasets that have a status of ACTIVE or CREATE_FAILED. To get the status use the DescribeDataset operation.  Forecast does not automatically update any dataset groups that contain the deleted dataset. In order to update the dataset group, use the UpdateDatasetGroup operation, omitting the deleted dataset's ARN.
    @Sendable
    @inlinable
    public func deleteDataset(_ input: DeleteDatasetRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteDataset", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes an Amazon Forecast dataset that was created using the CreateDataset operation. You can only delete datasets that have a status of ACTIVE or CREATE_FAILED. To get the status use the DescribeDataset operation.  Forecast does not automatically update any dataset groups that contain the deleted dataset. In order to update the dataset group, use the UpdateDatasetGroup operation, omitting the deleted dataset's ARN.
    ///
    /// Parameters:
    ///   - datasetArn: The Amazon Resource Name (ARN) of the dataset to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteDataset(
        datasetArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteDatasetRequest(
            datasetArn: datasetArn
        )
        return try await self.deleteDataset(input, logger: logger)
    }

    /// Deletes a dataset group created using the CreateDatasetGroup operation. You can only delete dataset groups that have a status of ACTIVE, CREATE_FAILED, or UPDATE_FAILED. To get the status, use the DescribeDatasetGroup operation. This operation deletes only the dataset group, not the datasets in the group.
    @Sendable
    @inlinable
    public func deleteDatasetGroup(_ input: DeleteDatasetGroupRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteDatasetGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a dataset group created using the CreateDatasetGroup operation. You can only delete dataset groups that have a status of ACTIVE, CREATE_FAILED, or UPDATE_FAILED. To get the status, use the DescribeDatasetGroup operation. This operation deletes only the dataset group, not the datasets in the group.
    ///
    /// Parameters:
    ///   - datasetGroupArn: The Amazon Resource Name (ARN) of the dataset group to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteDatasetGroup(
        datasetGroupArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteDatasetGroupRequest(
            datasetGroupArn: datasetGroupArn
        )
        return try await self.deleteDatasetGroup(input, logger: logger)
    }

    /// Deletes a dataset import job created using the CreateDatasetImportJob operation. You can delete only dataset import jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeDatasetImportJob operation.
    @Sendable
    @inlinable
    public func deleteDatasetImportJob(_ input: DeleteDatasetImportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteDatasetImportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a dataset import job created using the CreateDatasetImportJob operation. You can delete only dataset import jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeDatasetImportJob operation.
    ///
    /// Parameters:
    ///   - datasetImportJobArn: The Amazon Resource Name (ARN) of the dataset import job to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteDatasetImportJob(
        datasetImportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteDatasetImportJobRequest(
            datasetImportJobArn: datasetImportJobArn
        )
        return try await self.deleteDatasetImportJob(input, logger: logger)
    }

    /// Deletes an Explainability resource. You can delete only predictor that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeExplainability operation.
    @Sendable
    @inlinable
    public func deleteExplainability(_ input: DeleteExplainabilityRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteExplainability", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes an Explainability resource. You can delete only predictor that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeExplainability operation.
    ///
    /// Parameters:
    ///   - explainabilityArn: The Amazon Resource Name (ARN) of the Explainability resource to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteExplainability(
        explainabilityArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteExplainabilityRequest(
            explainabilityArn: explainabilityArn
        )
        return try await self.deleteExplainability(input, logger: logger)
    }

    /// Deletes an Explainability export.
    @Sendable
    @inlinable
    public func deleteExplainabilityExport(_ input: DeleteExplainabilityExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteExplainabilityExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes an Explainability export.
    ///
    /// Parameters:
    ///   - explainabilityExportArn: The Amazon Resource Name (ARN) of the Explainability export to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteExplainabilityExport(
        explainabilityExportArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteExplainabilityExportRequest(
            explainabilityExportArn: explainabilityExportArn
        )
        return try await self.deleteExplainabilityExport(input, logger: logger)
    }

    /// Deletes a forecast created using the CreateForecast operation. You can delete only forecasts that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecast operation. You can't delete a forecast while it is being exported. After a forecast is deleted, you can no longer query the forecast.
    @Sendable
    @inlinable
    public func deleteForecast(_ input: DeleteForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a forecast created using the CreateForecast operation. You can delete only forecasts that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecast operation. You can't delete a forecast while it is being exported. After a forecast is deleted, you can no longer query the forecast.
    ///
    /// Parameters:
    ///   - forecastArn: The Amazon Resource Name (ARN) of the forecast to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteForecast(
        forecastArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteForecastRequest(
            forecastArn: forecastArn
        )
        return try await self.deleteForecast(input, logger: logger)
    }

    /// Deletes a forecast export job created using the CreateForecastExportJob operation. You can delete only export jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecastExportJob operation.
    @Sendable
    @inlinable
    public func deleteForecastExportJob(_ input: DeleteForecastExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteForecastExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a forecast export job created using the CreateForecastExportJob operation. You can delete only export jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecastExportJob operation.
    ///
    /// Parameters:
    ///   - forecastExportJobArn: The Amazon Resource Name (ARN) of the forecast export job to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteForecastExportJob(
        forecastExportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteForecastExportJobRequest(
            forecastExportJobArn: forecastExportJobArn
        )
        return try await self.deleteForecastExportJob(input, logger: logger)
    }

    /// Deletes a monitor resource. You can only delete a monitor resource with a status of ACTIVE, ACTIVE_STOPPED, CREATE_FAILED, or CREATE_STOPPED.
    @Sendable
    @inlinable
    public func deleteMonitor(_ input: DeleteMonitorRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteMonitor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a monitor resource. You can only delete a monitor resource with a status of ACTIVE, ACTIVE_STOPPED, CREATE_FAILED, or CREATE_STOPPED.
    ///
    /// Parameters:
    ///   - monitorArn: The Amazon Resource Name (ARN) of the monitor resource to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteMonitor(
        monitorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteMonitorRequest(
            monitorArn: monitorArn
        )
        return try await self.deleteMonitor(input, logger: logger)
    }

    /// Deletes a predictor created using the DescribePredictor or CreatePredictor operations. You can delete only predictor that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribePredictor operation.
    @Sendable
    @inlinable
    public func deletePredictor(_ input: DeletePredictorRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeletePredictor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a predictor created using the DescribePredictor or CreatePredictor operations. You can delete only predictor that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribePredictor operation.
    ///
    /// Parameters:
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deletePredictor(
        predictorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeletePredictorRequest(
            predictorArn: predictorArn
        )
        return try await self.deletePredictor(input, logger: logger)
    }

    /// Deletes a predictor backtest export job.
    @Sendable
    @inlinable
    public func deletePredictorBacktestExportJob(_ input: DeletePredictorBacktestExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeletePredictorBacktestExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a predictor backtest export job.
    ///
    /// Parameters:
    ///   - predictorBacktestExportJobArn: The Amazon Resource Name (ARN) of the predictor backtest export job to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deletePredictorBacktestExportJob(
        predictorBacktestExportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeletePredictorBacktestExportJobRequest(
            predictorBacktestExportJobArn: predictorBacktestExportJobArn
        )
        return try await self.deletePredictorBacktestExportJob(input, logger: logger)
    }

    /// Deletes an entire resource tree. This operation will delete the parent resource and its child resources. Child resources are resources that were created from another resource. For example, when a forecast is generated from a predictor, the forecast is the child resource and the predictor is the parent resource. Amazon Forecast resources possess the following parent-child resource hierarchies:    Dataset: dataset import jobs    Dataset Group: predictors, predictor backtest export jobs, forecasts, forecast export jobs    Predictor: predictor backtest export jobs, forecasts, forecast export jobs    Forecast: forecast export jobs     DeleteResourceTree will only delete Amazon Forecast resources, and will not delete datasets or exported files stored in Amazon S3.
    @Sendable
    @inlinable
    public func deleteResourceTree(_ input: DeleteResourceTreeRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteResourceTree", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes an entire resource tree. This operation will delete the parent resource and its child resources. Child resources are resources that were created from another resource. For example, when a forecast is generated from a predictor, the forecast is the child resource and the predictor is the parent resource. Amazon Forecast resources possess the following parent-child resource hierarchies:    Dataset: dataset import jobs    Dataset Group: predictors, predictor backtest export jobs, forecasts, forecast export jobs    Predictor: predictor backtest export jobs, forecasts, forecast export jobs    Forecast: forecast export jobs     DeleteResourceTree will only delete Amazon Forecast resources, and will not delete datasets or exported files stored in Amazon S3.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) of the parent resource to delete. All child resources of the parent resource will also be deleted.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteResourceTree(
        resourceArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteResourceTreeRequest(
            resourceArn: resourceArn
        )
        return try await self.deleteResourceTree(input, logger: logger)
    }

    /// Deletes a what-if analysis created using the CreateWhatIfAnalysis operation. You can delete only what-if analyses that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfAnalysis operation.  You can't delete a what-if analysis while any of its forecasts are being exported.
    @Sendable
    @inlinable
    public func deleteWhatIfAnalysis(_ input: DeleteWhatIfAnalysisRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteWhatIfAnalysis", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a what-if analysis created using the CreateWhatIfAnalysis operation. You can delete only what-if analyses that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfAnalysis operation.  You can't delete a what-if analysis while any of its forecasts are being exported.
    ///
    /// Parameters:
    ///   - whatIfAnalysisArn: The Amazon Resource Name (ARN) of the what-if analysis that you want to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteWhatIfAnalysis(
        whatIfAnalysisArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteWhatIfAnalysisRequest(
            whatIfAnalysisArn: whatIfAnalysisArn
        )
        return try await self.deleteWhatIfAnalysis(input, logger: logger)
    }

    /// Deletes a what-if forecast created using the CreateWhatIfForecast operation. You can delete only what-if forecasts that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfForecast operation.  You can't delete a what-if forecast while it is being exported. After a what-if forecast is deleted, you can no longer query the what-if analysis.
    @Sendable
    @inlinable
    public func deleteWhatIfForecast(_ input: DeleteWhatIfForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteWhatIfForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a what-if forecast created using the CreateWhatIfForecast operation. You can delete only what-if forecasts that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfForecast operation.  You can't delete a what-if forecast while it is being exported. After a what-if forecast is deleted, you can no longer query the what-if analysis.
    ///
    /// Parameters:
    ///   - whatIfForecastArn: The Amazon Resource Name (ARN) of the what-if forecast that you want to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteWhatIfForecast(
        whatIfForecastArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteWhatIfForecastRequest(
            whatIfForecastArn: whatIfForecastArn
        )
        return try await self.deleteWhatIfForecast(input, logger: logger)
    }

    /// Deletes a what-if forecast export created using the CreateWhatIfForecastExport operation. You can delete only what-if forecast exports that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfForecastExport operation.
    @Sendable
    @inlinable
    public func deleteWhatIfForecastExport(_ input: DeleteWhatIfForecastExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteWhatIfForecastExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes a what-if forecast export created using the CreateWhatIfForecastExport operation. You can delete only what-if forecast exports that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeWhatIfForecastExport operation.
    ///
    /// Parameters:
    ///   - whatIfForecastExportArn: The Amazon Resource Name (ARN) of the what-if forecast export that you want to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteWhatIfForecastExport(
        whatIfForecastExportArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteWhatIfForecastExportRequest(
            whatIfForecastExportArn: whatIfForecastExportArn
        )
        return try await self.deleteWhatIfForecastExport(input, logger: logger)
    }

    /// Describes a predictor created using the CreateAutoPredictor operation.
    @Sendable
    @inlinable
    public func describeAutoPredictor(_ input: DescribeAutoPredictorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeAutoPredictorResponse {
        try await self.client.execute(
            operation: "DescribeAutoPredictor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a predictor created using the CreateAutoPredictor operation.
    ///
    /// Parameters:
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeAutoPredictor(
        predictorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeAutoPredictorResponse {
        let input = DescribeAutoPredictorRequest(
            predictorArn: predictorArn
        )
        return try await self.describeAutoPredictor(input, logger: logger)
    }

    /// Describes an Amazon Forecast dataset created using the CreateDataset operation. In addition to listing the parameters specified in the CreateDataset request, this operation includes the following dataset properties:    CreationTime     LastModificationTime     Status
    @Sendable
    @inlinable
    public func describeDataset(_ input: DescribeDatasetRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeDatasetResponse {
        try await self.client.execute(
            operation: "DescribeDataset", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes an Amazon Forecast dataset created using the CreateDataset operation. In addition to listing the parameters specified in the CreateDataset request, this operation includes the following dataset properties:    CreationTime     LastModificationTime     Status
    ///
    /// Parameters:
    ///   - datasetArn: The Amazon Resource Name (ARN) of the dataset.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeDataset(
        datasetArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeDatasetResponse {
        let input = DescribeDatasetRequest(
            datasetArn: datasetArn
        )
        return try await self.describeDataset(input, logger: logger)
    }

    /// Describes a dataset group created using the CreateDatasetGroup operation. In addition to listing the parameters provided in the CreateDatasetGroup request, this operation includes the following properties:    DatasetArns - The datasets belonging to the group.    CreationTime     LastModificationTime     Status
    @Sendable
    @inlinable
    public func describeDatasetGroup(_ input: DescribeDatasetGroupRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeDatasetGroupResponse {
        try await self.client.execute(
            operation: "DescribeDatasetGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a dataset group created using the CreateDatasetGroup operation. In addition to listing the parameters provided in the CreateDatasetGroup request, this operation includes the following properties:    DatasetArns - The datasets belonging to the group.    CreationTime     LastModificationTime     Status
    ///
    /// Parameters:
    ///   - datasetGroupArn: The Amazon Resource Name (ARN) of the dataset group.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeDatasetGroup(
        datasetGroupArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeDatasetGroupResponse {
        let input = DescribeDatasetGroupRequest(
            datasetGroupArn: datasetGroupArn
        )
        return try await self.describeDatasetGroup(input, logger: logger)
    }

    /// Describes a dataset import job created using the CreateDatasetImportJob operation. In addition to listing the parameters provided in the CreateDatasetImportJob request, this operation includes the following properties:    CreationTime     LastModificationTime     DataSize     FieldStatistics     Status     Message - If an error occurred, information about the error.
    @Sendable
    @inlinable
    public func describeDatasetImportJob(_ input: DescribeDatasetImportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeDatasetImportJobResponse {
        try await self.client.execute(
            operation: "DescribeDatasetImportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a dataset import job created using the CreateDatasetImportJob operation. In addition to listing the parameters provided in the CreateDatasetImportJob request, this operation includes the following properties:    CreationTime     LastModificationTime     DataSize     FieldStatistics     Status     Message - If an error occurred, information about the error.
    ///
    /// Parameters:
    ///   - datasetImportJobArn: The Amazon Resource Name (ARN) of the dataset import job.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeDatasetImportJob(
        datasetImportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeDatasetImportJobResponse {
        let input = DescribeDatasetImportJobRequest(
            datasetImportJobArn: datasetImportJobArn
        )
        return try await self.describeDatasetImportJob(input, logger: logger)
    }

    /// Describes an Explainability resource created using the CreateExplainability operation.
    @Sendable
    @inlinable
    public func describeExplainability(_ input: DescribeExplainabilityRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeExplainabilityResponse {
        try await self.client.execute(
            operation: "DescribeExplainability", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes an Explainability resource created using the CreateExplainability operation.
    ///
    /// Parameters:
    ///   - explainabilityArn: The Amazon Resource Name (ARN) of the Explaianability to describe.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeExplainability(
        explainabilityArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeExplainabilityResponse {
        let input = DescribeExplainabilityRequest(
            explainabilityArn: explainabilityArn
        )
        return try await self.describeExplainability(input, logger: logger)
    }

    /// Describes an Explainability export created using the CreateExplainabilityExport operation.
    @Sendable
    @inlinable
    public func describeExplainabilityExport(_ input: DescribeExplainabilityExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeExplainabilityExportResponse {
        try await self.client.execute(
            operation: "DescribeExplainabilityExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes an Explainability export created using the CreateExplainabilityExport operation.
    ///
    /// Parameters:
    ///   - explainabilityExportArn: The Amazon Resource Name (ARN) of the Explainability export.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeExplainabilityExport(
        explainabilityExportArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeExplainabilityExportResponse {
        let input = DescribeExplainabilityExportRequest(
            explainabilityExportArn: explainabilityExportArn
        )
        return try await self.describeExplainabilityExport(input, logger: logger)
    }

    /// Describes a forecast created using the CreateForecast operation. In addition to listing the properties provided in the CreateForecast request, this operation lists the following properties:    DatasetGroupArn - The dataset group that provided the training data.    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    @Sendable
    @inlinable
    public func describeForecast(_ input: DescribeForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeForecastResponse {
        try await self.client.execute(
            operation: "DescribeForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a forecast created using the CreateForecast operation. In addition to listing the properties provided in the CreateForecast request, this operation lists the following properties:    DatasetGroupArn - The dataset group that provided the training data.    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    ///
    /// Parameters:
    ///   - forecastArn: The Amazon Resource Name (ARN) of the forecast.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeForecast(
        forecastArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeForecastResponse {
        let input = DescribeForecastRequest(
            forecastArn: forecastArn
        )
        return try await self.describeForecast(input, logger: logger)
    }

    /// Describes a forecast export job created using the CreateForecastExportJob operation. In addition to listing the properties provided by the user in the CreateForecastExportJob request, this operation lists the following properties:    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    @Sendable
    @inlinable
    public func describeForecastExportJob(_ input: DescribeForecastExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeForecastExportJobResponse {
        try await self.client.execute(
            operation: "DescribeForecastExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a forecast export job created using the CreateForecastExportJob operation. In addition to listing the properties provided by the user in the CreateForecastExportJob request, this operation lists the following properties:    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    ///
    /// Parameters:
    ///   - forecastExportJobArn: The Amazon Resource Name (ARN) of the forecast export job.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeForecastExportJob(
        forecastExportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeForecastExportJobResponse {
        let input = DescribeForecastExportJobRequest(
            forecastExportJobArn: forecastExportJobArn
        )
        return try await self.describeForecastExportJob(input, logger: logger)
    }

    /// Describes a monitor resource. In addition to listing the properties provided in the CreateMonitor request, this operation lists the following properties:    Baseline     CreationTime     LastEvaluationTime     LastEvaluationState     LastModificationTime     Message     Status
    @Sendable
    @inlinable
    public func describeMonitor(_ input: DescribeMonitorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeMonitorResponse {
        try await self.client.execute(
            operation: "DescribeMonitor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a monitor resource. In addition to listing the properties provided in the CreateMonitor request, this operation lists the following properties:    Baseline     CreationTime     LastEvaluationTime     LastEvaluationState     LastModificationTime     Message     Status
    ///
    /// Parameters:
    ///   - monitorArn: The Amazon Resource Name (ARN) of the monitor resource to describe.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeMonitor(
        monitorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeMonitorResponse {
        let input = DescribeMonitorRequest(
            monitorArn: monitorArn
        )
        return try await self.describeMonitor(input, logger: logger)
    }

    ///  This operation is only valid for legacy predictors created with CreatePredictor. If you are not using a legacy predictor, use DescribeAutoPredictor.  Describes a predictor created using the CreatePredictor operation. In addition to listing the properties provided in the CreatePredictor request, this operation lists the following properties:    DatasetImportJobArns - The dataset import jobs used to import training data.    AutoMLAlgorithmArns - If AutoML is performed, the algorithms that were evaluated.    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    @Sendable
    @inlinable
    public func describePredictor(_ input: DescribePredictorRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribePredictorResponse {
        try await self.client.execute(
            operation: "DescribePredictor", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This operation is only valid for legacy predictors created with CreatePredictor. If you are not using a legacy predictor, use DescribeAutoPredictor.  Describes a predictor created using the CreatePredictor operation. In addition to listing the properties provided in the CreatePredictor request, this operation lists the following properties:    DatasetImportJobArns - The dataset import jobs used to import training data.    AutoMLAlgorithmArns - If AutoML is performed, the algorithms that were evaluated.    CreationTime     LastModificationTime     Status     Message - If an error occurred, information about the error.
    ///
    /// Parameters:
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor that you want information about.
    ///   - logger: Logger use during operation
    @inlinable
    public func describePredictor(
        predictorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribePredictorResponse {
        let input = DescribePredictorRequest(
            predictorArn: predictorArn
        )
        return try await self.describePredictor(input, logger: logger)
    }

    /// Describes a predictor backtest export job created using the CreatePredictorBacktestExportJob operation. In addition to listing the properties provided by the user in the CreatePredictorBacktestExportJob request, this operation lists the following properties:    CreationTime     LastModificationTime     Status     Message (if an error occurred)
    @Sendable
    @inlinable
    public func describePredictorBacktestExportJob(_ input: DescribePredictorBacktestExportJobRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribePredictorBacktestExportJobResponse {
        try await self.client.execute(
            operation: "DescribePredictorBacktestExportJob", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes a predictor backtest export job created using the CreatePredictorBacktestExportJob operation. In addition to listing the properties provided by the user in the CreatePredictorBacktestExportJob request, this operation lists the following properties:    CreationTime     LastModificationTime     Status     Message (if an error occurred)
    ///
    /// Parameters:
    ///   - predictorBacktestExportJobArn: The Amazon Resource Name (ARN) of the predictor backtest export job.
    ///   - logger: Logger use during operation
    @inlinable
    public func describePredictorBacktestExportJob(
        predictorBacktestExportJobArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribePredictorBacktestExportJobResponse {
        let input = DescribePredictorBacktestExportJobRequest(
            predictorBacktestExportJobArn: predictorBacktestExportJobArn
        )
        return try await self.describePredictorBacktestExportJob(input, logger: logger)
    }

    /// Describes the what-if analysis created using the CreateWhatIfAnalysis operation. In addition to listing the properties provided in the CreateWhatIfAnalysis request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    @Sendable
    @inlinable
    public func describeWhatIfAnalysis(_ input: DescribeWhatIfAnalysisRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeWhatIfAnalysisResponse {
        try await self.client.execute(
            operation: "DescribeWhatIfAnalysis", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes the what-if analysis created using the CreateWhatIfAnalysis operation. In addition to listing the properties provided in the CreateWhatIfAnalysis request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    ///
    /// Parameters:
    ///   - whatIfAnalysisArn: The Amazon Resource Name (ARN) of the what-if analysis that you are interested in.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeWhatIfAnalysis(
        whatIfAnalysisArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeWhatIfAnalysisResponse {
        let input = DescribeWhatIfAnalysisRequest(
            whatIfAnalysisArn: whatIfAnalysisArn
        )
        return try await self.describeWhatIfAnalysis(input, logger: logger)
    }

    /// Describes the what-if forecast created using the CreateWhatIfForecast operation. In addition to listing the properties provided in the CreateWhatIfForecast request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    @Sendable
    @inlinable
    public func describeWhatIfForecast(_ input: DescribeWhatIfForecastRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeWhatIfForecastResponse {
        try await self.client.execute(
            operation: "DescribeWhatIfForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes the what-if forecast created using the CreateWhatIfForecast operation. In addition to listing the properties provided in the CreateWhatIfForecast request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    ///
    /// Parameters:
    ///   - whatIfForecastArn: The Amazon Resource Name (ARN) of the what-if forecast that you are interested in.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeWhatIfForecast(
        whatIfForecastArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeWhatIfForecastResponse {
        let input = DescribeWhatIfForecastRequest(
            whatIfForecastArn: whatIfForecastArn
        )
        return try await self.describeWhatIfForecast(input, logger: logger)
    }

    /// Describes the what-if forecast export created using the CreateWhatIfForecastExport operation. In addition to listing the properties provided in the CreateWhatIfForecastExport request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    @Sendable
    @inlinable
    public func describeWhatIfForecastExport(_ input: DescribeWhatIfForecastExportRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeWhatIfForecastExportResponse {
        try await self.client.execute(
            operation: "DescribeWhatIfForecastExport", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes the what-if forecast export created using the CreateWhatIfForecastExport operation. In addition to listing the properties provided in the CreateWhatIfForecastExport request, this operation lists the following properties:    CreationTime     LastModificationTime     Message - If an error occurred, information about the error.    Status
    ///
    /// Parameters:
    ///   - whatIfForecastExportArn: The Amazon Resource Name (ARN) of the what-if forecast export that you are interested in.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeWhatIfForecastExport(
        whatIfForecastExportArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeWhatIfForecastExportResponse {
        let input = DescribeWhatIfForecastExportRequest(
            whatIfForecastExportArn: whatIfForecastExportArn
        )
        return try await self.describeWhatIfForecastExport(input, logger: logger)
    }

    /// Provides metrics on the accuracy of the models that were trained by the CreatePredictor operation. Use metrics to see how well the model performed and to decide whether to use the predictor to generate a forecast. For more information, see Predictor Metrics. This operation generates metrics for each backtest window that was evaluated. The number of backtest windows (NumberOfBacktestWindows) is specified using the EvaluationParameters object, which is optionally included in the CreatePredictor request. If NumberOfBacktestWindows isn't specified, the number defaults to one. The parameters of the filling method determine which items contribute to the metrics. If you want all items to contribute, specify zero. If you want only those items that have complete data in the range being evaluated to contribute, specify nan. For more information, see FeaturizationMethod.  Before you can get accuracy metrics, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation.
    @Sendable
    @inlinable
    public func getAccuracyMetrics(_ input: GetAccuracyMetricsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> GetAccuracyMetricsResponse {
        try await self.client.execute(
            operation: "GetAccuracyMetrics", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Provides metrics on the accuracy of the models that were trained by the CreatePredictor operation. Use metrics to see how well the model performed and to decide whether to use the predictor to generate a forecast. For more information, see Predictor Metrics. This operation generates metrics for each backtest window that was evaluated. The number of backtest windows (NumberOfBacktestWindows) is specified using the EvaluationParameters object, which is optionally included in the CreatePredictor request. If NumberOfBacktestWindows isn't specified, the number defaults to one. The parameters of the filling method determine which items contribute to the metrics. If you want all items to contribute, specify zero. If you want only those items that have complete data in the range being evaluated to contribute, specify nan. For more information, see FeaturizationMethod.  Before you can get accuracy metrics, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation.
    ///
    /// Parameters:
    ///   - predictorArn: The Amazon Resource Name (ARN) of the predictor to get metrics for.
    ///   - logger: Logger use during operation
    @inlinable
    public func getAccuracyMetrics(
        predictorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> GetAccuracyMetricsResponse {
        let input = GetAccuracyMetricsRequest(
            predictorArn: predictorArn
        )
        return try await self.getAccuracyMetrics(input, logger: logger)
    }

    /// Returns a list of dataset groups created using the CreateDatasetGroup operation. For each dataset group, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the dataset group ARN with the DescribeDatasetGroup operation.
    @Sendable
    @inlinable
    public func listDatasetGroups(_ input: ListDatasetGroupsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListDatasetGroupsResponse {
        try await self.client.execute(
            operation: "ListDatasetGroups", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of dataset groups created using the CreateDatasetGroup operation. For each dataset group, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the dataset group ARN with the DescribeDatasetGroup operation.
    ///
    /// Parameters:
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listDatasetGroups(
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListDatasetGroupsResponse {
        let input = ListDatasetGroupsRequest(
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listDatasetGroups(input, logger: logger)
    }

    /// Returns a list of dataset import jobs created using the CreateDatasetImportJob operation. For each import job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the ARN with the DescribeDatasetImportJob operation. You can filter the list by providing an array of Filter objects.
    @Sendable
    @inlinable
    public func listDatasetImportJobs(_ input: ListDatasetImportJobsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListDatasetImportJobsResponse {
        try await self.client.execute(
            operation: "ListDatasetImportJobs", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of dataset import jobs created using the CreateDatasetImportJob operation. For each import job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the ARN with the DescribeDatasetImportJob operation. You can filter the list by providing an array of Filter objects.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the datasets that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the datasets that match the statement, specify IS. To exclude matching datasets, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetArn and Status.    Value - The value to match.   For example, to list all dataset import jobs whose status is ACTIVE, you specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listDatasetImportJobs(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListDatasetImportJobsResponse {
        let input = ListDatasetImportJobsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listDatasetImportJobs(input, logger: logger)
    }

    /// Returns a list of datasets created using the CreateDataset operation. For each dataset, a summary of its properties, including its Amazon Resource Name (ARN), is returned. To retrieve the complete set of properties, use the ARN with the DescribeDataset operation.
    @Sendable
    @inlinable
    public func listDatasets(_ input: ListDatasetsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListDatasetsResponse {
        try await self.client.execute(
            operation: "ListDatasets", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of datasets created using the CreateDataset operation. For each dataset, a summary of its properties, including its Amazon Resource Name (ARN), is returned. To retrieve the complete set of properties, use the ARN with the DescribeDataset operation.
    ///
    /// Parameters:
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listDatasets(
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListDatasetsResponse {
        let input = ListDatasetsRequest(
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listDatasets(input, logger: logger)
    }

    /// Returns a list of Explainability resources created using the CreateExplainability operation. This operation returns a summary for each Explainability. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular Explainability resource, use the ARN with the DescribeExplainability operation.
    @Sendable
    @inlinable
    public func listExplainabilities(_ input: ListExplainabilitiesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListExplainabilitiesResponse {
        try await self.client.execute(
            operation: "ListExplainabilities", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Explainability resources created using the CreateExplainability operation. This operation returns a summary for each Explainability. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular Explainability resource, use the ARN with the DescribeExplainability operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. Valid values are ResourceArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items returned in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listExplainabilities(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListExplainabilitiesResponse {
        let input = ListExplainabilitiesRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listExplainabilities(input, logger: logger)
    }

    /// Returns a list of Explainability exports created using the CreateExplainabilityExport operation. This operation returns a summary for each Explainability export. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular Explainability export, use the ARN with the DescribeExplainability operation.
    @Sendable
    @inlinable
    public func listExplainabilityExports(_ input: ListExplainabilityExportsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListExplainabilityExportsResponse {
        try await self.client.execute(
            operation: "ListExplainabilityExports", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of Explainability exports created using the CreateExplainabilityExport operation. This operation returns a summary for each Explainability export. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular Explainability export, use the ARN with the DescribeExplainability operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. Valid values are ResourceArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listExplainabilityExports(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListExplainabilityExportsResponse {
        let input = ListExplainabilityExportsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listExplainabilityExports(input, logger: logger)
    }

    /// Returns a list of forecast export jobs created using the CreateForecastExportJob operation. For each forecast export job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, use the ARN with the DescribeForecastExportJob operation. You can filter the list using an array of Filter objects.
    @Sendable
    @inlinable
    public func listForecastExportJobs(_ input: ListForecastExportJobsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListForecastExportJobsResponse {
        try await self.client.execute(
            operation: "ListForecastExportJobs", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of forecast export jobs created using the CreateForecastExportJob operation. For each forecast export job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, use the ARN with the DescribeForecastExportJob operation. You can filter the list using an array of Filter objects.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are ForecastArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityforecast, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "ForecastArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityforecast" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listForecastExportJobs(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListForecastExportJobsResponse {
        let input = ListForecastExportJobsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listForecastExportJobs(input, logger: logger)
    }

    /// Returns a list of forecasts created using the CreateForecast operation. For each forecast, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, specify the ARN with the DescribeForecast operation. You can filter the list using an array of Filter objects.
    @Sendable
    @inlinable
    public func listForecasts(_ input: ListForecastsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListForecastsResponse {
        try await self.client.execute(
            operation: "ListForecasts", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of forecasts created using the CreateForecast operation. For each forecast, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, specify the ARN with the DescribeForecast operation. You can filter the list using an array of Filter objects.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the forecasts that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecasts that match the statement, specify IS. To exclude matching forecasts, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetGroupArn, PredictorArn, and Status.    Value - The value to match.   For example, to list all forecasts whose status is not ACTIVE, you would specify:  "Filters": [ { "Condition": "IS_NOT", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listForecasts(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListForecastsResponse {
        let input = ListForecastsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listForecasts(input, logger: logger)
    }

    /// Returns a list of the monitoring evaluation results and predictor events collected by the monitor resource during different windows of time. For information about monitoring see predictor-monitoring. For more information about retrieving monitoring results see Viewing Monitoring Results.
    @Sendable
    @inlinable
    public func listMonitorEvaluations(_ input: ListMonitorEvaluationsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListMonitorEvaluationsResponse {
        try await self.client.execute(
            operation: "ListMonitorEvaluations", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of the monitoring evaluation results and predictor events collected by the monitor resource during different windows of time. For information about monitoring see predictor-monitoring. For more information about retrieving monitoring results see Viewing Monitoring Results.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. The only valid value is  EvaluationState.    Value - The value to match. Valid values are only SUCCESS or FAILURE.   For example, to list only successful monitor evaluations, you would specify:  "Filters": [ { "Condition": "IS", "Key": "EvaluationState", "Value": "SUCCESS" } ]
    ///   - maxResults: The maximum number of monitoring results to return.
    ///   - monitorArn: The Amazon Resource Name (ARN) of the monitor resource to get results from.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listMonitorEvaluations(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        monitorArn: String,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListMonitorEvaluationsResponse {
        let input = ListMonitorEvaluationsRequest(
            filters: filters, 
            maxResults: maxResults, 
            monitorArn: monitorArn, 
            nextToken: nextToken
        )
        return try await self.listMonitorEvaluations(input, logger: logger)
    }

    /// Returns a list of monitors created with the CreateMonitor operation and CreateAutoPredictor operation. For each monitor resource, this operation returns of a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve a complete set of properties of a monitor resource by specify the monitor's ARN in the DescribeMonitor operation.
    @Sendable
    @inlinable
    public func listMonitors(_ input: ListMonitorsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListMonitorsResponse {
        try await self.client.execute(
            operation: "ListMonitors", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of monitors created with the CreateMonitor operation and CreateAutoPredictor operation. For each monitor resource, this operation returns of a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve a complete set of properties of a monitor resource by specify the monitor's ARN in the DescribeMonitor operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. The only valid value is  Status.    Value - The value to match.   For example, to list all monitors who's status is ACTIVE, you would specify:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The maximum number of monitors to include in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listMonitors(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListMonitorsResponse {
        let input = ListMonitorsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listMonitors(input, logger: logger)
    }

    /// Returns a list of predictor backtest export jobs created using the CreatePredictorBacktestExportJob operation. This operation returns a summary for each backtest export job. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular backtest export job, use the ARN with the DescribePredictorBacktestExportJob operation.
    @Sendable
    @inlinable
    public func listPredictorBacktestExportJobs(_ input: ListPredictorBacktestExportJobsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListPredictorBacktestExportJobsResponse {
        try await self.client.execute(
            operation: "ListPredictorBacktestExportJobs", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of predictor backtest export jobs created using the CreatePredictorBacktestExportJob operation. This operation returns a summary for each backtest export job. You can filter the list using an array of Filter objects. To retrieve the complete set of properties for a particular backtest export job, use the ARN with the DescribePredictorBacktestExportJob operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the predictor backtest export jobs that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the predictor backtest export jobs that match the statement, specify IS. To exclude matching predictor backtest export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are PredictorArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listPredictorBacktestExportJobs(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListPredictorBacktestExportJobsResponse {
        let input = ListPredictorBacktestExportJobsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listPredictorBacktestExportJobs(input, logger: logger)
    }

    /// Returns a list of predictors created using the CreateAutoPredictor or CreatePredictor operations. For each predictor, this operation returns a summary of its properties, including its Amazon Resource Name (ARN).  You can retrieve the complete set of properties by using the ARN with the DescribeAutoPredictor and DescribePredictor operations. You can filter the list using an array of Filter objects.
    @Sendable
    @inlinable
    public func listPredictors(_ input: ListPredictorsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListPredictorsResponse {
        try await self.client.execute(
            operation: "ListPredictors", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of predictors created using the CreateAutoPredictor or CreatePredictor operations. For each predictor, this operation returns a summary of its properties, including its Amazon Resource Name (ARN).  You can retrieve the complete set of properties by using the ARN with the DescribeAutoPredictor and DescribePredictor operations. You can filter the list using an array of Filter objects.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the predictors that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the predictors that match the statement, specify IS. To exclude matching predictors, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetGroupArn and Status.    Value - The value to match.   For example, to list all predictors whose status is ACTIVE, you would specify:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listPredictors(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListPredictorsResponse {
        let input = ListPredictorsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listPredictors(input, logger: logger)
    }

    /// Lists the tags for an Amazon Forecast resource.
    @Sendable
    @inlinable
    public func listTagsForResource(_ input: ListTagsForResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListTagsForResourceResponse {
        try await self.client.execute(
            operation: "ListTagsForResource", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Lists the tags for an Amazon Forecast resource.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) that identifies the resource for which to list the tags.
    ///   - logger: Logger use during operation
    @inlinable
    public func listTagsForResource(
        resourceArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListTagsForResourceResponse {
        let input = ListTagsForResourceRequest(
            resourceArn: resourceArn
        )
        return try await self.listTagsForResource(input, logger: logger)
    }

    /// Returns a list of what-if analyses created using the CreateWhatIfAnalysis operation. For each what-if analysis, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if analysis ARN with the DescribeWhatIfAnalysis operation.
    @Sendable
    @inlinable
    public func listWhatIfAnalyses(_ input: ListWhatIfAnalysesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListWhatIfAnalysesResponse {
        try await self.client.execute(
            operation: "ListWhatIfAnalyses", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of what-if analyses created using the CreateWhatIfAnalysis operation. For each what-if analysis, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if analysis ARN with the DescribeWhatIfAnalysis operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if analysis jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the what-if analysis jobs that match the statement, specify IS. To exclude matching what-if analysis jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfAnalysisArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWhatIf, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfAnalysisArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWhatIf" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listWhatIfAnalyses(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListWhatIfAnalysesResponse {
        let input = ListWhatIfAnalysesRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listWhatIfAnalyses(input, logger: logger)
    }

    /// Returns a list of what-if forecast exports created using the CreateWhatIfForecastExport operation. For each what-if forecast export, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if forecast export ARN with the DescribeWhatIfForecastExport operation.
    @Sendable
    @inlinable
    public func listWhatIfForecastExports(_ input: ListWhatIfForecastExportsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListWhatIfForecastExportsResponse {
        try await self.client.execute(
            operation: "ListWhatIfForecastExports", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of what-if forecast exports created using the CreateWhatIfForecastExport operation. For each what-if forecast export, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if forecast export ARN with the DescribeWhatIfForecastExport operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfForecastExportArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWIFExport, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfForecastExportArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWIFExport" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next  request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listWhatIfForecastExports(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListWhatIfForecastExportsResponse {
        let input = ListWhatIfForecastExportsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listWhatIfForecastExports(input, logger: logger)
    }

    /// Returns a list of what-if forecasts created using the CreateWhatIfForecast operation. For each what-if forecast, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if forecast ARN with the DescribeWhatIfForecast operation.
    @Sendable
    @inlinable
    public func listWhatIfForecasts(_ input: ListWhatIfForecastsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> ListWhatIfForecastsResponse {
        try await self.client.execute(
            operation: "ListWhatIfForecasts", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Returns a list of what-if forecasts created using the CreateWhatIfForecast operation. For each what-if forecast, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the what-if forecast ARN with the DescribeWhatIfForecast operation.
    ///
    /// Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfForecastArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWhatIfForecast, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfForecastArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWhatIfForecast" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - nextToken: If the result of the previous request was truncated, the response includes a NextToken. To retrieve the next set of results, use the token in the next  request. Tokens expire after 24 hours.
    ///   - logger: Logger use during operation
    @inlinable
    public func listWhatIfForecasts(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ListWhatIfForecastsResponse {
        let input = ListWhatIfForecastsRequest(
            filters: filters, 
            maxResults: maxResults, 
            nextToken: nextToken
        )
        return try await self.listWhatIfForecasts(input, logger: logger)
    }

    /// Resumes a stopped monitor resource.
    @Sendable
    @inlinable
    public func resumeResource(_ input: ResumeResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "ResumeResource", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Resumes a stopped monitor resource.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) of the monitor resource to resume.
    ///   - logger: Logger use during operation
    @inlinable
    public func resumeResource(
        resourceArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = ResumeResourceRequest(
            resourceArn: resourceArn
        )
        return try await self.resumeResource(input, logger: logger)
    }

    /// Stops a resource. The resource undergoes the following states: CREATE_STOPPING and CREATE_STOPPED. You cannot resume a resource once it has been stopped. This operation can be applied to the following resources (and their corresponding child resources):   Dataset Import Job   Predictor Job   Forecast Job   Forecast Export Job   Predictor Backtest Export Job   Explainability Job   Explainability Export Job
    @Sendable
    @inlinable
    public func stopResource(_ input: StopResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "StopResource", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Stops a resource. The resource undergoes the following states: CREATE_STOPPING and CREATE_STOPPED. You cannot resume a resource once it has been stopped. This operation can be applied to the following resources (and their corresponding child resources):   Dataset Import Job   Predictor Job   Forecast Job   Forecast Export Job   Predictor Backtest Export Job   Explainability Job   Explainability Export Job
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) that identifies the resource to stop. The supported ARNs are DatasetImportJobArn, PredictorArn, PredictorBacktestExportJobArn, ForecastArn, ForecastExportJobArn, ExplainabilityArn, and ExplainabilityExportArn.
    ///   - logger: Logger use during operation
    @inlinable
    public func stopResource(
        resourceArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = StopResourceRequest(
            resourceArn: resourceArn
        )
        return try await self.stopResource(input, logger: logger)
    }

    /// Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are also deleted.
    @Sendable
    @inlinable
    public func tagResource(_ input: TagResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> TagResourceResponse {
        try await self.client.execute(
            operation: "TagResource", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are also deleted.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) that identifies the resource for which to list the tags.
    ///   - tags: The tags to add to the resource. A tag is an array of key-value pairs. The following basic restrictions apply to tags:   Maximum number of tags per resource - 50.   For each resource, each tag key must be unique, and each tag key can have only one value.   Maximum key length - 128 Unicode characters in UTF-8.   Maximum value length - 256 Unicode characters in UTF-8.   If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case sensitive.   Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for keys as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys with this prefix. Values can have this prefix. If a tag value has aws as its prefix but the key does not, then Forecast considers it to be a user tag and will count against the limit of 50 tags. Tags with only the key prefix of aws do not count against your tags per resource limit.
    ///   - logger: Logger use during operation
    @inlinable
    public func tagResource(
        resourceArn: String,
        tags: [Tag],
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> TagResourceResponse {
        let input = TagResourceRequest(
            resourceArn: resourceArn, 
            tags: tags
        )
        return try await self.tagResource(input, logger: logger)
    }

    /// Deletes the specified tags from a resource.
    @Sendable
    @inlinable
    public func untagResource(_ input: UntagResourceRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UntagResourceResponse {
        try await self.client.execute(
            operation: "UntagResource", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified tags from a resource.
    ///
    /// Parameters:
    ///   - resourceArn: The Amazon Resource Name (ARN) that identifies the resource for which to list the tags.
    ///   - tagKeys: The keys of the tags to be removed.
    ///   - logger: Logger use during operation
    @inlinable
    public func untagResource(
        resourceArn: String,
        tagKeys: [String],
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UntagResourceResponse {
        let input = UntagResourceRequest(
            resourceArn: resourceArn, 
            tagKeys: tagKeys
        )
        return try await self.untagResource(input, logger: logger)
    }

    /// Replaces the datasets in a dataset group with the specified datasets.  The Status of the dataset group must be ACTIVE before you can use the dataset group to create a predictor. Use the DescribeDatasetGroup operation to get the status.
    @Sendable
    @inlinable
    public func updateDatasetGroup(_ input: UpdateDatasetGroupRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> UpdateDatasetGroupResponse {
        try await self.client.execute(
            operation: "UpdateDatasetGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Replaces the datasets in a dataset group with the specified datasets.  The Status of the dataset group must be ACTIVE before you can use the dataset group to create a predictor. Use the DescribeDatasetGroup operation to get the status.
    ///
    /// Parameters:
    ///   - datasetArns: An array of the Amazon Resource Names (ARNs) of the datasets to add to the dataset group.
    ///   - datasetGroupArn: The ARN of the dataset group.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateDatasetGroup(
        datasetArns: [String],
        datasetGroupArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> UpdateDatasetGroupResponse {
        let input = UpdateDatasetGroupRequest(
            datasetArns: datasetArns, 
            datasetGroupArn: datasetGroupArn
        )
        return try await self.updateDatasetGroup(input, logger: logger)
    }
}

extension Forecast {
    /// Initializer required by `AWSService.with(middlewares:timeout:byteBufferAllocator:options)`. You are not able to use this initializer directly as there are not public
    /// initializers for `AWSServiceConfig.Patch`. Please use `AWSService.with(middlewares:timeout:byteBufferAllocator:options)` instead.
    public init(from: Forecast, patch: AWSServiceConfig.Patch) {
        self.client = from.client
        self.config = from.config.with(patch: patch)
    }
}

// MARK: Paginators

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension Forecast {
    /// Return PaginatorSequence for operation ``listDatasetGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetGroupsPaginator(
        _ input: ListDatasetGroupsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListDatasetGroupsRequest, ListDatasetGroupsResponse> {
        return .init(
            input: input,
            command: self.listDatasetGroups,
            inputKey: \ListDatasetGroupsRequest.nextToken,
            outputKey: \ListDatasetGroupsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listDatasetGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetGroupsPaginator(
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListDatasetGroupsRequest, ListDatasetGroupsResponse> {
        let input = ListDatasetGroupsRequest(
            maxResults: maxResults
        )
        return self.listDatasetGroupsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listDatasetImportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetImportJobsPaginator(
        _ input: ListDatasetImportJobsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListDatasetImportJobsRequest, ListDatasetImportJobsResponse> {
        return .init(
            input: input,
            command: self.listDatasetImportJobs,
            inputKey: \ListDatasetImportJobsRequest.nextToken,
            outputKey: \ListDatasetImportJobsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listDatasetImportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the datasets that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the datasets that match the statement, specify IS. To exclude matching datasets, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetArn and Status.    Value - The value to match.   For example, to list all dataset import jobs whose status is ACTIVE, you specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetImportJobsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListDatasetImportJobsRequest, ListDatasetImportJobsResponse> {
        let input = ListDatasetImportJobsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listDatasetImportJobsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listDatasets(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetsPaginator(
        _ input: ListDatasetsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListDatasetsRequest, ListDatasetsResponse> {
        return .init(
            input: input,
            command: self.listDatasets,
            inputKey: \ListDatasetsRequest.nextToken,
            outputKey: \ListDatasetsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listDatasets(_:logger:)``.
    ///
    /// - Parameters:
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listDatasetsPaginator(
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListDatasetsRequest, ListDatasetsResponse> {
        let input = ListDatasetsRequest(
            maxResults: maxResults
        )
        return self.listDatasetsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listExplainabilities(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listExplainabilitiesPaginator(
        _ input: ListExplainabilitiesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListExplainabilitiesRequest, ListExplainabilitiesResponse> {
        return .init(
            input: input,
            command: self.listExplainabilities,
            inputKey: \ListExplainabilitiesRequest.nextToken,
            outputKey: \ListExplainabilitiesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listExplainabilities(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. Valid values are ResourceArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items returned in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listExplainabilitiesPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListExplainabilitiesRequest, ListExplainabilitiesResponse> {
        let input = ListExplainabilitiesRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listExplainabilitiesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listExplainabilityExports(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listExplainabilityExportsPaginator(
        _ input: ListExplainabilityExportsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListExplainabilityExportsRequest, ListExplainabilityExportsResponse> {
        return .init(
            input: input,
            command: self.listExplainabilityExports,
            inputKey: \ListExplainabilityExportsRequest.nextToken,
            outputKey: \ListExplainabilityExportsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listExplainabilityExports(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. Valid values are ResourceArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listExplainabilityExportsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListExplainabilityExportsRequest, ListExplainabilityExportsResponse> {
        let input = ListExplainabilityExportsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listExplainabilityExportsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listForecastExportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listForecastExportJobsPaginator(
        _ input: ListForecastExportJobsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListForecastExportJobsRequest, ListForecastExportJobsResponse> {
        return .init(
            input: input,
            command: self.listForecastExportJobs,
            inputKey: \ListForecastExportJobsRequest.nextToken,
            outputKey: \ListForecastExportJobsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listForecastExportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are ForecastArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityforecast, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "ForecastArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityforecast" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listForecastExportJobsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListForecastExportJobsRequest, ListForecastExportJobsResponse> {
        let input = ListForecastExportJobsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listForecastExportJobsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listForecasts(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listForecastsPaginator(
        _ input: ListForecastsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListForecastsRequest, ListForecastsResponse> {
        return .init(
            input: input,
            command: self.listForecasts,
            inputKey: \ListForecastsRequest.nextToken,
            outputKey: \ListForecastsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listForecasts(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the forecasts that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecasts that match the statement, specify IS. To exclude matching forecasts, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetGroupArn, PredictorArn, and Status.    Value - The value to match.   For example, to list all forecasts whose status is not ACTIVE, you would specify:  "Filters": [ { "Condition": "IS_NOT", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listForecastsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListForecastsRequest, ListForecastsResponse> {
        let input = ListForecastsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listForecastsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listMonitorEvaluations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listMonitorEvaluationsPaginator(
        _ input: ListMonitorEvaluationsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListMonitorEvaluationsRequest, ListMonitorEvaluationsResponse> {
        return .init(
            input: input,
            command: self.listMonitorEvaluations,
            inputKey: \ListMonitorEvaluationsRequest.nextToken,
            outputKey: \ListMonitorEvaluationsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listMonitorEvaluations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. The only valid value is  EvaluationState.    Value - The value to match. Valid values are only SUCCESS or FAILURE.   For example, to list only successful monitor evaluations, you would specify:  "Filters": [ { "Condition": "IS", "Key": "EvaluationState", "Value": "SUCCESS" } ]
    ///   - maxResults: The maximum number of monitoring results to return.
    ///   - monitorArn: The Amazon Resource Name (ARN) of the monitor resource to get results from.
    ///   - logger: Logger used for logging
    @inlinable
    public func listMonitorEvaluationsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        monitorArn: String,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListMonitorEvaluationsRequest, ListMonitorEvaluationsResponse> {
        let input = ListMonitorEvaluationsRequest(
            filters: filters, 
            maxResults: maxResults, 
            monitorArn: monitorArn
        )
        return self.listMonitorEvaluationsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listMonitors(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listMonitorsPaginator(
        _ input: ListMonitorsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListMonitorsRequest, ListMonitorsResponse> {
        return .init(
            input: input,
            command: self.listMonitors,
            inputKey: \ListMonitorsRequest.nextToken,
            outputKey: \ListMonitorsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listMonitors(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT.    Key - The name of the parameter to filter on. The only valid value is  Status.    Value - The value to match.   For example, to list all monitors who's status is ACTIVE, you would specify:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The maximum number of monitors to include in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listMonitorsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListMonitorsRequest, ListMonitorsResponse> {
        let input = ListMonitorsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listMonitorsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listPredictorBacktestExportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listPredictorBacktestExportJobsPaginator(
        _ input: ListPredictorBacktestExportJobsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListPredictorBacktestExportJobsRequest, ListPredictorBacktestExportJobsResponse> {
        return .init(
            input: input,
            command: self.listPredictorBacktestExportJobs,
            inputKey: \ListPredictorBacktestExportJobsRequest.nextToken,
            outputKey: \ListPredictorBacktestExportJobsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listPredictorBacktestExportJobs(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the predictor backtest export jobs that match the statement from the list. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the predictor backtest export jobs that match the statement, specify IS. To exclude matching predictor backtest export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are PredictorArn and Status.    Value - The value to match.
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listPredictorBacktestExportJobsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListPredictorBacktestExportJobsRequest, ListPredictorBacktestExportJobsResponse> {
        let input = ListPredictorBacktestExportJobsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listPredictorBacktestExportJobsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listPredictors(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listPredictorsPaginator(
        _ input: ListPredictorsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListPredictorsRequest, ListPredictorsResponse> {
        return .init(
            input: input,
            command: self.listPredictors,
            inputKey: \ListPredictorsRequest.nextToken,
            outputKey: \ListPredictorsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listPredictors(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the predictors that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the predictors that match the statement, specify IS. To exclude matching predictors, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are DatasetGroupArn and Status.    Value - The value to match.   For example, to list all predictors whose status is ACTIVE, you would specify:  "Filters": [ { "Condition": "IS", "Key": "Status", "Value": "ACTIVE" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listPredictorsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListPredictorsRequest, ListPredictorsResponse> {
        let input = ListPredictorsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listPredictorsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listWhatIfAnalyses(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfAnalysesPaginator(
        _ input: ListWhatIfAnalysesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListWhatIfAnalysesRequest, ListWhatIfAnalysesResponse> {
        return .init(
            input: input,
            command: self.listWhatIfAnalyses,
            inputKey: \ListWhatIfAnalysesRequest.nextToken,
            outputKey: \ListWhatIfAnalysesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listWhatIfAnalyses(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if analysis jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the what-if analysis jobs that match the statement, specify IS. To exclude matching what-if analysis jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfAnalysisArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWhatIf, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfAnalysisArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWhatIf" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfAnalysesPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListWhatIfAnalysesRequest, ListWhatIfAnalysesResponse> {
        let input = ListWhatIfAnalysesRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listWhatIfAnalysesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listWhatIfForecastExports(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfForecastExportsPaginator(
        _ input: ListWhatIfForecastExportsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListWhatIfForecastExportsRequest, ListWhatIfForecastExportsResponse> {
        return .init(
            input: input,
            command: self.listWhatIfForecastExports,
            inputKey: \ListWhatIfForecastExportsRequest.nextToken,
            outputKey: \ListWhatIfForecastExportsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listWhatIfForecastExports(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfForecastExportArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWIFExport, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfForecastExportArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWIFExport" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfForecastExportsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListWhatIfForecastExportsRequest, ListWhatIfForecastExportsResponse> {
        let input = ListWhatIfForecastExportsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listWhatIfForecastExportsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``listWhatIfForecasts(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfForecastsPaginator(
        _ input: ListWhatIfForecastsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<ListWhatIfForecastsRequest, ListWhatIfForecastsResponse> {
        return .init(
            input: input,
            command: self.listWhatIfForecasts,
            inputKey: \ListWhatIfForecastsRequest.nextToken,
            outputKey: \ListWhatIfForecastsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``listWhatIfForecasts(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: An array of filters. For each filter, you provide a condition and a match statement. The condition is either IS or IS_NOT, which specifies whether to include or exclude the what-if forecast export jobs that match the statement from the list, respectively. The match statement consists of a key and a value.  Filter properties     Condition - The condition to apply. Valid values are IS and IS_NOT. To include the forecast export jobs that match the statement, specify IS. To exclude matching forecast export jobs, specify IS_NOT.    Key - The name of the parameter to filter on. Valid values are WhatIfForecastArn and Status.    Value - The value to match.   For example, to list all jobs that export a forecast named electricityWhatIfForecast, specify the following filter:  "Filters": [ { "Condition": "IS", "Key": "WhatIfForecastArn", "Value": "arn:aws:forecast:us-west-2::forecast/electricityWhatIfForecast" } ]
    ///   - maxResults: The number of items to return in the response.
    ///   - logger: Logger used for logging
    @inlinable
    public func listWhatIfForecastsPaginator(
        filters: [Filter]? = nil,
        maxResults: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<ListWhatIfForecastsRequest, ListWhatIfForecastsResponse> {
        let input = ListWhatIfForecastsRequest(
            filters: filters, 
            maxResults: maxResults
        )
        return self.listWhatIfForecastsPaginator(input, logger: logger)
    }
}

extension Forecast.ListDatasetGroupsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListDatasetGroupsRequest {
        return .init(
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListDatasetImportJobsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListDatasetImportJobsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListDatasetsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListDatasetsRequest {
        return .init(
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListExplainabilitiesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListExplainabilitiesRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListExplainabilityExportsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListExplainabilityExportsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListForecastExportJobsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListForecastExportJobsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListForecastsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListForecastsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListMonitorEvaluationsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListMonitorEvaluationsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            monitorArn: self.monitorArn,
            nextToken: token
        )
    }
}

extension Forecast.ListMonitorsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListMonitorsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListPredictorBacktestExportJobsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListPredictorBacktestExportJobsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListPredictorsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListPredictorsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListWhatIfAnalysesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListWhatIfAnalysesRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListWhatIfForecastExportsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListWhatIfForecastExportsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}

extension Forecast.ListWhatIfForecastsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> Forecast.ListWhatIfForecastsRequest {
        return .init(
            filters: self.filters,
            maxResults: self.maxResults,
            nextToken: token
        )
    }
}
