//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2021 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

import Foundation
import SotoCore

extension MachineLearning {
    // MARK: Enums

    public enum Algorithm: String, CustomStringConvertible, Codable {
        case sgd
        public var description: String { return self.rawValue }
    }

    public enum BatchPredictionFilterVariable: String, CustomStringConvertible, Codable {
        case createdat = "CreatedAt"
        case datasourceid = "DataSourceId"
        case datauri = "DataURI"
        case iamuser = "IAMUser"
        case lastupdatedat = "LastUpdatedAt"
        case mlmodelid = "MLModelId"
        case name = "Name"
        case status = "Status"
        public var description: String { return self.rawValue }
    }

    public enum DataSourceFilterVariable: String, CustomStringConvertible, Codable {
        case createdat = "CreatedAt"
        case datalocations3 = "DataLocationS3"
        case iamuser = "IAMUser"
        case lastupdatedat = "LastUpdatedAt"
        case name = "Name"
        case status = "Status"
        public var description: String { return self.rawValue }
    }

    public enum DetailsAttributes: String, CustomStringConvertible, Codable {
        case algorithm = "Algorithm"
        case predictivemodeltype = "PredictiveModelType"
        public var description: String { return self.rawValue }
    }

    public enum EntityStatus: String, CustomStringConvertible, Codable {
        case completed = "COMPLETED"
        case deleted = "DELETED"
        case failed = "FAILED"
        case inprogress = "INPROGRESS"
        case pending = "PENDING"
        public var description: String { return self.rawValue }
    }

    public enum EvaluationFilterVariable: String, CustomStringConvertible, Codable {
        case createdat = "CreatedAt"
        case datasourceid = "DataSourceId"
        case datauri = "DataURI"
        case iamuser = "IAMUser"
        case lastupdatedat = "LastUpdatedAt"
        case mlmodelid = "MLModelId"
        case name = "Name"
        case status = "Status"
        public var description: String { return self.rawValue }
    }

    public enum MLModelFilterVariable: String, CustomStringConvertible, Codable {
        case algorithm = "Algorithm"
        case createdat = "CreatedAt"
        case iamuser = "IAMUser"
        case lastupdatedat = "LastUpdatedAt"
        case mlmodeltype = "MLModelType"
        case name = "Name"
        case realtimeendpointstatus = "RealtimeEndpointStatus"
        case status = "Status"
        case trainingdatasourceid = "TrainingDataSourceId"
        case trainingdatauri = "TrainingDataURI"
        public var description: String { return self.rawValue }
    }

    public enum MLModelType: String, CustomStringConvertible, Codable {
        case binary = "BINARY"
        case multiclass = "MULTICLASS"
        case regression = "REGRESSION"
        public var description: String { return self.rawValue }
    }

    public enum RealtimeEndpointStatus: String, CustomStringConvertible, Codable {
        case failed = "FAILED"
        case none = "NONE"
        case ready = "READY"
        case updating = "UPDATING"
        public var description: String { return self.rawValue }
    }

    public enum SortOrder: String, CustomStringConvertible, Codable {
        case asc
        case dsc
        public var description: String { return self.rawValue }
    }

    public enum TaggableResourceType: String, CustomStringConvertible, Codable {
        case batchprediction = "BatchPrediction"
        case datasource = "DataSource"
        case evaluation = "Evaluation"
        case mlmodel = "MLModel"
        public var description: String { return self.rawValue }
    }

    // MARK: Shapes

    public struct AddTagsInput: AWSEncodableShape {
        /// The ID of the ML object to tag. For example, exampleModelId.
        public let resourceId: String
        /// The type of the ML object to tag.
        public let resourceType: TaggableResourceType
        /// The key-value pairs to use to create tags. If you specify a key without specifying a value, Amazon ML creates a tag with the specified key and a value of null.
        public let tags: [Tag]

        public init(resourceId: String, resourceType: TaggableResourceType, tags: [Tag]) {
            self.resourceId = resourceId
            self.resourceType = resourceType
            self.tags = tags
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceId, name: "resourceId", parent: name, max: 64)
            try self.validate(self.resourceId, name: "resourceId", parent: name, min: 1)
            try self.validate(self.resourceId, name: "resourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.tags.forEach {
                try $0.validate(name: "\(name).tags[]")
            }
            try self.validate(self.tags, name: "tags", parent: name, max: 100)
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
            case tags = "Tags"
        }
    }

    public struct AddTagsOutput: AWSDecodableShape {
        /// The ID of the ML object that was tagged.
        public let resourceId: String?
        /// The type of the ML object that was tagged.
        public let resourceType: TaggableResourceType?

        public init(resourceId: String? = nil, resourceType: TaggableResourceType? = nil) {
            self.resourceId = resourceId
            self.resourceType = resourceType
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
        }
    }

    public struct BatchPrediction: AWSDecodableShape {
        /// The ID of the DataSource that points to the group of observations to predict.
        public let batchPredictionDataSourceId: String?
        /// The ID assigned to the BatchPrediction at creation. This value should be identical to the value of the BatchPredictionID  in the request.
        public let batchPredictionId: String?
        public let computeTime: Int64?
        /// The time that the BatchPrediction was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account that invoked the BatchPrediction. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        public let finishedAt: Date?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let inputDataLocationS3: String?
        public let invalidRecordCount: Int64?
        /// The time of the most recent edit to the BatchPrediction. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A description of the most recent details about processing the batch prediction request.
        public let message: String?
        /// The ID of the MLModel that generated predictions for the BatchPrediction request.
        public let mLModelId: String?
        /// A user-supplied name or description of the BatchPrediction.
        public let name: String?
        /// The location of an Amazon S3 bucket or directory to receive the operation results. The following substrings are not allowed in the s3 key portion of the outputURI field: ':', '//', '/./', '/../'.
        public let outputUri: String?
        public let startedAt: Date?
        /// The status of the BatchPrediction. This element can have one of the following values:    PENDING - Amazon Machine Learning (Amazon ML) submitted a request to generate predictions for a batch of observations.    INPROGRESS - The process is underway.    FAILED - The request to perform a batch prediction did not run to completion. It is not usable.    COMPLETED - The batch prediction process completed successfully.    DELETED - The BatchPrediction is marked as deleted. It is not usable.
        public let status: EntityStatus?
        public let totalRecordCount: Int64?

        public init(batchPredictionDataSourceId: String? = nil, batchPredictionId: String? = nil, computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, invalidRecordCount: Int64? = nil, lastUpdatedAt: Date? = nil, message: String? = nil, mLModelId: String? = nil, name: String? = nil, outputUri: String? = nil, startedAt: Date? = nil, status: EntityStatus? = nil, totalRecordCount: Int64? = nil) {
            self.batchPredictionDataSourceId = batchPredictionDataSourceId
            self.batchPredictionId = batchPredictionId
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.invalidRecordCount = invalidRecordCount
            self.lastUpdatedAt = lastUpdatedAt
            self.message = message
            self.mLModelId = mLModelId
            self.name = name
            self.outputUri = outputUri
            self.startedAt = startedAt
            self.status = status
            self.totalRecordCount = totalRecordCount
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionDataSourceId = "BatchPredictionDataSourceId"
            case batchPredictionId = "BatchPredictionId"
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case invalidRecordCount = "InvalidRecordCount"
            case lastUpdatedAt = "LastUpdatedAt"
            case message = "Message"
            case mLModelId = "MLModelId"
            case name = "Name"
            case outputUri = "OutputUri"
            case startedAt = "StartedAt"
            case status = "Status"
            case totalRecordCount = "TotalRecordCount"
        }
    }

    public struct CreateBatchPredictionInput: AWSEncodableShape {
        /// The ID of the DataSource that points to the group of observations to predict.
        public let batchPredictionDataSourceId: String
        /// A user-supplied ID that uniquely identifies the BatchPrediction.
        public let batchPredictionId: String
        /// A user-supplied name or description of the BatchPrediction. BatchPredictionName can only use the UTF-8 character set.
        public let batchPredictionName: String?
        /// The ID of the MLModel that will generate predictions for the group of observations.
        public let mLModelId: String
        /// The location of an Amazon Simple Storage Service (Amazon S3) bucket or directory to store the batch prediction results. The following substrings are not allowed in the s3 key portion of the outputURI field: ':', '//', '/./', '/../'.  Amazon ML needs permissions to store and retrieve the logs on your behalf. For information about how to set permissions, see the Amazon Machine Learning Developer Guide.
        public let outputUri: String

        public init(batchPredictionDataSourceId: String, batchPredictionId: String, batchPredictionName: String? = nil, mLModelId: String, outputUri: String) {
            self.batchPredictionDataSourceId = batchPredictionDataSourceId
            self.batchPredictionId = batchPredictionId
            self.batchPredictionName = batchPredictionName
            self.mLModelId = mLModelId
            self.outputUri = outputUri
        }

        public func validate(name: String) throws {
            try self.validate(self.batchPredictionDataSourceId, name: "batchPredictionDataSourceId", parent: name, max: 64)
            try self.validate(self.batchPredictionDataSourceId, name: "batchPredictionDataSourceId", parent: name, min: 1)
            try self.validate(self.batchPredictionDataSourceId, name: "batchPredictionDataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, max: 64)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, min: 1)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.batchPredictionName, name: "batchPredictionName", parent: name, max: 1024)
            try self.validate(self.batchPredictionName, name: "batchPredictionName", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.outputUri, name: "outputUri", parent: name, max: 2048)
            try self.validate(self.outputUri, name: "outputUri", parent: name, pattern: "s3://([^/]+)(/.*)?")
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionDataSourceId = "BatchPredictionDataSourceId"
            case batchPredictionId = "BatchPredictionId"
            case batchPredictionName = "BatchPredictionName"
            case mLModelId = "MLModelId"
            case outputUri = "OutputUri"
        }
    }

    public struct CreateBatchPredictionOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the BatchPrediction. This value is identical to the value of the  BatchPredictionId in the request.
        public let batchPredictionId: String?

        public init(batchPredictionId: String? = nil) {
            self.batchPredictionId = batchPredictionId
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
        }
    }

    public struct CreateDataSourceFromRDSInput: AWSEncodableShape {
        /// The compute statistics for a DataSource. The statistics are generated from the observation data referenced by  a DataSource. Amazon ML uses the statistics internally during MLModel training. This parameter must be set to true if the DataSource needs to be used for MLModel training.
        public let computeStatistics: Bool?
        /// A user-supplied ID that uniquely identifies the DataSource. Typically, an Amazon Resource Number (ARN)  becomes the ID for a DataSource.
        public let dataSourceId: String
        /// A user-supplied name or description of the DataSource.
        public let dataSourceName: String?
        /// The data specification of an Amazon RDS DataSource:   DatabaseInformation -    DatabaseName - The name of the Amazon RDS database.    InstanceIdentifier  - A unique identifier for the Amazon RDS database instance.     DatabaseCredentials - AWS Identity and Access Management (IAM) credentials that are used to connect to the Amazon RDS database.   ResourceRole - A role (DataPipelineDefaultResourceRole) assumed by an EC2 instance to carry out the copy task from Amazon RDS to Amazon
        /// 			Simple Storage Service (Amazon S3). For more information, see Role templates for data pipelines.   ServiceRole - A role (DataPipelineDefaultRole) assumed by the AWS Data Pipeline service to monitor the progress of the copy task from Amazon RDS
        /// 			to Amazon S3. For more information, see Role templates for data pipelines.   SecurityInfo - The security information to use to access an RDS DB instance. You need to set up appropriate ingress rules for the security entity IDs provided to allow access to the Amazon RDS instance. Specify a [SubnetId, SecurityGroupIds] pair for a VPC-based RDS DB instance.   SelectSqlQuery - A query that is used to retrieve the observation data for the Datasource.   S3StagingLocation - The Amazon S3 location for staging Amazon RDS data. The data retrieved from Amazon RDS using SelectSqlQuery is stored in this location.   DataSchemaUri - The Amazon S3 location of the DataSchema.   DataSchema - A JSON string representing the schema. This is not required if DataSchemaUri is specified.    DataRearrangement - A JSON string that represents the splitting and rearrangement requirements for the Datasource.  Sample -  "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"
        public let rDSData: RDSDataSpec
        /// The role that Amazon ML assumes on behalf of the user to create and activate a data pipeline in the user's account and copy data using the SelectSqlQuery query from Amazon RDS to Amazon S3.
        public let roleARN: String

        public init(computeStatistics: Bool? = nil, dataSourceId: String, dataSourceName: String? = nil, rDSData: RDSDataSpec, roleARN: String) {
            self.computeStatistics = computeStatistics
            self.dataSourceId = dataSourceId
            self.dataSourceName = dataSourceName
            self.rDSData = rDSData
            self.roleARN = roleARN
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, max: 1024)
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, pattern: ".*\\S.*|^$")
            try self.rDSData.validate(name: "\(name).rDSData")
            try self.validate(self.roleARN, name: "roleARN", parent: name, max: 110)
            try self.validate(self.roleARN, name: "roleARN", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case computeStatistics = "ComputeStatistics"
            case dataSourceId = "DataSourceId"
            case dataSourceName = "DataSourceName"
            case rDSData = "RDSData"
            case roleARN = "RoleARN"
        }
    }

    public struct CreateDataSourceFromRDSOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the datasource. This value should be identical to the value of the  DataSourceID in the request.
        public let dataSourceId: String?

        public init(dataSourceId: String? = nil) {
            self.dataSourceId = dataSourceId
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct CreateDataSourceFromRedshiftInput: AWSEncodableShape {
        /// The compute statistics for a DataSource. The statistics are generated from the observation data referenced by  a DataSource. Amazon ML uses the statistics internally during MLModel training. This parameter must be set to true if the DataSource needs to be used for MLModel training.
        public let computeStatistics: Bool?
        /// A user-supplied ID that uniquely identifies the DataSource.
        public let dataSourceId: String
        /// A user-supplied name or description of the DataSource.
        public let dataSourceName: String?
        /// The data specification of an Amazon Redshift DataSource:   DatabaseInformation -     DatabaseName - The name of the Amazon Redshift database.    ClusterIdentifier - The unique ID for the Amazon Redshift cluster.     DatabaseCredentials - The AWS Identity and Access Management (IAM) credentials that are used to connect to the Amazon Redshift database.   SelectSqlQuery - The query that is used to retrieve the observation data for the
        /// 			Datasource.   S3StagingLocation - The Amazon Simple Storage Service (Amazon S3) location for staging Amazon Redshift data. The data retrieved from Amazon Redshift using the SelectSqlQuery query is stored in this location.   DataSchemaUri - The Amazon S3 location of the DataSchema.   DataSchema - A JSON string representing the schema. This is not required if DataSchemaUri is specified.    DataRearrangement - A JSON string that represents the splitting and rearrangement requirements for the DataSource. Sample -  "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"
        public let dataSpec: RedshiftDataSpec
        /// A fully specified role Amazon Resource Name (ARN). Amazon ML assumes the role on behalf of the user to create the following:    A security group to allow Amazon ML to execute the SelectSqlQuery query on an Amazon Redshift cluster   An Amazon S3 bucket policy to grant Amazon ML read/write permissions on the S3StagingLocation
        public let roleARN: String

        public init(computeStatistics: Bool? = nil, dataSourceId: String, dataSourceName: String? = nil, dataSpec: RedshiftDataSpec, roleARN: String) {
            self.computeStatistics = computeStatistics
            self.dataSourceId = dataSourceId
            self.dataSourceName = dataSourceName
            self.dataSpec = dataSpec
            self.roleARN = roleARN
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, max: 1024)
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, pattern: ".*\\S.*|^$")
            try self.dataSpec.validate(name: "\(name).dataSpec")
            try self.validate(self.roleARN, name: "roleARN", parent: name, max: 110)
            try self.validate(self.roleARN, name: "roleARN", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case computeStatistics = "ComputeStatistics"
            case dataSourceId = "DataSourceId"
            case dataSourceName = "DataSourceName"
            case dataSpec = "DataSpec"
            case roleARN = "RoleARN"
        }
    }

    public struct CreateDataSourceFromRedshiftOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the datasource. This value should be identical to the value of the  DataSourceID in the request.
        public let dataSourceId: String?

        public init(dataSourceId: String? = nil) {
            self.dataSourceId = dataSourceId
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct CreateDataSourceFromS3Input: AWSEncodableShape {
        /// The compute statistics for a DataSource. The statistics are generated from the observation data referenced by  a DataSource. Amazon ML uses the statistics internally during MLModel training. This parameter must be set to true if the DataSource needs to be used for MLModel training.
        public let computeStatistics: Bool?
        /// A user-supplied identifier that uniquely identifies the DataSource.
        public let dataSourceId: String
        /// A user-supplied name or description of the DataSource.
        public let dataSourceName: String?
        /// The data specification of a DataSource:   DataLocationS3 - The Amazon S3 location of the observation data.   DataSchemaLocationS3 - The Amazon S3 location of the DataSchema.   DataSchema - A JSON string representing the schema. This is not required if DataSchemaUri is specified.    DataRearrangement - A JSON string that represents the splitting and rearrangement requirements for the Datasource.  Sample -  "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"
        public let dataSpec: S3DataSpec

        public init(computeStatistics: Bool? = nil, dataSourceId: String, dataSourceName: String? = nil, dataSpec: S3DataSpec) {
            self.computeStatistics = computeStatistics
            self.dataSourceId = dataSourceId
            self.dataSourceName = dataSourceName
            self.dataSpec = dataSpec
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, max: 1024)
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, pattern: ".*\\S.*|^$")
            try self.dataSpec.validate(name: "\(name).dataSpec")
        }

        private enum CodingKeys: String, CodingKey {
            case computeStatistics = "ComputeStatistics"
            case dataSourceId = "DataSourceId"
            case dataSourceName = "DataSourceName"
            case dataSpec = "DataSpec"
        }
    }

    public struct CreateDataSourceFromS3Output: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the DataSource. This value should be identical to the value of the  DataSourceID in the request.
        public let dataSourceId: String?

        public init(dataSourceId: String? = nil) {
            self.dataSourceId = dataSourceId
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct CreateEvaluationInput: AWSEncodableShape {
        /// The ID of the DataSource for the evaluation. The schema of the DataSource  must match the schema used to create the MLModel.
        public let evaluationDataSourceId: String
        /// A user-supplied ID that uniquely identifies the Evaluation.
        public let evaluationId: String
        /// A user-supplied name or description of the Evaluation.
        public let evaluationName: String?
        /// The ID of the MLModel to evaluate.  The schema used in creating the MLModel must match the schema of the DataSource used in the Evaluation.
        public let mLModelId: String

        public init(evaluationDataSourceId: String, evaluationId: String, evaluationName: String? = nil, mLModelId: String) {
            self.evaluationDataSourceId = evaluationDataSourceId
            self.evaluationId = evaluationId
            self.evaluationName = evaluationName
            self.mLModelId = mLModelId
        }

        public func validate(name: String) throws {
            try self.validate(self.evaluationDataSourceId, name: "evaluationDataSourceId", parent: name, max: 64)
            try self.validate(self.evaluationDataSourceId, name: "evaluationDataSourceId", parent: name, min: 1)
            try self.validate(self.evaluationDataSourceId, name: "evaluationDataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, max: 64)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, min: 1)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.evaluationName, name: "evaluationName", parent: name, max: 1024)
            try self.validate(self.evaluationName, name: "evaluationName", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationDataSourceId = "EvaluationDataSourceId"
            case evaluationId = "EvaluationId"
            case evaluationName = "EvaluationName"
            case mLModelId = "MLModelId"
        }
    }

    public struct CreateEvaluationOutput: AWSDecodableShape {
        /// The user-supplied ID that uniquely identifies the Evaluation. This value should be identical to the value of the  EvaluationId in the request.
        public let evaluationId: String?

        public init(evaluationId: String? = nil) {
            self.evaluationId = evaluationId
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
        }
    }

    public struct CreateMLModelInput: AWSEncodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel.
        public let mLModelId: String
        /// A user-supplied name or description of the MLModel.
        public let mLModelName: String?
        /// The category of supervised learning that this MLModel will address. Choose from the following types:   Choose REGRESSION if the MLModel will be used to predict a numeric value.   Choose BINARY if the MLModel result has two possible values.   Choose MULTICLASS if the MLModel result has a limited number of values.    For more information, see the Amazon Machine Learning Developer Guide.
        public let mLModelType: MLModelType
        /// A list of the training parameters in the MLModel. The list is implemented as a map of key-value pairs. The following is the current set of training parameters:    sgd.maxMLModelSizeInBytes - The maximum allowed size of the model. Depending on the input data, the size of the model might affect its performance.  The value is an integer that ranges from 100000 to 2147483648. The default value is 33554432.    sgd.maxPasses - The number of times that the training process traverses the observations to build the MLModel. The value is an integer that ranges from 1 to 10000. The default value is 10.    sgd.shuffleType - Whether Amazon ML shuffles the training data. Shuffling the data improves a model's ability to find the optimal solution for a variety of data types. The valid values are auto and none. The default value is none. We strongly recommend that you shuffle your data.    sgd.l1RegularizationAmount - The coefficient regularization L1 norm. It controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to zero, resulting in a sparse feature set. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L1 normalization. This parameter can't be used when L2 is specified. Use this parameter sparingly.    sgd.l2RegularizationAmount - The coefficient regularization L2 norm. It controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to small, nonzero values. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L2 normalization. This parameter can't be used when L1 is specified. Use this parameter sparingly.
        public let parameters: [String: String]?
        /// The data recipe for creating the MLModel. You must specify either the recipe or its URI. If you don't specify a recipe or its URI, Amazon ML creates a default.
        public let recipe: String?
        /// The Amazon Simple Storage Service (Amazon S3) location and file name that contains the MLModel recipe. You must specify either the recipe or its URI. If you don't specify a recipe or its URI, Amazon ML creates a default.
        public let recipeUri: String?
        /// The DataSource that points to the training data.
        public let trainingDataSourceId: String

        public init(mLModelId: String, mLModelName: String? = nil, mLModelType: MLModelType, parameters: [String: String]? = nil, recipe: String? = nil, recipeUri: String? = nil, trainingDataSourceId: String) {
            self.mLModelId = mLModelId
            self.mLModelName = mLModelName
            self.mLModelType = mLModelType
            self.parameters = parameters
            self.recipe = recipe
            self.recipeUri = recipeUri
            self.trainingDataSourceId = trainingDataSourceId
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.mLModelName, name: "mLModelName", parent: name, max: 1024)
            try self.validate(self.mLModelName, name: "mLModelName", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.recipe, name: "recipe", parent: name, max: 131_071)
            try self.validate(self.recipeUri, name: "recipeUri", parent: name, max: 2048)
            try self.validate(self.recipeUri, name: "recipeUri", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.validate(self.trainingDataSourceId, name: "trainingDataSourceId", parent: name, max: 64)
            try self.validate(self.trainingDataSourceId, name: "trainingDataSourceId", parent: name, min: 1)
            try self.validate(self.trainingDataSourceId, name: "trainingDataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case mLModelName = "MLModelName"
            case mLModelType = "MLModelType"
            case parameters = "Parameters"
            case recipe = "Recipe"
            case recipeUri = "RecipeUri"
            case trainingDataSourceId = "TrainingDataSourceId"
        }
    }

    public struct CreateMLModelOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel. This value should be identical to the value of the  MLModelId in the request.
        public let mLModelId: String?

        public init(mLModelId: String? = nil) {
            self.mLModelId = mLModelId
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }

    public struct CreateRealtimeEndpointInput: AWSEncodableShape {
        /// The ID assigned to the MLModel during creation.
        public let mLModelId: String

        public init(mLModelId: String) {
            self.mLModelId = mLModelId
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }

    public struct CreateRealtimeEndpointOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel. This value should be identical to the value of the  MLModelId in the request.
        public let mLModelId: String?
        /// The endpoint information of the MLModel
        public let realtimeEndpointInfo: RealtimeEndpointInfo?

        public init(mLModelId: String? = nil, realtimeEndpointInfo: RealtimeEndpointInfo? = nil) {
            self.mLModelId = mLModelId
            self.realtimeEndpointInfo = realtimeEndpointInfo
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case realtimeEndpointInfo = "RealtimeEndpointInfo"
        }
    }

    public struct DataSource: AWSDecodableShape {
        ///  The parameter is true if statistics need to be generated from the observation data.
        public let computeStatistics: Bool?
        public let computeTime: Int64?
        /// The time that the DataSource was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account from which the DataSource was created. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The location and name of the data in Amazon Simple Storage Service (Amazon S3) that is used by a DataSource.
        public let dataLocationS3: String?
        /// A JSON string that represents the splitting and rearrangement requirement used when this DataSource was created.
        public let dataRearrangement: String?
        /// The total number of observations contained in the data files that the DataSource references.
        public let dataSizeInBytes: Int64?
        /// The ID that is assigned to the DataSource during creation.
        public let dataSourceId: String?
        public let finishedAt: Date?
        /// The time of the most recent edit to the  BatchPrediction. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A description of the most recent details about creating the DataSource.
        public let message: String?
        /// A user-supplied name or description of the DataSource.
        public let name: String?
        /// The number of data files referenced by the DataSource.
        public let numberOfFiles: Int64?
        public let rDSMetadata: RDSMetadata?
        public let redshiftMetadata: RedshiftMetadata?
        public let roleARN: String?
        public let startedAt: Date?
        /// The current status of the DataSource. This element can have one of the following values:    PENDING	- Amazon Machine Learning (Amazon ML) submitted a request to create a DataSource.   INPROGRESS - The creation process is underway.   FAILED - The request to create a DataSource did not run to completion. It is not usable.   COMPLETED - The creation process completed successfully.   DELETED	- The DataSource is marked as deleted. It is not usable.
        public let status: EntityStatus?

        public init(computeStatistics: Bool? = nil, computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, dataLocationS3: String? = nil, dataRearrangement: String? = nil, dataSizeInBytes: Int64? = nil, dataSourceId: String? = nil, finishedAt: Date? = nil, lastUpdatedAt: Date? = nil, message: String? = nil, name: String? = nil, numberOfFiles: Int64? = nil, rDSMetadata: RDSMetadata? = nil, redshiftMetadata: RedshiftMetadata? = nil, roleARN: String? = nil, startedAt: Date? = nil, status: EntityStatus? = nil) {
            self.computeStatistics = computeStatistics
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.dataLocationS3 = dataLocationS3
            self.dataRearrangement = dataRearrangement
            self.dataSizeInBytes = dataSizeInBytes
            self.dataSourceId = dataSourceId
            self.finishedAt = finishedAt
            self.lastUpdatedAt = lastUpdatedAt
            self.message = message
            self.name = name
            self.numberOfFiles = numberOfFiles
            self.rDSMetadata = rDSMetadata
            self.redshiftMetadata = redshiftMetadata
            self.roleARN = roleARN
            self.startedAt = startedAt
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case computeStatistics = "ComputeStatistics"
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case dataLocationS3 = "DataLocationS3"
            case dataRearrangement = "DataRearrangement"
            case dataSizeInBytes = "DataSizeInBytes"
            case dataSourceId = "DataSourceId"
            case finishedAt = "FinishedAt"
            case lastUpdatedAt = "LastUpdatedAt"
            case message = "Message"
            case name = "Name"
            case numberOfFiles = "NumberOfFiles"
            case rDSMetadata = "RDSMetadata"
            case redshiftMetadata = "RedshiftMetadata"
            case roleARN = "RoleARN"
            case startedAt = "StartedAt"
            case status = "Status"
        }
    }

    public struct DeleteBatchPredictionInput: AWSEncodableShape {
        /// A user-supplied ID that uniquely identifies the BatchPrediction.
        public let batchPredictionId: String

        public init(batchPredictionId: String) {
            self.batchPredictionId = batchPredictionId
        }

        public func validate(name: String) throws {
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, max: 64)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, min: 1)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
        }
    }

    public struct DeleteBatchPredictionOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the BatchPrediction. This value should be identical to the value of the BatchPredictionID in the request.
        public let batchPredictionId: String?

        public init(batchPredictionId: String? = nil) {
            self.batchPredictionId = batchPredictionId
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
        }
    }

    public struct DeleteDataSourceInput: AWSEncodableShape {
        /// A user-supplied ID that uniquely identifies the DataSource.
        public let dataSourceId: String

        public init(dataSourceId: String) {
            self.dataSourceId = dataSourceId
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct DeleteDataSourceOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the DataSource. This value should be identical to the value of the DataSourceID in the request.
        public let dataSourceId: String?

        public init(dataSourceId: String? = nil) {
            self.dataSourceId = dataSourceId
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct DeleteEvaluationInput: AWSEncodableShape {
        /// A user-supplied ID that uniquely identifies the Evaluation to delete.
        public let evaluationId: String

        public init(evaluationId: String) {
            self.evaluationId = evaluationId
        }

        public func validate(name: String) throws {
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, max: 64)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, min: 1)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
        }
    }

    public struct DeleteEvaluationOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the Evaluation. This value should be identical to the value of the EvaluationId in the request.
        public let evaluationId: String?

        public init(evaluationId: String? = nil) {
            self.evaluationId = evaluationId
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
        }
    }

    public struct DeleteMLModelInput: AWSEncodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel.
        public let mLModelId: String

        public init(mLModelId: String) {
            self.mLModelId = mLModelId
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }

    public struct DeleteMLModelOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel. This value should be identical to the value of the MLModelID in the request.
        public let mLModelId: String?

        public init(mLModelId: String? = nil) {
            self.mLModelId = mLModelId
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }

    public struct DeleteRealtimeEndpointInput: AWSEncodableShape {
        /// The ID assigned to the MLModel during creation.
        public let mLModelId: String

        public init(mLModelId: String) {
            self.mLModelId = mLModelId
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }

    public struct DeleteRealtimeEndpointOutput: AWSDecodableShape {
        /// A user-supplied ID that uniquely identifies the MLModel. This value should be identical to the value of the  MLModelId in the request.
        public let mLModelId: String?
        /// The endpoint information of the MLModel
        public let realtimeEndpointInfo: RealtimeEndpointInfo?

        public init(mLModelId: String? = nil, realtimeEndpointInfo: RealtimeEndpointInfo? = nil) {
            self.mLModelId = mLModelId
            self.realtimeEndpointInfo = realtimeEndpointInfo
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case realtimeEndpointInfo = "RealtimeEndpointInfo"
        }
    }

    public struct DeleteTagsInput: AWSEncodableShape {
        /// The ID of the tagged ML object. For example, exampleModelId.
        public let resourceId: String
        /// The type of the tagged ML object.
        public let resourceType: TaggableResourceType
        /// One or more tags to delete.
        public let tagKeys: [String]

        public init(resourceId: String, resourceType: TaggableResourceType, tagKeys: [String]) {
            self.resourceId = resourceId
            self.resourceType = resourceType
            self.tagKeys = tagKeys
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceId, name: "resourceId", parent: name, max: 64)
            try self.validate(self.resourceId, name: "resourceId", parent: name, min: 1)
            try self.validate(self.resourceId, name: "resourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.tagKeys.forEach {
                try validate($0, name: "tagKeys[]", parent: name, max: 128)
                try validate($0, name: "tagKeys[]", parent: name, min: 1)
                try validate($0, name: "tagKeys[]", parent: name, pattern: "^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$")
            }
            try self.validate(self.tagKeys, name: "tagKeys", parent: name, max: 100)
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
            case tagKeys = "TagKeys"
        }
    }

    public struct DeleteTagsOutput: AWSDecodableShape {
        /// The ID of the ML object from which tags were deleted.
        public let resourceId: String?
        /// The type of the ML object from which tags were deleted.
        public let resourceType: TaggableResourceType?

        public init(resourceId: String? = nil, resourceType: TaggableResourceType? = nil) {
            self.resourceId = resourceId
            self.resourceType = resourceType
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
        }
    }

    public struct DescribeBatchPredictionsInput: AWSEncodableShape {
        /// The equal to operator. The BatchPrediction results will have  FilterVariable values that exactly match the value specified with EQ.
        public let eq: String?
        /// Use one of the following variables to filter a list of BatchPrediction:    CreatedAt - Sets the search criteria to the BatchPrediction creation date.    Status - Sets the search criteria to the BatchPrediction status.    Name - Sets the search criteria to the contents of the BatchPrediction  Name.    IAMUser - Sets the search criteria to the user account that invoked the BatchPrediction creation.    MLModelId - Sets the search criteria to the MLModel used in the BatchPrediction.    DataSourceId - Sets the search criteria to the DataSource used in the BatchPrediction.    DataURI - Sets the search criteria to the data file(s) used in the BatchPrediction. The URL can identify either a file or an Amazon Simple Storage Solution (Amazon S3) bucket or directory.
        public let filterVariable: BatchPredictionFilterVariable?
        /// The greater than or equal to operator. The BatchPrediction results will have FilterVariable values that are greater than or equal to the value specified with GE.
        public let ge: String?
        /// The greater than operator. The BatchPrediction results will  have FilterVariable values that are greater than the value specified with GT.
        public let gt: String?
        /// The less than or equal to operator. The BatchPrediction results will have FilterVariable values that are less than or equal to the value specified with LE.
        public let le: String?
        /// The number of pages of information to include in the result. The range of acceptable values is 1 through 100. The default value is 100.
        public let limit: Int?
        /// The less than operator. The BatchPrediction results will  have FilterVariable values that are less than the value specified with LT.
        public let lt: String?
        /// The not equal to operator. The BatchPrediction results will have FilterVariable values not equal to the value specified with NE.
        public let ne: String?
        /// An ID of the page in the paginated results.
        public let nextToken: String?
        /// A string that is found at the beginning of a variable, such as Name or Id.  For example, a Batch Prediction operation could have the Name  2014-09-09-HolidayGiftMailer. To search for  this BatchPrediction, select Name for the FilterVariable and any of the following strings for the  Prefix:     2014-09   2014-09-09   2014-09-09-Holiday
        public let prefix: String?
        /// A two-value parameter that determines the sequence of the resulting list of MLModels.    asc - Arranges the list in ascending order (A-Z, 0-9).    dsc - Arranges the list in descending order (Z-A, 9-0).   Results are sorted by FilterVariable.
        public let sortOrder: SortOrder?

        public init(eq: String? = nil, filterVariable: BatchPredictionFilterVariable? = nil, ge: String? = nil, gt: String? = nil, le: String? = nil, limit: Int? = nil, lt: String? = nil, ne: String? = nil, nextToken: String? = nil, prefix: String? = nil, sortOrder: SortOrder? = nil) {
            self.eq = eq
            self.filterVariable = filterVariable
            self.ge = ge
            self.gt = gt
            self.le = le
            self.limit = limit
            self.lt = lt
            self.ne = ne
            self.nextToken = nextToken
            self.prefix = prefix
            self.sortOrder = sortOrder
        }

        public func validate(name: String) throws {
            try self.validate(self.eq, name: "eq", parent: name, max: 1024)
            try self.validate(self.eq, name: "eq", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ge, name: "ge", parent: name, max: 1024)
            try self.validate(self.ge, name: "ge", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.gt, name: "gt", parent: name, max: 1024)
            try self.validate(self.gt, name: "gt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.le, name: "le", parent: name, max: 1024)
            try self.validate(self.le, name: "le", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.limit, name: "limit", parent: name, max: 100)
            try self.validate(self.limit, name: "limit", parent: name, min: 1)
            try self.validate(self.lt, name: "lt", parent: name, max: 1024)
            try self.validate(self.lt, name: "lt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ne, name: "ne", parent: name, max: 1024)
            try self.validate(self.ne, name: "ne", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.prefix, name: "prefix", parent: name, max: 1024)
            try self.validate(self.prefix, name: "prefix", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case eq = "EQ"
            case filterVariable = "FilterVariable"
            case ge = "GE"
            case gt = "GT"
            case le = "LE"
            case limit = "Limit"
            case lt = "LT"
            case ne = "NE"
            case nextToken = "NextToken"
            case prefix = "Prefix"
            case sortOrder = "SortOrder"
        }
    }

    public struct DescribeBatchPredictionsOutput: AWSDecodableShape {
        /// The ID of the next page in the paginated results that indicates at least one more page follows.
        public let nextToken: String?
        /// A list of BatchPrediction objects that meet the search criteria.
        public let results: [BatchPrediction]?

        public init(nextToken: String? = nil, results: [BatchPrediction]? = nil) {
            self.nextToken = nextToken
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case results = "Results"
        }
    }

    public struct DescribeDataSourcesInput: AWSEncodableShape {
        /// The equal to operator. The DataSource results will have  FilterVariable values that exactly match the value specified with EQ.
        public let eq: String?
        /// Use one of the following variables to filter a list of DataSource:    CreatedAt - Sets the search criteria to DataSource creation dates.    Status - Sets the search criteria to DataSource statuses.    Name - Sets the search criteria to the contents of DataSource  Name.    DataUri - Sets the search criteria to the URI of data files used to create the DataSource. The URI can identify either a file or an Amazon Simple Storage Service (Amazon S3) bucket or directory.    IAMUser - Sets the search criteria to the user account that invoked the DataSource creation.
        public let filterVariable: DataSourceFilterVariable?
        /// The greater than or equal to operator. The DataSource results will have FilterVariable values that are greater than or equal to the value specified with GE.
        public let ge: String?
        /// The greater than operator. The DataSource results will  have FilterVariable values that are greater than the value specified with GT.
        public let gt: String?
        /// The less than or equal to operator. The DataSource results will have FilterVariable values that are less than or equal to the value specified with LE.
        public let le: String?
        ///  The maximum number of DataSource to include in the result.
        public let limit: Int?
        /// The less than operator. The DataSource results will  have FilterVariable values that are less than the value specified with LT.
        public let lt: String?
        /// The not equal to operator. The DataSource results will have FilterVariable values not equal to the value specified with NE.
        public let ne: String?
        /// The ID of the page in the paginated results.
        public let nextToken: String?
        /// A string that is found at the beginning of a variable, such as Name or Id.  For example, a DataSource could have the Name  2014-09-09-HolidayGiftMailer. To search for  this DataSource, select Name for the FilterVariable and any of the following strings for the  Prefix:      2014-09   2014-09-09   2014-09-09-Holiday
        public let prefix: String?
        /// A two-value parameter that determines the sequence of the resulting list of DataSource.    asc - Arranges the list in ascending order (A-Z, 0-9).    dsc - Arranges the list in descending order (Z-A, 9-0).   Results are sorted by FilterVariable.
        public let sortOrder: SortOrder?

        public init(eq: String? = nil, filterVariable: DataSourceFilterVariable? = nil, ge: String? = nil, gt: String? = nil, le: String? = nil, limit: Int? = nil, lt: String? = nil, ne: String? = nil, nextToken: String? = nil, prefix: String? = nil, sortOrder: SortOrder? = nil) {
            self.eq = eq
            self.filterVariable = filterVariable
            self.ge = ge
            self.gt = gt
            self.le = le
            self.limit = limit
            self.lt = lt
            self.ne = ne
            self.nextToken = nextToken
            self.prefix = prefix
            self.sortOrder = sortOrder
        }

        public func validate(name: String) throws {
            try self.validate(self.eq, name: "eq", parent: name, max: 1024)
            try self.validate(self.eq, name: "eq", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ge, name: "ge", parent: name, max: 1024)
            try self.validate(self.ge, name: "ge", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.gt, name: "gt", parent: name, max: 1024)
            try self.validate(self.gt, name: "gt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.le, name: "le", parent: name, max: 1024)
            try self.validate(self.le, name: "le", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.limit, name: "limit", parent: name, max: 100)
            try self.validate(self.limit, name: "limit", parent: name, min: 1)
            try self.validate(self.lt, name: "lt", parent: name, max: 1024)
            try self.validate(self.lt, name: "lt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ne, name: "ne", parent: name, max: 1024)
            try self.validate(self.ne, name: "ne", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.prefix, name: "prefix", parent: name, max: 1024)
            try self.validate(self.prefix, name: "prefix", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case eq = "EQ"
            case filterVariable = "FilterVariable"
            case ge = "GE"
            case gt = "GT"
            case le = "LE"
            case limit = "Limit"
            case lt = "LT"
            case ne = "NE"
            case nextToken = "NextToken"
            case prefix = "Prefix"
            case sortOrder = "SortOrder"
        }
    }

    public struct DescribeDataSourcesOutput: AWSDecodableShape {
        /// An ID of the next page in the paginated results that indicates at least one more page follows.
        public let nextToken: String?
        /// A list of DataSource that meet the search criteria.
        public let results: [DataSource]?

        public init(nextToken: String? = nil, results: [DataSource]? = nil) {
            self.nextToken = nextToken
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case results = "Results"
        }
    }

    public struct DescribeEvaluationsInput: AWSEncodableShape {
        /// The equal to operator. The Evaluation results will have  FilterVariable values that exactly match the value specified with EQ.
        public let eq: String?
        /// Use one of the following variable to filter a list of Evaluation objects:       CreatedAt - Sets the search criteria to the Evaluation creation date.    Status - Sets the search criteria to the Evaluation status.    Name - Sets the search criteria to the contents of Evaluation   Name.    IAMUser - Sets the search criteria to the user account that invoked an Evaluation.    MLModelId - Sets the search criteria to the MLModel that was evaluated.    DataSourceId - Sets the search criteria to the DataSource used in Evaluation.    DataUri - Sets the search criteria to the data file(s) used in Evaluation. The URL can identify either a file or an Amazon Simple Storage Solution (Amazon S3) bucket or directory.
        public let filterVariable: EvaluationFilterVariable?
        /// The greater than or equal to operator. The Evaluation results will have FilterVariable values that are greater than or equal to the value specified with GE.
        public let ge: String?
        /// The greater than operator. The Evaluation results will  have FilterVariable values that are greater than the value specified with GT.
        public let gt: String?
        /// The less than or equal to operator. The Evaluation results will have FilterVariable values that are less than or equal to the value specified with LE.
        public let le: String?
        ///  The maximum number of Evaluation to include in the result.
        public let limit: Int?
        /// The less than operator. The Evaluation results will  have FilterVariable values that are less than the value specified with LT.
        public let lt: String?
        /// The not equal to operator. The Evaluation results will have FilterVariable values not equal to the value specified with NE.
        public let ne: String?
        /// The ID of the page in the paginated results.
        public let nextToken: String?
        /// A string that is found at the beginning of a variable, such as Name or Id.  For example, an Evaluation could have the Name  2014-09-09-HolidayGiftMailer. To search for  this Evaluation, select Name for the FilterVariable and any of the following strings for the  Prefix:      2014-09   2014-09-09   2014-09-09-Holiday
        public let prefix: String?
        /// A two-value parameter that determines the sequence of the resulting list of Evaluation.    asc - Arranges the list in ascending order (A-Z, 0-9).    dsc - Arranges the list in descending order (Z-A, 9-0).   Results are sorted by FilterVariable.
        public let sortOrder: SortOrder?

        public init(eq: String? = nil, filterVariable: EvaluationFilterVariable? = nil, ge: String? = nil, gt: String? = nil, le: String? = nil, limit: Int? = nil, lt: String? = nil, ne: String? = nil, nextToken: String? = nil, prefix: String? = nil, sortOrder: SortOrder? = nil) {
            self.eq = eq
            self.filterVariable = filterVariable
            self.ge = ge
            self.gt = gt
            self.le = le
            self.limit = limit
            self.lt = lt
            self.ne = ne
            self.nextToken = nextToken
            self.prefix = prefix
            self.sortOrder = sortOrder
        }

        public func validate(name: String) throws {
            try self.validate(self.eq, name: "eq", parent: name, max: 1024)
            try self.validate(self.eq, name: "eq", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ge, name: "ge", parent: name, max: 1024)
            try self.validate(self.ge, name: "ge", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.gt, name: "gt", parent: name, max: 1024)
            try self.validate(self.gt, name: "gt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.le, name: "le", parent: name, max: 1024)
            try self.validate(self.le, name: "le", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.limit, name: "limit", parent: name, max: 100)
            try self.validate(self.limit, name: "limit", parent: name, min: 1)
            try self.validate(self.lt, name: "lt", parent: name, max: 1024)
            try self.validate(self.lt, name: "lt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ne, name: "ne", parent: name, max: 1024)
            try self.validate(self.ne, name: "ne", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.prefix, name: "prefix", parent: name, max: 1024)
            try self.validate(self.prefix, name: "prefix", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case eq = "EQ"
            case filterVariable = "FilterVariable"
            case ge = "GE"
            case gt = "GT"
            case le = "LE"
            case limit = "Limit"
            case lt = "LT"
            case ne = "NE"
            case nextToken = "NextToken"
            case prefix = "Prefix"
            case sortOrder = "SortOrder"
        }
    }

    public struct DescribeEvaluationsOutput: AWSDecodableShape {
        /// The ID of the next page in the paginated results that indicates at least one more page follows.
        public let nextToken: String?
        /// A list of Evaluation that meet the search criteria.
        public let results: [Evaluation]?

        public init(nextToken: String? = nil, results: [Evaluation]? = nil) {
            self.nextToken = nextToken
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case results = "Results"
        }
    }

    public struct DescribeMLModelsInput: AWSEncodableShape {
        /// The equal to operator. The MLModel results will have  FilterVariable values that exactly match the value specified with EQ.
        public let eq: String?
        /// Use one of the following variables to filter a list of MLModel:    CreatedAt - Sets the search criteria to MLModel creation date.    Status - Sets the search criteria to MLModel status.    Name - Sets the search criteria to the contents of MLModel  Name.    IAMUser - Sets the search criteria to the user account that invoked the MLModel creation.    TrainingDataSourceId - Sets the search criteria to the DataSource used to train one or more MLModel.    RealtimeEndpointStatus - Sets the search criteria to the MLModel real-time endpoint status.    MLModelType - Sets the search criteria to MLModel type: binary, regression, or multi-class.    Algorithm - Sets the search criteria to the algorithm that the MLModel uses.    TrainingDataURI - Sets the search criteria to the data file(s) used in training a MLModel. The URL can identify either a file or an Amazon Simple Storage Service (Amazon S3) bucket or directory.
        public let filterVariable: MLModelFilterVariable?
        /// The greater than or equal to operator. The MLModel results will have FilterVariable values that are greater than or equal to the value specified with GE.
        public let ge: String?
        /// The greater than operator. The MLModel results will  have FilterVariable values that are greater than the value specified with GT.
        public let gt: String?
        /// The less than or equal to operator. The MLModel results will have FilterVariable values that are less than or equal to the value specified with LE.
        public let le: String?
        /// The number of pages of information to include in the result. The range of acceptable values is 1 through 100. The default value is 100.
        public let limit: Int?
        /// The less than operator. The MLModel results will  have FilterVariable values that are less than the value specified with LT.
        public let lt: String?
        /// The not equal to operator. The MLModel results will have FilterVariable values not equal to the value specified with NE.
        public let ne: String?
        /// The ID of the page in the paginated results.
        public let nextToken: String?
        /// A string that is found at the beginning of a variable, such as Name or Id.  For example, an MLModel could have the Name  2014-09-09-HolidayGiftMailer. To search for  this MLModel, select Name for the FilterVariable and any of the following strings for the  Prefix:      2014-09   2014-09-09   2014-09-09-Holiday
        public let prefix: String?
        /// A two-value parameter that determines the sequence of the resulting list of MLModel.    asc - Arranges the list in ascending order (A-Z, 0-9).    dsc - Arranges the list in descending order (Z-A, 9-0).   Results are sorted by FilterVariable.
        public let sortOrder: SortOrder?

        public init(eq: String? = nil, filterVariable: MLModelFilterVariable? = nil, ge: String? = nil, gt: String? = nil, le: String? = nil, limit: Int? = nil, lt: String? = nil, ne: String? = nil, nextToken: String? = nil, prefix: String? = nil, sortOrder: SortOrder? = nil) {
            self.eq = eq
            self.filterVariable = filterVariable
            self.ge = ge
            self.gt = gt
            self.le = le
            self.limit = limit
            self.lt = lt
            self.ne = ne
            self.nextToken = nextToken
            self.prefix = prefix
            self.sortOrder = sortOrder
        }

        public func validate(name: String) throws {
            try self.validate(self.eq, name: "eq", parent: name, max: 1024)
            try self.validate(self.eq, name: "eq", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ge, name: "ge", parent: name, max: 1024)
            try self.validate(self.ge, name: "ge", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.gt, name: "gt", parent: name, max: 1024)
            try self.validate(self.gt, name: "gt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.le, name: "le", parent: name, max: 1024)
            try self.validate(self.le, name: "le", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.limit, name: "limit", parent: name, max: 100)
            try self.validate(self.limit, name: "limit", parent: name, min: 1)
            try self.validate(self.lt, name: "lt", parent: name, max: 1024)
            try self.validate(self.lt, name: "lt", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.ne, name: "ne", parent: name, max: 1024)
            try self.validate(self.ne, name: "ne", parent: name, pattern: ".*\\S.*|^$")
            try self.validate(self.prefix, name: "prefix", parent: name, max: 1024)
            try self.validate(self.prefix, name: "prefix", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case eq = "EQ"
            case filterVariable = "FilterVariable"
            case ge = "GE"
            case gt = "GT"
            case le = "LE"
            case limit = "Limit"
            case lt = "LT"
            case ne = "NE"
            case nextToken = "NextToken"
            case prefix = "Prefix"
            case sortOrder = "SortOrder"
        }
    }

    public struct DescribeMLModelsOutput: AWSDecodableShape {
        /// The ID of the next page in the paginated results that indicates at least one more page follows.
        public let nextToken: String?
        /// A list of MLModel that meet the search criteria.
        public let results: [MLModel]?

        public init(nextToken: String? = nil, results: [MLModel]? = nil) {
            self.nextToken = nextToken
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case results = "Results"
        }
    }

    public struct DescribeTagsInput: AWSEncodableShape {
        /// The ID of the ML object. For example, exampleModelId.
        public let resourceId: String
        /// The type of the ML object.
        public let resourceType: TaggableResourceType

        public init(resourceId: String, resourceType: TaggableResourceType) {
            self.resourceId = resourceId
            self.resourceType = resourceType
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceId, name: "resourceId", parent: name, max: 64)
            try self.validate(self.resourceId, name: "resourceId", parent: name, min: 1)
            try self.validate(self.resourceId, name: "resourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
        }
    }

    public struct DescribeTagsOutput: AWSDecodableShape {
        /// The ID of the tagged ML object.
        public let resourceId: String?
        /// The type of the tagged ML object.
        public let resourceType: TaggableResourceType?
        /// A list of tags associated with the ML object.
        public let tags: [Tag]?

        public init(resourceId: String? = nil, resourceType: TaggableResourceType? = nil, tags: [Tag]? = nil) {
            self.resourceId = resourceId
            self.resourceType = resourceType
            self.tags = tags
        }

        private enum CodingKeys: String, CodingKey {
            case resourceId = "ResourceId"
            case resourceType = "ResourceType"
            case tags = "Tags"
        }
    }

    public struct Evaluation: AWSDecodableShape {
        public let computeTime: Int64?
        /// The time that the Evaluation was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account that invoked the evaluation. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The ID of the DataSource that is used to evaluate the MLModel.
        public let evaluationDataSourceId: String?
        /// The ID that is assigned to the Evaluation at creation.
        public let evaluationId: String?
        public let finishedAt: Date?
        /// The location and name of the data in Amazon Simple Storage Server (Amazon S3) that is used in the evaluation.
        public let inputDataLocationS3: String?
        /// The time of the most recent edit to the Evaluation. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A description of the most recent details about evaluating the MLModel.
        public let message: String?
        /// The ID of the MLModel that is the focus of the evaluation.
        public let mLModelId: String?
        /// A user-supplied name or description of the Evaluation.
        public let name: String?
        /// Measurements of how well the MLModel performed, using observations referenced by the DataSource. One of the following metrics is returned, based on the type of the MLModel:     BinaryAUC: A binary MLModel uses the Area Under the Curve (AUC) technique to measure performance.    RegressionRMSE: A regression MLModel uses the Root Mean Square Error (RMSE) technique to measure performance. RMSE measures the difference between predicted and actual values for a single variable.    MulticlassAvgFScore: A multiclass MLModel uses the F1 score technique to measure performance.     For more information about performance metrics, please see the Amazon Machine Learning Developer Guide.
        public let performanceMetrics: PerformanceMetrics?
        public let startedAt: Date?
        /// The status of the evaluation. This element can have one of the following values:    PENDING - Amazon Machine Learning (Amazon ML) submitted a request to evaluate an MLModel.    INPROGRESS - The evaluation is underway.    FAILED - The request to evaluate an MLModel did not run to completion. It is not usable.    COMPLETED - The evaluation process completed successfully.    DELETED - The Evaluation is marked as deleted. It is not usable.
        public let status: EntityStatus?

        public init(computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, evaluationDataSourceId: String? = nil, evaluationId: String? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, lastUpdatedAt: Date? = nil, message: String? = nil, mLModelId: String? = nil, name: String? = nil, performanceMetrics: PerformanceMetrics? = nil, startedAt: Date? = nil, status: EntityStatus? = nil) {
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.evaluationDataSourceId = evaluationDataSourceId
            self.evaluationId = evaluationId
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.lastUpdatedAt = lastUpdatedAt
            self.message = message
            self.mLModelId = mLModelId
            self.name = name
            self.performanceMetrics = performanceMetrics
            self.startedAt = startedAt
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case evaluationDataSourceId = "EvaluationDataSourceId"
            case evaluationId = "EvaluationId"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case lastUpdatedAt = "LastUpdatedAt"
            case message = "Message"
            case mLModelId = "MLModelId"
            case name = "Name"
            case performanceMetrics = "PerformanceMetrics"
            case startedAt = "StartedAt"
            case status = "Status"
        }
    }

    public struct GetBatchPredictionInput: AWSEncodableShape {
        /// An ID assigned to the BatchPrediction at creation.
        public let batchPredictionId: String

        public init(batchPredictionId: String) {
            self.batchPredictionId = batchPredictionId
        }

        public func validate(name: String) throws {
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, max: 64)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, min: 1)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
        }
    }

    public struct GetBatchPredictionOutput: AWSDecodableShape {
        /// The ID of the DataSource that was used to create the BatchPrediction.
        public let batchPredictionDataSourceId: String?
        /// An ID assigned to the BatchPrediction at creation. This value should be identical to the value of the BatchPredictionID  in the request.
        public let batchPredictionId: String?
        /// The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the BatchPrediction, normalized and scaled on computation resources. ComputeTime is only available if the BatchPrediction is in the COMPLETED state.
        public let computeTime: Int64?
        /// The time when the BatchPrediction was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account that invoked the BatchPrediction. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The epoch time when Amazon Machine Learning marked the BatchPrediction as COMPLETED or FAILED. FinishedAt is only available when the BatchPrediction is in the COMPLETED or FAILED state.
        public let finishedAt: Date?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let inputDataLocationS3: String?
        /// The number of invalid records that Amazon Machine Learning saw while processing the BatchPrediction.
        public let invalidRecordCount: Int64?
        /// The time of the most recent edit to BatchPrediction. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A link to the file that contains logs of the CreateBatchPrediction operation.
        public let logUri: String?
        /// A description of the most recent details about processing the batch prediction request.
        public let message: String?
        /// The ID of the MLModel that generated predictions for the BatchPrediction request.
        public let mLModelId: String?
        /// A user-supplied name or description of the BatchPrediction.
        public let name: String?
        /// The location of an Amazon S3 bucket or directory to receive the operation results.
        public let outputUri: String?
        /// The epoch time when Amazon Machine Learning marked the BatchPrediction as INPROGRESS. StartedAt isn't available if the BatchPrediction is in the PENDING state.
        public let startedAt: Date?
        /// The status of the BatchPrediction, which can be one of the following values:    PENDING - Amazon Machine Learning (Amazon ML) submitted a request to generate batch predictions.    INPROGRESS - The batch predictions are in progress.    FAILED - The request to perform a batch prediction did not run to completion. It is not usable.    COMPLETED - The batch prediction process completed successfully.    DELETED - The BatchPrediction is marked as deleted. It is not usable.
        public let status: EntityStatus?
        /// The number of total records that Amazon Machine Learning saw while processing the BatchPrediction.
        public let totalRecordCount: Int64?

        public init(batchPredictionDataSourceId: String? = nil, batchPredictionId: String? = nil, computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, invalidRecordCount: Int64? = nil, lastUpdatedAt: Date? = nil, logUri: String? = nil, message: String? = nil, mLModelId: String? = nil, name: String? = nil, outputUri: String? = nil, startedAt: Date? = nil, status: EntityStatus? = nil, totalRecordCount: Int64? = nil) {
            self.batchPredictionDataSourceId = batchPredictionDataSourceId
            self.batchPredictionId = batchPredictionId
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.invalidRecordCount = invalidRecordCount
            self.lastUpdatedAt = lastUpdatedAt
            self.logUri = logUri
            self.message = message
            self.mLModelId = mLModelId
            self.name = name
            self.outputUri = outputUri
            self.startedAt = startedAt
            self.status = status
            self.totalRecordCount = totalRecordCount
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionDataSourceId = "BatchPredictionDataSourceId"
            case batchPredictionId = "BatchPredictionId"
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case invalidRecordCount = "InvalidRecordCount"
            case lastUpdatedAt = "LastUpdatedAt"
            case logUri = "LogUri"
            case message = "Message"
            case mLModelId = "MLModelId"
            case name = "Name"
            case outputUri = "OutputUri"
            case startedAt = "StartedAt"
            case status = "Status"
            case totalRecordCount = "TotalRecordCount"
        }
    }

    public struct GetDataSourceInput: AWSEncodableShape {
        /// The ID assigned to the DataSource at creation.
        public let dataSourceId: String
        /// Specifies whether the GetDataSource operation should return DataSourceSchema. If true, DataSourceSchema is returned. If false, DataSourceSchema is not returned.
        public let verbose: Bool?

        public init(dataSourceId: String, verbose: Bool? = nil) {
            self.dataSourceId = dataSourceId
            self.verbose = verbose
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
            case verbose = "Verbose"
        }
    }

    public struct GetDataSourceOutput: AWSDecodableShape {
        ///  The parameter is true if statistics need to be generated from the observation data.
        public let computeStatistics: Bool?
        /// The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the DataSource, normalized and scaled on computation resources. ComputeTime is only available if the DataSource is in the COMPLETED state and the ComputeStatistics is set to true.
        public let computeTime: Int64?
        /// The time that the DataSource was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account from which the DataSource was created. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let dataLocationS3: String?
        /// A JSON string that represents the splitting and rearrangement requirement used when this DataSource was created.
        public let dataRearrangement: String?
        /// The total size of observations in the data files.
        public let dataSizeInBytes: Int64?
        /// The ID assigned to the DataSource at creation.  This value should be identical to the value of the DataSourceId in the request.
        public let dataSourceId: String?
        /// The schema used by all of the data files of this DataSource.  Note: This parameter is provided as part of the verbose format.
        public let dataSourceSchema: String?
        /// The epoch time when Amazon Machine Learning marked the DataSource as COMPLETED or FAILED. FinishedAt is only available when the DataSource is in the COMPLETED or FAILED state.
        public let finishedAt: Date?
        /// The time of the most recent edit to the DataSource. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A link to the file containing logs of CreateDataSourceFrom* operations.
        public let logUri: String?
        /// The user-supplied description of the most recent details about creating the DataSource.
        public let message: String?
        /// A user-supplied name or description of the DataSource.
        public let name: String?
        /// The number of data files referenced by the DataSource.
        public let numberOfFiles: Int64?
        public let rDSMetadata: RDSMetadata?
        public let redshiftMetadata: RedshiftMetadata?
        public let roleARN: String?
        /// The epoch time when Amazon Machine Learning marked the DataSource as INPROGRESS. StartedAt isn't available if the DataSource is in the PENDING state.
        public let startedAt: Date?
        /// The current status of the DataSource. This element can have one of the following values:    PENDING - Amazon ML submitted a request to create a DataSource.    INPROGRESS - The creation process is underway.    FAILED - The request to create a DataSource did not run to completion. It is not usable.    COMPLETED - The creation process completed successfully.    DELETED - The DataSource is marked as deleted. It is not usable.
        public let status: EntityStatus?

        public init(computeStatistics: Bool? = nil, computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, dataLocationS3: String? = nil, dataRearrangement: String? = nil, dataSizeInBytes: Int64? = nil, dataSourceId: String? = nil, dataSourceSchema: String? = nil, finishedAt: Date? = nil, lastUpdatedAt: Date? = nil, logUri: String? = nil, message: String? = nil, name: String? = nil, numberOfFiles: Int64? = nil, rDSMetadata: RDSMetadata? = nil, redshiftMetadata: RedshiftMetadata? = nil, roleARN: String? = nil, startedAt: Date? = nil, status: EntityStatus? = nil) {
            self.computeStatistics = computeStatistics
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.dataLocationS3 = dataLocationS3
            self.dataRearrangement = dataRearrangement
            self.dataSizeInBytes = dataSizeInBytes
            self.dataSourceId = dataSourceId
            self.dataSourceSchema = dataSourceSchema
            self.finishedAt = finishedAt
            self.lastUpdatedAt = lastUpdatedAt
            self.logUri = logUri
            self.message = message
            self.name = name
            self.numberOfFiles = numberOfFiles
            self.rDSMetadata = rDSMetadata
            self.redshiftMetadata = redshiftMetadata
            self.roleARN = roleARN
            self.startedAt = startedAt
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case computeStatistics = "ComputeStatistics"
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case dataLocationS3 = "DataLocationS3"
            case dataRearrangement = "DataRearrangement"
            case dataSizeInBytes = "DataSizeInBytes"
            case dataSourceId = "DataSourceId"
            case dataSourceSchema = "DataSourceSchema"
            case finishedAt = "FinishedAt"
            case lastUpdatedAt = "LastUpdatedAt"
            case logUri = "LogUri"
            case message = "Message"
            case name = "Name"
            case numberOfFiles = "NumberOfFiles"
            case rDSMetadata = "RDSMetadata"
            case redshiftMetadata = "RedshiftMetadata"
            case roleARN = "RoleARN"
            case startedAt = "StartedAt"
            case status = "Status"
        }
    }

    public struct GetEvaluationInput: AWSEncodableShape {
        /// The ID of the Evaluation to retrieve. The evaluation of each MLModel is recorded and cataloged. The ID provides the means to access the information.
        public let evaluationId: String

        public init(evaluationId: String) {
            self.evaluationId = evaluationId
        }

        public func validate(name: String) throws {
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, max: 64)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, min: 1)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
        }
    }

    public struct GetEvaluationOutput: AWSDecodableShape {
        /// The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the Evaluation, normalized and scaled on computation resources. ComputeTime is only available if the Evaluation is in the COMPLETED state.
        public let computeTime: Int64?
        /// The time that the Evaluation was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account that invoked the evaluation. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The DataSource used for this evaluation.
        public let evaluationDataSourceId: String?
        /// The evaluation ID which is same as the EvaluationId in the request.
        public let evaluationId: String?
        /// The epoch time when Amazon Machine Learning marked the Evaluation as COMPLETED or FAILED. FinishedAt is only available when the Evaluation is in the COMPLETED or FAILED state.
        public let finishedAt: Date?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let inputDataLocationS3: String?
        /// The time of the most recent edit to the Evaluation. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A link to the file that contains logs of the CreateEvaluation operation.
        public let logUri: String?
        /// A description of the most recent details about evaluating the MLModel.
        public let message: String?
        /// The ID of the MLModel that was the focus of the evaluation.
        public let mLModelId: String?
        /// A user-supplied name or description of the Evaluation.
        public let name: String?
        /// Measurements of how well the MLModel performed using observations referenced by the DataSource. One of the following metric is returned based on the type of the MLModel:     BinaryAUC: A binary MLModel uses the Area Under the Curve (AUC) technique to measure performance.    RegressionRMSE: A regression MLModel uses the Root Mean Square Error (RMSE) technique to measure performance. RMSE measures the difference between predicted and actual values for a single variable.    MulticlassAvgFScore: A multiclass MLModel uses the F1 score technique to measure performance.     For more information about performance metrics, please see the Amazon Machine Learning Developer Guide.
        public let performanceMetrics: PerformanceMetrics?
        /// The epoch time when Amazon Machine Learning marked the Evaluation as INPROGRESS. StartedAt isn't available if the Evaluation is in the PENDING state.
        public let startedAt: Date?
        /// The status of the evaluation. This element can have one of the following values:    PENDING - Amazon Machine Language (Amazon ML) submitted a request to evaluate an MLModel.    INPROGRESS - The evaluation is underway.    FAILED - The request to evaluate an MLModel did not run to completion. It is not usable.    COMPLETED - The evaluation process completed successfully.    DELETED - The Evaluation is marked as deleted. It is not usable.
        public let status: EntityStatus?

        public init(computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, evaluationDataSourceId: String? = nil, evaluationId: String? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, lastUpdatedAt: Date? = nil, logUri: String? = nil, message: String? = nil, mLModelId: String? = nil, name: String? = nil, performanceMetrics: PerformanceMetrics? = nil, startedAt: Date? = nil, status: EntityStatus? = nil) {
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.evaluationDataSourceId = evaluationDataSourceId
            self.evaluationId = evaluationId
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.lastUpdatedAt = lastUpdatedAt
            self.logUri = logUri
            self.message = message
            self.mLModelId = mLModelId
            self.name = name
            self.performanceMetrics = performanceMetrics
            self.startedAt = startedAt
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case evaluationDataSourceId = "EvaluationDataSourceId"
            case evaluationId = "EvaluationId"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case lastUpdatedAt = "LastUpdatedAt"
            case logUri = "LogUri"
            case message = "Message"
            case mLModelId = "MLModelId"
            case name = "Name"
            case performanceMetrics = "PerformanceMetrics"
            case startedAt = "StartedAt"
            case status = "Status"
        }
    }

    public struct GetMLModelInput: AWSEncodableShape {
        /// The ID assigned to the MLModel at creation.
        public let mLModelId: String
        /// Specifies whether the GetMLModel operation should return Recipe. If true, Recipe is returned. If false, Recipe is not returned.
        public let verbose: Bool?

        public init(mLModelId: String, verbose: Bool? = nil) {
            self.mLModelId = mLModelId
            self.verbose = verbose
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case verbose = "Verbose"
        }
    }

    public struct GetMLModelOutput: AWSDecodableShape {
        /// The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the MLModel, normalized and scaled on computation resources. ComputeTime is only available if the MLModel is in the COMPLETED state.
        public let computeTime: Int64?
        /// The time that the MLModel was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account from which the MLModel was created. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The current endpoint of the MLModel
        public let endpointInfo: RealtimeEndpointInfo?
        /// The epoch time when Amazon Machine Learning marked the MLModel as COMPLETED or FAILED. FinishedAt is only available when the MLModel is in the COMPLETED or FAILED state.
        public let finishedAt: Date?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let inputDataLocationS3: String?
        /// The time of the most recent edit to the MLModel. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A link to the file that contains logs of the CreateMLModel operation.
        public let logUri: String?
        /// A description of the most recent details about accessing the MLModel.
        public let message: String?
        /// The MLModel ID,  which is same as the MLModelId in the request.
        public let mLModelId: String?
        /// Identifies the MLModel category. The following are the available types:    REGRESSION -- Produces a numeric result. For example, "What price should a house be listed at?"   BINARY -- Produces one of two possible results. For example, "Is this an e-commerce website?"   MULTICLASS -- Produces one of several possible results. For example, "Is this a HIGH, LOW or MEDIUM risk trade?"
        public let mLModelType: MLModelType?
        /// A user-supplied name or description of the MLModel.
        public let name: String?
        /// The recipe to use when training the MLModel. The Recipe provides detailed information about the observation data to use during training, and manipulations to perform on the observation data during training.  Note: This parameter is provided as part of the verbose format.
        public let recipe: String?
        /// The schema used by all of the data files referenced by the DataSource.  Note: This parameter is provided as part of the verbose format.
        public let schema: String?
        /// The scoring threshold is used in binary classification MLModel models. It marks the boundary between a positive prediction and a negative prediction. Output values greater than or equal to the threshold receive a positive result from the MLModel, such as  true. Output values less than the threshold receive a negative response from the MLModel,  such as false.
        public let scoreThreshold: Float?
        /// The time of the most recent edit to the ScoreThreshold. The time is expressed in epoch time.
        public let scoreThresholdLastUpdatedAt: Date?
        public let sizeInBytes: Int64?
        /// The epoch time when Amazon Machine Learning marked the MLModel as INPROGRESS. StartedAt isn't available if the MLModel is in the PENDING state.
        public let startedAt: Date?
        /// The current status of the MLModel. This element can have one of the following values:    PENDING - Amazon Machine Learning (Amazon ML) submitted a request to describe a MLModel.    INPROGRESS - The request is processing.    FAILED - The request did not run to completion. The ML model isn't usable.    COMPLETED - The request completed successfully.    DELETED - The MLModel is marked as deleted. It isn't usable.
        public let status: EntityStatus?
        /// The ID of the training DataSource.
        public let trainingDataSourceId: String?
        /// A list of the training parameters in the MLModel. The list is implemented as a map of key-value pairs. The following is the current set of training parameters:    sgd.maxMLModelSizeInBytes - The maximum allowed size of the model. Depending on the input data, the size of the model might affect its performance.  The value is an integer that ranges from 100000 to 2147483648. The default value is 33554432.    sgd.maxPasses - The number of times that the training process traverses the observations to build the MLModel. The value is an integer that ranges from 1 to 10000. The default value is 10.    sgd.shuffleType - Whether Amazon ML shuffles the training data. Shuffling data improves a model's ability to find the optimal solution for a variety of data types. The valid values are auto and none. The default value is none. We strongly recommend that you shuffle your data.    sgd.l1RegularizationAmount - The coefficient regularization L1 norm. It controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to zero, resulting in a sparse feature set. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L1 normalization. This parameter can't be used when L2 is specified. Use this parameter sparingly.    sgd.l2RegularizationAmount - The coefficient regularization L2 norm. It controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to small, nonzero values. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L2 normalization. This parameter can't be used when L1 is specified. Use this parameter sparingly.
        public let trainingParameters: [String: String]?

        public init(computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, endpointInfo: RealtimeEndpointInfo? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, lastUpdatedAt: Date? = nil, logUri: String? = nil, message: String? = nil, mLModelId: String? = nil, mLModelType: MLModelType? = nil, name: String? = nil, recipe: String? = nil, schema: String? = nil, scoreThreshold: Float? = nil, scoreThresholdLastUpdatedAt: Date? = nil, sizeInBytes: Int64? = nil, startedAt: Date? = nil, status: EntityStatus? = nil, trainingDataSourceId: String? = nil, trainingParameters: [String: String]? = nil) {
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.endpointInfo = endpointInfo
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.lastUpdatedAt = lastUpdatedAt
            self.logUri = logUri
            self.message = message
            self.mLModelId = mLModelId
            self.mLModelType = mLModelType
            self.name = name
            self.recipe = recipe
            self.schema = schema
            self.scoreThreshold = scoreThreshold
            self.scoreThresholdLastUpdatedAt = scoreThresholdLastUpdatedAt
            self.sizeInBytes = sizeInBytes
            self.startedAt = startedAt
            self.status = status
            self.trainingDataSourceId = trainingDataSourceId
            self.trainingParameters = trainingParameters
        }

        private enum CodingKeys: String, CodingKey {
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case endpointInfo = "EndpointInfo"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case lastUpdatedAt = "LastUpdatedAt"
            case logUri = "LogUri"
            case message = "Message"
            case mLModelId = "MLModelId"
            case mLModelType = "MLModelType"
            case name = "Name"
            case recipe = "Recipe"
            case schema = "Schema"
            case scoreThreshold = "ScoreThreshold"
            case scoreThresholdLastUpdatedAt = "ScoreThresholdLastUpdatedAt"
            case sizeInBytes = "SizeInBytes"
            case startedAt = "StartedAt"
            case status = "Status"
            case trainingDataSourceId = "TrainingDataSourceId"
            case trainingParameters = "TrainingParameters"
        }
    }

    public struct MLModel: AWSDecodableShape {
        /// The algorithm used to train the MLModel. The following algorithm is supported:    SGD -- Stochastic gradient descent. The goal of SGD is to minimize the gradient of the loss function.
        public let algorithm: Algorithm?
        public let computeTime: Int64?
        /// The time that the MLModel was created. The time is expressed in epoch time.
        public let createdAt: Date?
        /// The AWS user account from which the MLModel was created. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.
        public let createdByIamUser: String?
        /// The current endpoint of the MLModel.
        public let endpointInfo: RealtimeEndpointInfo?
        public let finishedAt: Date?
        /// The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).
        public let inputDataLocationS3: String?
        /// The time of the most recent edit to the MLModel. The time is expressed in epoch time.
        public let lastUpdatedAt: Date?
        /// A description of the most recent details about accessing the MLModel.
        public let message: String?
        /// The ID assigned to the MLModel at creation.
        public let mLModelId: String?
        /// Identifies the MLModel category. The following are the available types:    REGRESSION - Produces a numeric result. For example, "What price should a house be listed at?"    BINARY - Produces one of two possible results. For example, "Is this a child-friendly web site?".    MULTICLASS - Produces one of several possible results. For example, "Is this a HIGH-, LOW-, or MEDIUM-risk trade?".
        public let mLModelType: MLModelType?
        /// A user-supplied name or description of the MLModel.
        public let name: String?
        public let scoreThreshold: Float?
        /// The time of the most recent edit to the ScoreThreshold. The time is expressed in epoch time.
        public let scoreThresholdLastUpdatedAt: Date?
        public let sizeInBytes: Int64?
        public let startedAt: Date?
        /// The current status of an MLModel. This element can have one of the following values:     PENDING	- Amazon Machine Learning (Amazon ML) submitted a request to create an MLModel.    INPROGRESS	- The creation process is underway.    FAILED - The request to create an MLModel didn't run to completion. The model isn't usable.    COMPLETED	- The creation process completed successfully.    DELETED - The MLModel is marked as deleted. It isn't usable.
        public let status: EntityStatus?
        /// The ID of the training DataSource. The CreateMLModel operation uses the TrainingDataSourceId.
        public let trainingDataSourceId: String?
        /// A list of the training parameters in the MLModel. The list is implemented as a map of key-value pairs. The following is the current set of training parameters:    sgd.maxMLModelSizeInBytes - The maximum allowed size of the model. Depending on the input data, the size of the model might affect its performance.  The value is an integer that ranges from 100000 to 2147483648. The default value is 33554432.    sgd.maxPasses - The number of times that the training process traverses the observations to build the MLModel. The value is an integer that ranges from 1 to 10000. The default value is 10.    sgd.shuffleType - Whether Amazon ML shuffles the training data. Shuffling the data improves a model's ability to find the optimal solution for a variety of data types. The valid values are auto and none. The default value is none.    sgd.l1RegularizationAmount - The coefficient regularization L1 norm, which controls overfitting the data by penalizing large coefficients. This parameter tends to drive coefficients to zero, resulting in sparse feature set. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L1 normalization. This parameter can't be used when L2 is specified. Use this parameter sparingly.    sgd.l2RegularizationAmount - The coefficient regularization L2 norm, which controls overfitting the data by penalizing large coefficients. This tends to drive coefficients to small, nonzero values. If you use this parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges from 0 to MAX_DOUBLE. The default is to not use L2 normalization. This parameter can't be used when L1 is specified. Use this parameter sparingly.
        public let trainingParameters: [String: String]?

        public init(algorithm: Algorithm? = nil, computeTime: Int64? = nil, createdAt: Date? = nil, createdByIamUser: String? = nil, endpointInfo: RealtimeEndpointInfo? = nil, finishedAt: Date? = nil, inputDataLocationS3: String? = nil, lastUpdatedAt: Date? = nil, message: String? = nil, mLModelId: String? = nil, mLModelType: MLModelType? = nil, name: String? = nil, scoreThreshold: Float? = nil, scoreThresholdLastUpdatedAt: Date? = nil, sizeInBytes: Int64? = nil, startedAt: Date? = nil, status: EntityStatus? = nil, trainingDataSourceId: String? = nil, trainingParameters: [String: String]? = nil) {
            self.algorithm = algorithm
            self.computeTime = computeTime
            self.createdAt = createdAt
            self.createdByIamUser = createdByIamUser
            self.endpointInfo = endpointInfo
            self.finishedAt = finishedAt
            self.inputDataLocationS3 = inputDataLocationS3
            self.lastUpdatedAt = lastUpdatedAt
            self.message = message
            self.mLModelId = mLModelId
            self.mLModelType = mLModelType
            self.name = name
            self.scoreThreshold = scoreThreshold
            self.scoreThresholdLastUpdatedAt = scoreThresholdLastUpdatedAt
            self.sizeInBytes = sizeInBytes
            self.startedAt = startedAt
            self.status = status
            self.trainingDataSourceId = trainingDataSourceId
            self.trainingParameters = trainingParameters
        }

        private enum CodingKeys: String, CodingKey {
            case algorithm = "Algorithm"
            case computeTime = "ComputeTime"
            case createdAt = "CreatedAt"
            case createdByIamUser = "CreatedByIamUser"
            case endpointInfo = "EndpointInfo"
            case finishedAt = "FinishedAt"
            case inputDataLocationS3 = "InputDataLocationS3"
            case lastUpdatedAt = "LastUpdatedAt"
            case message = "Message"
            case mLModelId = "MLModelId"
            case mLModelType = "MLModelType"
            case name = "Name"
            case scoreThreshold = "ScoreThreshold"
            case scoreThresholdLastUpdatedAt = "ScoreThresholdLastUpdatedAt"
            case sizeInBytes = "SizeInBytes"
            case startedAt = "StartedAt"
            case status = "Status"
            case trainingDataSourceId = "TrainingDataSourceId"
            case trainingParameters = "TrainingParameters"
        }
    }

    public struct PerformanceMetrics: AWSDecodableShape {
        public let properties: [String: String]?

        public init(properties: [String: String]? = nil) {
            self.properties = properties
        }

        private enum CodingKeys: String, CodingKey {
            case properties = "Properties"
        }
    }

    public struct PredictInput: AWSEncodableShape {
        /// A unique identifier of the MLModel.
        public let mLModelId: String
        public let predictEndpoint: String
        public let record: [String: String]

        public init(mLModelId: String, predictEndpoint: String, record: [String: String]) {
            self.mLModelId = mLModelId
            self.predictEndpoint = predictEndpoint
            self.record = record
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.predictEndpoint, name: "predictEndpoint", parent: name, max: 2048)
            try self.validate(self.predictEndpoint, name: "predictEndpoint", parent: name, pattern: "https://[a-zA-Z0-9-.]*\\.amazon(aws)?\\.com[/]?")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case predictEndpoint = "PredictEndpoint"
            case record = "Record"
        }
    }

    public struct PredictOutput: AWSDecodableShape {
        public let prediction: Prediction?

        public init(prediction: Prediction? = nil) {
            self.prediction = prediction
        }

        private enum CodingKeys: String, CodingKey {
            case prediction = "Prediction"
        }
    }

    public struct Prediction: AWSDecodableShape {
        public let details: [DetailsAttributes: String]?
        /// The prediction label for either a BINARY or MULTICLASS  MLModel.
        public let predictedLabel: String?
        public let predictedScores: [String: Float]?
        /// The prediction value for REGRESSION  MLModel.
        public let predictedValue: Float?

        public init(details: [DetailsAttributes: String]? = nil, predictedLabel: String? = nil, predictedScores: [String: Float]? = nil, predictedValue: Float? = nil) {
            self.details = details
            self.predictedLabel = predictedLabel
            self.predictedScores = predictedScores
            self.predictedValue = predictedValue
        }

        private enum CodingKeys: String, CodingKey {
            case details
            case predictedLabel
            case predictedScores
            case predictedValue
        }
    }

    public struct RDSDataSpec: AWSEncodableShape {
        /// The AWS Identity and Access Management (IAM) credentials that are used connect to the Amazon RDS database.
        public let databaseCredentials: RDSDatabaseCredentials
        /// Describes the DatabaseName and InstanceIdentifier of an Amazon RDS database.
        public let databaseInformation: RDSDatabase
        /// A JSON string that represents the splitting and rearrangement  processing to be applied to a DataSource. If the DataRearrangement  parameter is not provided, all of the input data is used to create the Datasource.
        ///  There are multiple parameters that control what data is used to create a datasource:     percentBegin   Use percentBegin to indicate the beginning of the range of the data used to  create the Datasource. If you do not include percentBegin and percentEnd, Amazon ML includes  all of the data when creating the datasource.     percentEnd   Use percentEnd to indicate the end of the range of the data used to create the  Datasource. If you do not include percentBegin and percentEnd, Amazon ML  includes all of the data when creating the datasource.     complement   The complement parameter instructs Amazon ML to use the data that is not included in the range of percentBegin to percentEnd to create a datasource. The complement parameter is useful if you need to create  complementary datasources for training and evaluation. To create a complementary datasource, use the same values for percentBegin and percentEnd, along with the complement parameter.
        ///  For example, the following two datasources do not share any data, and can be used to train and evaluate a model. The first datasource has 25 percent of the data, and the second one has 75 percent of the data. Datasource for evaluation: {"splitting":{"percentBegin":0, "percentEnd":25}}  Datasource for training: {"splitting":{"percentBegin":0, "percentEnd":25, "complement":"true"}}      strategy   To change how Amazon ML splits the data for a datasource, use the strategy parameter. The default value for the strategy parameter is sequential, meaning that Amazon ML takes all of the data records between the percentBegin and percentEnd parameters for the datasource, in the order that the records appear in the input data.
        ///  The following two DataRearrangement lines are examples of sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential", "complement":"true"}}
        ///  To randomly split the input data into the proportions indicated by the percentBegin and percentEnd  parameters, set the strategy parameter to random and provide a string that is used as the seed value for the random data splitting (for  example, you can use the S3 path to your data as the random seed string).  If you choose the random split strategy, Amazon ML assigns each row of data a pseudo-random number between 0 and 100, and then selects the rows that have an assigned number between percentBegin and percentEnd. Pseudo-random numbers are assigned  using both the input seed string value and the byte offset as a seed, so changing the data results in a  different split. Any existing ordering is preserved. The random splitting strategy ensures that variables in the training and evaluation data are distributed similarly.  It is useful in the cases where the input data may have an implicit sort order, which would otherwise result in  training and evaluation datasources containing non-similar data records. The following two DataRearrangement lines are examples of non-sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}
        public let dataRearrangement: String?
        /// A JSON string that represents the schema for an Amazon RDS DataSource. The DataSchema defines the structure of the observation data in the data file(s) referenced in the DataSource. A DataSchema is not required if you specify a  DataSchemaUri  Define your DataSchema as a series of key-value pairs. attributes and excludedVariableNames have an array of key-value pairs for their value. Use the following format to define your DataSchema. { "version": "1.0", "recordAnnotationFieldName": "F1", "recordWeightFieldName": "F2", "targetFieldName": "F3", "dataFormat": "CSV", "dataFileContainsHeader": true, "attributes": [ { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2", "fieldType": "NUMERIC" }, { "fieldName": "F3", "fieldType": "CATEGORICAL" }, { "fieldName": "F4", "fieldType": "NUMERIC" }, { "fieldName": "F5", "fieldType": "CATEGORICAL" }, { "fieldName": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "fieldType": "WEIGHTED_INT_SEQUENCE" }, { "fieldName": "F8", "fieldType": "WEIGHTED_STRING_SEQUENCE" } ], "excludedVariableNames": [ "F6" ] }
        public let dataSchema: String?
        /// The Amazon S3 location of the DataSchema.
        public let dataSchemaUri: String?
        /// The role (DataPipelineDefaultResourceRole) assumed by an Amazon Elastic Compute Cloud (Amazon EC2) instance to carry out the copy operation from Amazon RDS to an Amazon S3 task. For more information, see Role templates for data pipelines.
        public let resourceRole: String
        /// The Amazon S3 location for staging Amazon RDS data. The data retrieved from Amazon RDS using SelectSqlQuery is stored in this location.
        public let s3StagingLocation: String
        /// The security group IDs to be used to access a VPC-based RDS DB instance. Ensure that there are appropriate ingress rules set up to allow access to the RDS DB instance. This attribute is used by Data Pipeline to carry out the copy operation from Amazon RDS to an Amazon S3 task.
        public let securityGroupIds: [String]
        /// The query that is used to retrieve the observation data for the DataSource.
        public let selectSqlQuery: String
        /// The role (DataPipelineDefaultRole) assumed by AWS Data Pipeline service to monitor the progress of the copy task from Amazon RDS to Amazon S3. For more information, see Role templates for data pipelines.
        public let serviceRole: String
        /// The subnet ID to be used to access a VPC-based RDS DB instance. This attribute is used by Data Pipeline to carry out the copy task from Amazon RDS to Amazon S3.
        public let subnetId: String

        public init(databaseCredentials: RDSDatabaseCredentials, databaseInformation: RDSDatabase, dataRearrangement: String? = nil, dataSchema: String? = nil, dataSchemaUri: String? = nil, resourceRole: String, s3StagingLocation: String, securityGroupIds: [String], selectSqlQuery: String, serviceRole: String, subnetId: String) {
            self.databaseCredentials = databaseCredentials
            self.databaseInformation = databaseInformation
            self.dataRearrangement = dataRearrangement
            self.dataSchema = dataSchema
            self.dataSchemaUri = dataSchemaUri
            self.resourceRole = resourceRole
            self.s3StagingLocation = s3StagingLocation
            self.securityGroupIds = securityGroupIds
            self.selectSqlQuery = selectSqlQuery
            self.serviceRole = serviceRole
            self.subnetId = subnetId
        }

        public func validate(name: String) throws {
            try self.databaseCredentials.validate(name: "\(name).databaseCredentials")
            try self.databaseInformation.validate(name: "\(name).databaseInformation")
            try self.validate(self.dataSchema, name: "dataSchema", parent: name, max: 131_071)
            try self.validate(self.dataSchemaUri, name: "dataSchemaUri", parent: name, max: 2048)
            try self.validate(self.dataSchemaUri, name: "dataSchemaUri", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.validate(self.resourceRole, name: "resourceRole", parent: name, max: 64)
            try self.validate(self.resourceRole, name: "resourceRole", parent: name, min: 1)
            try self.validate(self.s3StagingLocation, name: "s3StagingLocation", parent: name, max: 2048)
            try self.validate(self.s3StagingLocation, name: "s3StagingLocation", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.securityGroupIds.forEach {
                try validate($0, name: "securityGroupIds[]", parent: name, max: 255)
                try validate($0, name: "securityGroupIds[]", parent: name, min: 1)
            }
            try self.validate(self.selectSqlQuery, name: "selectSqlQuery", parent: name, max: 16_777_216)
            try self.validate(self.selectSqlQuery, name: "selectSqlQuery", parent: name, min: 1)
            try self.validate(self.serviceRole, name: "serviceRole", parent: name, max: 64)
            try self.validate(self.serviceRole, name: "serviceRole", parent: name, min: 1)
            try self.validate(self.subnetId, name: "subnetId", parent: name, max: 255)
            try self.validate(self.subnetId, name: "subnetId", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case databaseCredentials = "DatabaseCredentials"
            case databaseInformation = "DatabaseInformation"
            case dataRearrangement = "DataRearrangement"
            case dataSchema = "DataSchema"
            case dataSchemaUri = "DataSchemaUri"
            case resourceRole = "ResourceRole"
            case s3StagingLocation = "S3StagingLocation"
            case securityGroupIds = "SecurityGroupIds"
            case selectSqlQuery = "SelectSqlQuery"
            case serviceRole = "ServiceRole"
            case subnetId = "SubnetId"
        }
    }

    public struct RDSDatabase: AWSEncodableShape & AWSDecodableShape {
        public let databaseName: String
        /// The ID of an RDS DB instance.
        public let instanceIdentifier: String

        public init(databaseName: String, instanceIdentifier: String) {
            self.databaseName = databaseName
            self.instanceIdentifier = instanceIdentifier
        }

        public func validate(name: String) throws {
            try self.validate(self.databaseName, name: "databaseName", parent: name, max: 64)
            try self.validate(self.databaseName, name: "databaseName", parent: name, min: 1)
            try self.validate(self.instanceIdentifier, name: "instanceIdentifier", parent: name, max: 63)
            try self.validate(self.instanceIdentifier, name: "instanceIdentifier", parent: name, min: 1)
            try self.validate(self.instanceIdentifier, name: "instanceIdentifier", parent: name, pattern: "[a-z0-9-]+")
        }

        private enum CodingKeys: String, CodingKey {
            case databaseName = "DatabaseName"
            case instanceIdentifier = "InstanceIdentifier"
        }
    }

    public struct RDSDatabaseCredentials: AWSEncodableShape {
        public let password: String
        public let username: String

        public init(password: String, username: String) {
            self.password = password
            self.username = username
        }

        public func validate(name: String) throws {
            try self.validate(self.password, name: "password", parent: name, max: 128)
            try self.validate(self.password, name: "password", parent: name, min: 8)
            try self.validate(self.username, name: "username", parent: name, max: 128)
            try self.validate(self.username, name: "username", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case password = "Password"
            case username = "Username"
        }
    }

    public struct RDSMetadata: AWSDecodableShape {
        /// The database details required to connect to an Amazon RDS.
        public let database: RDSDatabase?
        public let databaseUserName: String?
        /// The ID of the Data Pipeline instance that is used to carry to copy data from Amazon RDS to Amazon S3. You can use the ID to find details about the instance in the Data Pipeline console.
        public let dataPipelineId: String?
        /// The role (DataPipelineDefaultResourceRole) assumed by an Amazon EC2 instance to carry out the copy task from Amazon RDS to Amazon S3. For more information, see Role templates for data pipelines.
        public let resourceRole: String?
        /// The SQL query that is supplied during CreateDataSourceFromRDS. Returns only if Verbose is true in GetDataSourceInput.
        public let selectSqlQuery: String?
        /// The role (DataPipelineDefaultRole) assumed by the Data Pipeline service to monitor the progress of the copy task from Amazon RDS to Amazon S3. For more information, see Role templates for data pipelines.
        public let serviceRole: String?

        public init(database: RDSDatabase? = nil, databaseUserName: String? = nil, dataPipelineId: String? = nil, resourceRole: String? = nil, selectSqlQuery: String? = nil, serviceRole: String? = nil) {
            self.database = database
            self.databaseUserName = databaseUserName
            self.dataPipelineId = dataPipelineId
            self.resourceRole = resourceRole
            self.selectSqlQuery = selectSqlQuery
            self.serviceRole = serviceRole
        }

        private enum CodingKeys: String, CodingKey {
            case database = "Database"
            case databaseUserName = "DatabaseUserName"
            case dataPipelineId = "DataPipelineId"
            case resourceRole = "ResourceRole"
            case selectSqlQuery = "SelectSqlQuery"
            case serviceRole = "ServiceRole"
        }
    }

    public struct RealtimeEndpointInfo: AWSDecodableShape {
        /// The time that the request to create the real-time endpoint for the MLModel was received. The time is expressed in epoch time.
        public let createdAt: Date?
        ///  The current status of the real-time endpoint for the MLModel. This element can have one of the following values:     NONE  - Endpoint does not exist or was previously deleted.    READY - Endpoint is ready to be used for real-time predictions.    UPDATING - Updating/creating the endpoint.
        public let endpointStatus: RealtimeEndpointStatus?
        /// The URI that specifies where to send real-time prediction requests for the MLModel.  Note: The application must wait until the real-time endpoint is ready before using this URI.
        public let endpointUrl: String?
        ///  The maximum processing rate for the real-time endpoint for MLModel, measured in incoming requests per second.
        public let peakRequestsPerSecond: Int?

        public init(createdAt: Date? = nil, endpointStatus: RealtimeEndpointStatus? = nil, endpointUrl: String? = nil, peakRequestsPerSecond: Int? = nil) {
            self.createdAt = createdAt
            self.endpointStatus = endpointStatus
            self.endpointUrl = endpointUrl
            self.peakRequestsPerSecond = peakRequestsPerSecond
        }

        private enum CodingKeys: String, CodingKey {
            case createdAt = "CreatedAt"
            case endpointStatus = "EndpointStatus"
            case endpointUrl = "EndpointUrl"
            case peakRequestsPerSecond = "PeakRequestsPerSecond"
        }
    }

    public struct RedshiftDataSpec: AWSEncodableShape {
        /// Describes AWS Identity and Access Management (IAM) credentials that are used connect to the Amazon Redshift database.
        public let databaseCredentials: RedshiftDatabaseCredentials
        /// Describes the DatabaseName and ClusterIdentifier for an Amazon Redshift DataSource.
        public let databaseInformation: RedshiftDatabase
        /// A JSON string that represents the splitting and rearrangement  processing to be applied to a DataSource. If the DataRearrangement  parameter is not provided, all of the input data is used to create the Datasource.
        ///  There are multiple parameters that control what data is used to create a datasource:     percentBegin   Use percentBegin to indicate the beginning of the range of the data used to  create the Datasource. If you do not include percentBegin and percentEnd, Amazon ML includes  all of the data when creating the datasource.     percentEnd   Use percentEnd to indicate the end of the range of the data used to create the  Datasource. If you do not include percentBegin and percentEnd, Amazon ML  includes all of the data when creating the datasource.     complement   The complement parameter instructs Amazon ML to use the data that is not included in the range of percentBegin to percentEnd to create a datasource. The complement parameter is useful if you need to create  complementary datasources for training and evaluation. To create a complementary datasource, use the same values for percentBegin and percentEnd, along with the complement parameter.
        ///  For example, the following two datasources do not share any data, and can be used to train and evaluate a model. The first datasource has 25 percent of the data, and the second one has 75 percent of the data. Datasource for evaluation: {"splitting":{"percentBegin":0, "percentEnd":25}}  Datasource for training: {"splitting":{"percentBegin":0, "percentEnd":25, "complement":"true"}}      strategy   To change how Amazon ML splits the data for a datasource, use the strategy parameter. The default value for the strategy parameter is sequential, meaning that Amazon ML takes all of the data records between the percentBegin and percentEnd parameters for the datasource, in the order that the records appear in the input data.
        ///  The following two DataRearrangement lines are examples of sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential", "complement":"true"}}
        ///  To randomly split the input data into the proportions indicated by the percentBegin and percentEnd  parameters, set the strategy parameter to random and provide a string that is used as the seed value for the random data splitting (for  example, you can use the S3 path to your data as the random seed string).  If you choose the random split strategy, Amazon ML assigns each row of data a pseudo-random number between 0 and 100, and then selects the rows that have an assigned number between percentBegin and percentEnd. Pseudo-random numbers are assigned  using both the input seed string value and the byte offset as a seed, so changing the data results in a  different split. Any existing ordering is preserved. The random splitting strategy ensures that variables in the training and evaluation data are distributed similarly.  It is useful in the cases where the input data may have an implicit sort order, which would otherwise result in  training and evaluation datasources containing non-similar data records. The following two DataRearrangement lines are examples of non-sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}
        public let dataRearrangement: String?
        /// A JSON string that represents the schema for an Amazon Redshift  DataSource. The DataSchema defines the structure of the observation data in the data file(s) referenced in the DataSource. A DataSchema is not required if you specify a  DataSchemaUri. Define your DataSchema as a series of key-value pairs. attributes and excludedVariableNames have an array of key-value pairs for their value. Use the following format to define your DataSchema. { "version": "1.0", "recordAnnotationFieldName": "F1", "recordWeightFieldName": "F2", "targetFieldName": "F3", "dataFormat": "CSV", "dataFileContainsHeader": true, "attributes": [ { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2", "fieldType": "NUMERIC" }, { "fieldName": "F3", "fieldType": "CATEGORICAL" }, { "fieldName": "F4", "fieldType": "NUMERIC" }, { "fieldName": "F5", "fieldType": "CATEGORICAL" }, { "fieldName": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "fieldType": "WEIGHTED_INT_SEQUENCE" }, { "fieldName": "F8", "fieldType": "WEIGHTED_STRING_SEQUENCE" } ], "excludedVariableNames": [ "F6" ] }
        public let dataSchema: String?
        /// Describes the schema location for an Amazon Redshift DataSource.
        public let dataSchemaUri: String?
        /// Describes an Amazon S3 location to store the result set of the SelectSqlQuery query.
        public let s3StagingLocation: String
        /// Describes the SQL Query to execute on an Amazon Redshift database for an Amazon Redshift DataSource.
        public let selectSqlQuery: String

        public init(databaseCredentials: RedshiftDatabaseCredentials, databaseInformation: RedshiftDatabase, dataRearrangement: String? = nil, dataSchema: String? = nil, dataSchemaUri: String? = nil, s3StagingLocation: String, selectSqlQuery: String) {
            self.databaseCredentials = databaseCredentials
            self.databaseInformation = databaseInformation
            self.dataRearrangement = dataRearrangement
            self.dataSchema = dataSchema
            self.dataSchemaUri = dataSchemaUri
            self.s3StagingLocation = s3StagingLocation
            self.selectSqlQuery = selectSqlQuery
        }

        public func validate(name: String) throws {
            try self.databaseCredentials.validate(name: "\(name).databaseCredentials")
            try self.databaseInformation.validate(name: "\(name).databaseInformation")
            try self.validate(self.dataSchema, name: "dataSchema", parent: name, max: 131_071)
            try self.validate(self.dataSchemaUri, name: "dataSchemaUri", parent: name, max: 2048)
            try self.validate(self.dataSchemaUri, name: "dataSchemaUri", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.validate(self.s3StagingLocation, name: "s3StagingLocation", parent: name, max: 2048)
            try self.validate(self.s3StagingLocation, name: "s3StagingLocation", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.validate(self.selectSqlQuery, name: "selectSqlQuery", parent: name, max: 16_777_216)
            try self.validate(self.selectSqlQuery, name: "selectSqlQuery", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case databaseCredentials = "DatabaseCredentials"
            case databaseInformation = "DatabaseInformation"
            case dataRearrangement = "DataRearrangement"
            case dataSchema = "DataSchema"
            case dataSchemaUri = "DataSchemaUri"
            case s3StagingLocation = "S3StagingLocation"
            case selectSqlQuery = "SelectSqlQuery"
        }
    }

    public struct RedshiftDatabase: AWSEncodableShape & AWSDecodableShape {
        public let clusterIdentifier: String
        public let databaseName: String

        public init(clusterIdentifier: String, databaseName: String) {
            self.clusterIdentifier = clusterIdentifier
            self.databaseName = databaseName
        }

        public func validate(name: String) throws {
            try self.validate(self.clusterIdentifier, name: "clusterIdentifier", parent: name, max: 63)
            try self.validate(self.clusterIdentifier, name: "clusterIdentifier", parent: name, min: 1)
            try self.validate(self.clusterIdentifier, name: "clusterIdentifier", parent: name, pattern: "[a-z0-9-]+")
            try self.validate(self.databaseName, name: "databaseName", parent: name, max: 64)
            try self.validate(self.databaseName, name: "databaseName", parent: name, min: 1)
            try self.validate(self.databaseName, name: "databaseName", parent: name, pattern: "[a-z0-9]+")
        }

        private enum CodingKeys: String, CodingKey {
            case clusterIdentifier = "ClusterIdentifier"
            case databaseName = "DatabaseName"
        }
    }

    public struct RedshiftDatabaseCredentials: AWSEncodableShape {
        public let password: String
        public let username: String

        public init(password: String, username: String) {
            self.password = password
            self.username = username
        }

        public func validate(name: String) throws {
            try self.validate(self.password, name: "password", parent: name, max: 64)
            try self.validate(self.password, name: "password", parent: name, min: 8)
            try self.validate(self.username, name: "username", parent: name, max: 128)
            try self.validate(self.username, name: "username", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case password = "Password"
            case username = "Username"
        }
    }

    public struct RedshiftMetadata: AWSDecodableShape {
        public let databaseUserName: String?
        public let redshiftDatabase: RedshiftDatabase?
        ///  The SQL query that is specified during CreateDataSourceFromRedshift. Returns only if Verbose is true in GetDataSourceInput.
        public let selectSqlQuery: String?

        public init(databaseUserName: String? = nil, redshiftDatabase: RedshiftDatabase? = nil, selectSqlQuery: String? = nil) {
            self.databaseUserName = databaseUserName
            self.redshiftDatabase = redshiftDatabase
            self.selectSqlQuery = selectSqlQuery
        }

        private enum CodingKeys: String, CodingKey {
            case databaseUserName = "DatabaseUserName"
            case redshiftDatabase = "RedshiftDatabase"
            case selectSqlQuery = "SelectSqlQuery"
        }
    }

    public struct S3DataSpec: AWSEncodableShape {
        /// The location of the data file(s) used by a DataSource. The URI specifies a data file or  an Amazon Simple Storage Service (Amazon S3) directory or bucket containing data files.
        public let dataLocationS3: String
        /// A JSON string that represents the splitting and rearrangement  processing to be applied to a DataSource. If the DataRearrangement  parameter is not provided, all of the input data is used to create the Datasource.
        ///  There are multiple parameters that control what data is used to create a datasource:     percentBegin   Use percentBegin to indicate the beginning of the range of the data used to  create the Datasource. If you do not include percentBegin and percentEnd, Amazon ML includes  all of the data when creating the datasource.     percentEnd   Use percentEnd to indicate the end of the range of the data used to create the  Datasource. If you do not include percentBegin and percentEnd, Amazon ML  includes all of the data when creating the datasource.     complement   The complement parameter instructs Amazon ML to use the data that is not included in the range of percentBegin to percentEnd to create a datasource. The complement parameter is useful if you need to create  complementary datasources for training and evaluation. To create a complementary datasource, use the same values for percentBegin and percentEnd, along with the complement parameter.
        ///  For example, the following two datasources do not share any data, and can be used to train and evaluate a model. The first datasource has 25 percent of the data, and the second one has 75 percent of the data. Datasource for evaluation: {"splitting":{"percentBegin":0, "percentEnd":25}}  Datasource for training: {"splitting":{"percentBegin":0, "percentEnd":25, "complement":"true"}}      strategy   To change how Amazon ML splits the data for a datasource, use the strategy parameter. The default value for the strategy parameter is sequential, meaning that Amazon ML takes all of the data records between the percentBegin and percentEnd parameters for the datasource, in the order that the records appear in the input data.
        ///  The following two DataRearrangement lines are examples of sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"sequential", "complement":"true"}}
        ///  To randomly split the input data into the proportions indicated by the percentBegin and percentEnd  parameters, set the strategy parameter to random and provide a string that is used as the seed value for the random data splitting (for  example, you can use the S3 path to your data as the random seed string).  If you choose the random split strategy, Amazon ML assigns each row of data a pseudo-random number between 0 and 100, and then selects the rows that have an assigned number between percentBegin and percentEnd. Pseudo-random numbers are assigned  using both the input seed string value and the byte offset as a seed, so changing the data results in a  different split. Any existing ordering is preserved. The random splitting strategy ensures that variables in the training and evaluation data are distributed similarly.  It is useful in the cases where the input data may have an implicit sort order, which would otherwise result in  training and evaluation datasources containing non-similar data records. The following two DataRearrangement lines are examples of non-sequentially ordered training and evaluation datasources: Datasource for evaluation: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}  Datasource for training: {"splitting":{"percentBegin":70, "percentEnd":100, "strategy":"random", "randomSeed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}
        public let dataRearrangement: String?
        ///  A JSON string that represents the schema for an Amazon S3  DataSource. The DataSchema defines the structure of the observation data in the data file(s)  referenced in the DataSource. You must provide either the DataSchema or the DataSchemaLocationS3. Define your DataSchema as a series of key-value pairs. attributes  and excludedVariableNames have an array of key-value pairs for their value. Use the following format to define your DataSchema. { "version": "1.0", "recordAnnotationFieldName": "F1", "recordWeightFieldName": "F2", "targetFieldName": "F3", "dataFormat": "CSV", "dataFileContainsHeader": true, "attributes": [ { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2", "fieldType": "NUMERIC" }, { "fieldName": "F3", "fieldType": "CATEGORICAL" }, { "fieldName": "F4", "fieldType": "NUMERIC" }, { "fieldName": "F5", "fieldType": "CATEGORICAL" }, { "fieldName": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "fieldType": "WEIGHTED_INT_SEQUENCE" }, { "fieldName": "F8", "fieldType": "WEIGHTED_STRING_SEQUENCE" } ], "excludedVariableNames": [ "F6" ] }
        public let dataSchema: String?
        /// Describes the schema location in Amazon S3. You must provide either the  DataSchema or the DataSchemaLocationS3.
        public let dataSchemaLocationS3: String?

        public init(dataLocationS3: String, dataRearrangement: String? = nil, dataSchema: String? = nil, dataSchemaLocationS3: String? = nil) {
            self.dataLocationS3 = dataLocationS3
            self.dataRearrangement = dataRearrangement
            self.dataSchema = dataSchema
            self.dataSchemaLocationS3 = dataSchemaLocationS3
        }

        public func validate(name: String) throws {
            try self.validate(self.dataLocationS3, name: "dataLocationS3", parent: name, max: 2048)
            try self.validate(self.dataLocationS3, name: "dataLocationS3", parent: name, pattern: "s3://([^/]+)(/.*)?")
            try self.validate(self.dataSchema, name: "dataSchema", parent: name, max: 131_071)
            try self.validate(self.dataSchemaLocationS3, name: "dataSchemaLocationS3", parent: name, max: 2048)
            try self.validate(self.dataSchemaLocationS3, name: "dataSchemaLocationS3", parent: name, pattern: "s3://([^/]+)(/.*)?")
        }

        private enum CodingKeys: String, CodingKey {
            case dataLocationS3 = "DataLocationS3"
            case dataRearrangement = "DataRearrangement"
            case dataSchema = "DataSchema"
            case dataSchemaLocationS3 = "DataSchemaLocationS3"
        }
    }

    public struct Tag: AWSEncodableShape & AWSDecodableShape {
        /// A unique identifier for the tag. Valid characters include Unicode letters, digits, white space, _, ., /, =, +, -, %, and @.
        public let key: String?
        /// An optional string, typically used to describe or define the tag. Valid characters include Unicode letters, digits, white space, _, ., /, =, +, -, %, and @.
        public let value: String?

        public init(key: String? = nil, value: String? = nil) {
            self.key = key
            self.value = value
        }

        public func validate(name: String) throws {
            try self.validate(self.key, name: "key", parent: name, max: 128)
            try self.validate(self.key, name: "key", parent: name, min: 1)
            try self.validate(self.key, name: "key", parent: name, pattern: "^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$")
            try self.validate(self.value, name: "value", parent: name, max: 256)
            try self.validate(self.value, name: "value", parent: name, pattern: "^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$")
        }

        private enum CodingKeys: String, CodingKey {
            case key = "Key"
            case value = "Value"
        }
    }

    public struct UpdateBatchPredictionInput: AWSEncodableShape {
        /// The ID assigned to the BatchPrediction during creation.
        public let batchPredictionId: String
        /// A new user-supplied name or description of the BatchPrediction.
        public let batchPredictionName: String

        public init(batchPredictionId: String, batchPredictionName: String) {
            self.batchPredictionId = batchPredictionId
            self.batchPredictionName = batchPredictionName
        }

        public func validate(name: String) throws {
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, max: 64)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, min: 1)
            try self.validate(self.batchPredictionId, name: "batchPredictionId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.batchPredictionName, name: "batchPredictionName", parent: name, max: 1024)
            try self.validate(self.batchPredictionName, name: "batchPredictionName", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
            case batchPredictionName = "BatchPredictionName"
        }
    }

    public struct UpdateBatchPredictionOutput: AWSDecodableShape {
        /// The ID assigned to the BatchPrediction during creation.  This value should be identical to the value  of the BatchPredictionId in the request.
        public let batchPredictionId: String?

        public init(batchPredictionId: String? = nil) {
            self.batchPredictionId = batchPredictionId
        }

        private enum CodingKeys: String, CodingKey {
            case batchPredictionId = "BatchPredictionId"
        }
    }

    public struct UpdateDataSourceInput: AWSEncodableShape {
        /// The ID assigned to the DataSource during creation.
        public let dataSourceId: String
        /// A new user-supplied name or description of the DataSource that will replace the current description.
        public let dataSourceName: String

        public init(dataSourceId: String, dataSourceName: String) {
            self.dataSourceId = dataSourceId
            self.dataSourceName = dataSourceName
        }

        public func validate(name: String) throws {
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, max: 64)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, min: 1)
            try self.validate(self.dataSourceId, name: "dataSourceId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, max: 1024)
            try self.validate(self.dataSourceName, name: "dataSourceName", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
            case dataSourceName = "DataSourceName"
        }
    }

    public struct UpdateDataSourceOutput: AWSDecodableShape {
        /// The ID assigned to the DataSource during creation.  This value should be identical to the value  of the DataSourceID in the request.
        public let dataSourceId: String?

        public init(dataSourceId: String? = nil) {
            self.dataSourceId = dataSourceId
        }

        private enum CodingKeys: String, CodingKey {
            case dataSourceId = "DataSourceId"
        }
    }

    public struct UpdateEvaluationInput: AWSEncodableShape {
        /// The ID assigned to the Evaluation during creation.
        public let evaluationId: String
        /// A new user-supplied name or description of the Evaluation that will replace the current content.
        public let evaluationName: String

        public init(evaluationId: String, evaluationName: String) {
            self.evaluationId = evaluationId
            self.evaluationName = evaluationName
        }

        public func validate(name: String) throws {
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, max: 64)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, min: 1)
            try self.validate(self.evaluationId, name: "evaluationId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.evaluationName, name: "evaluationName", parent: name, max: 1024)
            try self.validate(self.evaluationName, name: "evaluationName", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
            case evaluationName = "EvaluationName"
        }
    }

    public struct UpdateEvaluationOutput: AWSDecodableShape {
        /// The ID assigned to the Evaluation during creation.  This value should be identical to the value  of the Evaluation in the request.
        public let evaluationId: String?

        public init(evaluationId: String? = nil) {
            self.evaluationId = evaluationId
        }

        private enum CodingKeys: String, CodingKey {
            case evaluationId = "EvaluationId"
        }
    }

    public struct UpdateMLModelInput: AWSEncodableShape {
        /// The ID assigned to the MLModel during creation.
        public let mLModelId: String
        /// A user-supplied name or description of the MLModel.
        public let mLModelName: String?
        /// The ScoreThreshold used in binary classification MLModel that marks the boundary between a positive prediction and a negative prediction. Output values greater than or equal to the ScoreThreshold receive a positive result from the MLModel, such as true. Output values less than the ScoreThreshold receive a negative response from the MLModel, such as false.
        public let scoreThreshold: Float?

        public init(mLModelId: String, mLModelName: String? = nil, scoreThreshold: Float? = nil) {
            self.mLModelId = mLModelId
            self.mLModelName = mLModelName
            self.scoreThreshold = scoreThreshold
        }

        public func validate(name: String) throws {
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, max: 64)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, min: 1)
            try self.validate(self.mLModelId, name: "mLModelId", parent: name, pattern: "[a-zA-Z0-9_.-]+")
            try self.validate(self.mLModelName, name: "mLModelName", parent: name, max: 1024)
            try self.validate(self.mLModelName, name: "mLModelName", parent: name, pattern: ".*\\S.*|^$")
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
            case mLModelName = "MLModelName"
            case scoreThreshold = "ScoreThreshold"
        }
    }

    public struct UpdateMLModelOutput: AWSDecodableShape {
        /// The ID assigned to the MLModel during creation.  This value should be identical to the value  of the MLModelID in the request.
        public let mLModelId: String?

        public init(mLModelId: String? = nil) {
            self.mLModelId = mLModelId
        }

        private enum CodingKeys: String, CodingKey {
            case mLModelId = "MLModelId"
        }
    }
}
