//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2024 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

#if canImport(FoundationEssentials)
import FoundationEssentials
#else
import Foundation
#endif
@_exported import SotoCore

/// Service object for interacting with AWS AutoScaling service.
///
/// Amazon EC2 Auto Scaling Amazon EC2 Auto Scaling is designed to automatically launch and terminate EC2 instances based on user-defined scaling policies, scheduled actions, and health checks. For more information, see the Amazon EC2 Auto Scaling User Guide and the Amazon EC2 Auto Scaling API Reference.
public struct AutoScaling: AWSService {
    // MARK: Member variables

    /// Client used for communication with AWS
    public let client: AWSClient
    /// Service configuration
    public let config: AWSServiceConfig

    // MARK: Initialization

    /// Initialize the AutoScaling client
    /// - parameters:
    ///     - client: AWSClient used to process requests
    ///     - region: Region of server you want to communicate with. This will override the partition parameter.
    ///     - partition: AWS partition where service resides, standard (.aws), china (.awscn), government (.awsusgov).
    ///     - endpoint: Custom endpoint URL to use instead of standard AWS servers
    ///     - middleware: Middleware chain used to edit requests before they are sent and responses before they are decoded 
    ///     - timeout: Timeout value for HTTP requests
    ///     - byteBufferAllocator: Allocator for ByteBuffers
    ///     - options: Service options
    public init(
        client: AWSClient,
        region: SotoCore.Region? = nil,
        partition: AWSPartition = .aws,
        endpoint: String? = nil,
        middleware: AWSMiddlewareProtocol? = nil,
        timeout: TimeAmount? = nil,
        byteBufferAllocator: ByteBufferAllocator = ByteBufferAllocator(),
        options: AWSServiceConfig.Options = []
    ) {
        self.client = client
        self.config = AWSServiceConfig(
            region: region,
            partition: region?.partition ?? partition,
            serviceName: "AutoScaling",
            serviceIdentifier: "autoscaling",
            serviceProtocol: .query,
            apiVersion: "2011-01-01",
            endpoint: endpoint,
            variantEndpoints: Self.variantEndpoints,
            errorType: AutoScalingErrorType.self,
            xmlNamespace: "http://autoscaling.amazonaws.com/doc/2011-01-01/",
            middleware: middleware,
            timeout: timeout,
            byteBufferAllocator: byteBufferAllocator,
            options: options
        )
    }




    /// FIPS and dualstack endpoints
    static var variantEndpoints: [EndpointVariantType: AWSServiceConfig.EndpointVariant] {[
        [.fips]: .init(endpoints: [
            "ca-central-1": "autoscaling-fips.ca-central-1.amazonaws.com",
            "ca-west-1": "autoscaling-fips.ca-west-1.amazonaws.com",
            "us-east-1": "autoscaling-fips.us-east-1.amazonaws.com",
            "us-east-2": "autoscaling-fips.us-east-2.amazonaws.com",
            "us-gov-east-1": "autoscaling.us-gov-east-1.amazonaws.com",
            "us-gov-west-1": "autoscaling.us-gov-west-1.amazonaws.com",
            "us-west-1": "autoscaling-fips.us-west-1.amazonaws.com",
            "us-west-2": "autoscaling-fips.us-west-2.amazonaws.com"
        ])
    ]}

    // MARK: API Calls

    /// Attaches one or more EC2 instances to the specified Auto Scaling group. When you attach instances, Amazon EC2 Auto Scaling increases the desired capacity of the group by the number of instances being attached. If the number of instances being attached plus the desired capacity of the group exceeds the maximum size of the group, the operation fails. If there is a Classic Load Balancer attached to your Auto Scaling group, the instances are also registered with the load balancer. If there are target groups attached to your Auto Scaling group, the instances are also registered with the target groups. For more information, see Detach or attach instances in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func attachInstances(_ input: AttachInstancesQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "AttachInstances", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Attaches one or more EC2 instances to the specified Auto Scaling group. When you attach instances, Amazon EC2 Auto Scaling increases the desired capacity of the group by the number of instances being attached. If the number of instances being attached plus the desired capacity of the group exceeds the maximum size of the group, the operation fails. If there is a Classic Load Balancer attached to your Auto Scaling group, the instances are also registered with the load balancer. If there are target groups attached to your Auto Scaling group, the instances are also registered with the target groups. For more information, see Detach or attach instances in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceIds: The IDs of the instances. You can specify up to 20 instances.
    ///   - logger: Logger use during operation
    @inlinable
    public func attachInstances(
        autoScalingGroupName: String? = nil,
        instanceIds: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = AttachInstancesQuery(
            autoScalingGroupName: autoScalingGroupName, 
            instanceIds: instanceIds
        )
        return try await self.attachInstances(input, logger: logger)
    }

    ///  This API operation is superseded by AttachTrafficSources, which can attach multiple traffic sources types. We recommend using AttachTrafficSources to simplify how you manage traffic sources. However, we continue to support AttachLoadBalancerTargetGroups. You can use both the original AttachLoadBalancerTargetGroups API operation and AttachTrafficSources on the same Auto Scaling group.  Attaches one or more target groups to the specified Auto Scaling group. This operation is used with the following load balancer types:    Application Load Balancer - Operates at the application layer (layer 7) and supports HTTP and HTTPS.    Network Load Balancer - Operates at the transport layer (layer 4) and supports TCP, TLS, and UDP.    Gateway Load Balancer - Operates at the network layer (layer 3).   To describe the target groups for an Auto Scaling group, call the DescribeLoadBalancerTargetGroups API. To detach the target group from the Auto Scaling group, call the DetachLoadBalancerTargetGroups API. This operation is additive and does not detach existing target groups or Classic Load Balancers from the Auto Scaling group. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func attachLoadBalancerTargetGroups(_ input: AttachLoadBalancerTargetGroupsType, logger: Logger = AWSClient.loggingDisabled) async throws -> AttachLoadBalancerTargetGroupsResultType {
        try await self.client.execute(
            operation: "AttachLoadBalancerTargetGroups", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by AttachTrafficSources, which can attach multiple traffic sources types. We recommend using AttachTrafficSources to simplify how you manage traffic sources. However, we continue to support AttachLoadBalancerTargetGroups. You can use both the original AttachLoadBalancerTargetGroups API operation and AttachTrafficSources on the same Auto Scaling group.  Attaches one or more target groups to the specified Auto Scaling group. This operation is used with the following load balancer types:    Application Load Balancer - Operates at the application layer (layer 7) and supports HTTP and HTTPS.    Network Load Balancer - Operates at the transport layer (layer 4) and supports TCP, TLS, and UDP.    Gateway Load Balancer - Operates at the network layer (layer 3).   To describe the target groups for an Auto Scaling group, call the DescribeLoadBalancerTargetGroups API. To detach the target group from the Auto Scaling group, call the DetachLoadBalancerTargetGroups API. This operation is additive and does not detach existing target groups or Classic Load Balancers from the Auto Scaling group. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - targetGroupARNs: The Amazon Resource Names (ARNs) of the target groups. You can specify up to 10 target groups. To get the ARN of a target group, use the Elastic Load Balancing DescribeTargetGroups API operation.
    ///   - logger: Logger use during operation
    @inlinable
    public func attachLoadBalancerTargetGroups(
        autoScalingGroupName: String? = nil,
        targetGroupARNs: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> AttachLoadBalancerTargetGroupsResultType {
        let input = AttachLoadBalancerTargetGroupsType(
            autoScalingGroupName: autoScalingGroupName, 
            targetGroupARNs: targetGroupARNs
        )
        return try await self.attachLoadBalancerTargetGroups(input, logger: logger)
    }

    ///  This API operation is superseded by https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_AttachTrafficSources.html, which can attach multiple traffic sources types. We recommend using AttachTrafficSources to simplify how you manage traffic sources. However, we continue to support AttachLoadBalancers. You can use both the original AttachLoadBalancers API operation and AttachTrafficSources on the same Auto Scaling group.  Attaches one or more Classic Load Balancers to the specified Auto Scaling group. Amazon EC2 Auto Scaling registers the running instances with these Classic Load Balancers. To describe the load balancers for an Auto Scaling group, call the DescribeLoadBalancers API. To detach a load balancer from the Auto Scaling group, call the DetachLoadBalancers API. This operation is additive and does not detach existing Classic Load Balancers or target groups from the Auto Scaling group. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func attachLoadBalancers(_ input: AttachLoadBalancersType, logger: Logger = AWSClient.loggingDisabled) async throws -> AttachLoadBalancersResultType {
        try await self.client.execute(
            operation: "AttachLoadBalancers", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_AttachTrafficSources.html, which can attach multiple traffic sources types. We recommend using AttachTrafficSources to simplify how you manage traffic sources. However, we continue to support AttachLoadBalancers. You can use both the original AttachLoadBalancers API operation and AttachTrafficSources on the same Auto Scaling group.  Attaches one or more Classic Load Balancers to the specified Auto Scaling group. Amazon EC2 Auto Scaling registers the running instances with these Classic Load Balancers. To describe the load balancers for an Auto Scaling group, call the DescribeLoadBalancers API. To detach a load balancer from the Auto Scaling group, call the DetachLoadBalancers API. This operation is additive and does not detach existing Classic Load Balancers or target groups from the Auto Scaling group. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - loadBalancerNames: The names of the load balancers. You can specify up to 10 load balancers.
    ///   - logger: Logger use during operation
    @inlinable
    public func attachLoadBalancers(
        autoScalingGroupName: String? = nil,
        loadBalancerNames: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> AttachLoadBalancersResultType {
        let input = AttachLoadBalancersType(
            autoScalingGroupName: autoScalingGroupName, 
            loadBalancerNames: loadBalancerNames
        )
        return try await self.attachLoadBalancers(input, logger: logger)
    }

    /// Attaches one or more traffic sources to the specified Auto Scaling group. You can use any of the following as traffic sources for an Auto Scaling group:   Application Load Balancer   Classic Load Balancer   Gateway Load Balancer   Network Load Balancer   VPC Lattice   This operation is additive and does not detach existing traffic sources from the Auto Scaling group.  After the operation completes, use the DescribeTrafficSources API to return details about the state of the attachments between traffic sources and your Auto Scaling group. To detach a traffic source from the Auto Scaling group, call the  DetachTrafficSources API.
    @Sendable
    @inlinable
    public func attachTrafficSources(_ input: AttachTrafficSourcesType, logger: Logger = AWSClient.loggingDisabled) async throws -> AttachTrafficSourcesResultType {
        try await self.client.execute(
            operation: "AttachTrafficSources", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Attaches one or more traffic sources to the specified Auto Scaling group. You can use any of the following as traffic sources for an Auto Scaling group:   Application Load Balancer   Classic Load Balancer   Gateway Load Balancer   Network Load Balancer   VPC Lattice   This operation is additive and does not detach existing traffic sources from the Auto Scaling group.  After the operation completes, use the DescribeTrafficSources API to return details about the state of the attachments between traffic sources and your Auto Scaling group. To detach a traffic source from the Auto Scaling group, call the  DetachTrafficSources API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - skipZonalShiftValidation:  If you enable zonal shift with cross-zone disabled load balancers, capacity could become imbalanced across Availability Zones. To skip the validation, specify true. For more information, see Auto Scaling group zonal shift in the Amazon EC2 Auto Scaling User Guide.
    ///   - trafficSources: The unique identifiers of one or more traffic sources. You can specify up to 10 traffic sources.
    ///   - logger: Logger use during operation
    @inlinable
    public func attachTrafficSources(
        autoScalingGroupName: String? = nil,
        skipZonalShiftValidation: Bool? = nil,
        trafficSources: [TrafficSourceIdentifier]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> AttachTrafficSourcesResultType {
        let input = AttachTrafficSourcesType(
            autoScalingGroupName: autoScalingGroupName, 
            skipZonalShiftValidation: skipZonalShiftValidation, 
            trafficSources: trafficSources
        )
        return try await self.attachTrafficSources(input, logger: logger)
    }

    /// Deletes one or more scheduled actions for the specified Auto Scaling group.
    @Sendable
    @inlinable
    public func batchDeleteScheduledAction(_ input: BatchDeleteScheduledActionType, logger: Logger = AWSClient.loggingDisabled) async throws -> BatchDeleteScheduledActionAnswer {
        try await self.client.execute(
            operation: "BatchDeleteScheduledAction", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes one or more scheduled actions for the specified Auto Scaling group.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - scheduledActionNames: The names of the scheduled actions to delete. The maximum number allowed is 50.
    ///   - logger: Logger use during operation
    @inlinable
    public func batchDeleteScheduledAction(
        autoScalingGroupName: String? = nil,
        scheduledActionNames: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> BatchDeleteScheduledActionAnswer {
        let input = BatchDeleteScheduledActionType(
            autoScalingGroupName: autoScalingGroupName, 
            scheduledActionNames: scheduledActionNames
        )
        return try await self.batchDeleteScheduledAction(input, logger: logger)
    }

    /// Creates or updates one or more scheduled scaling actions for an Auto Scaling group.
    @Sendable
    @inlinable
    public func batchPutScheduledUpdateGroupAction(_ input: BatchPutScheduledUpdateGroupActionType, logger: Logger = AWSClient.loggingDisabled) async throws -> BatchPutScheduledUpdateGroupActionAnswer {
        try await self.client.execute(
            operation: "BatchPutScheduledUpdateGroupAction", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates one or more scheduled scaling actions for an Auto Scaling group.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - scheduledUpdateGroupActions: One or more scheduled actions. The maximum number allowed is 50.
    ///   - logger: Logger use during operation
    @inlinable
    public func batchPutScheduledUpdateGroupAction(
        autoScalingGroupName: String? = nil,
        scheduledUpdateGroupActions: [ScheduledUpdateGroupActionRequest]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> BatchPutScheduledUpdateGroupActionAnswer {
        let input = BatchPutScheduledUpdateGroupActionType(
            autoScalingGroupName: autoScalingGroupName, 
            scheduledUpdateGroupActions: scheduledUpdateGroupActions
        )
        return try await self.batchPutScheduledUpdateGroupAction(input, logger: logger)
    }

    /// Cancels an instance refresh or rollback that is in progress. If an instance refresh or rollback is not in progress, an ActiveInstanceRefreshNotFound error occurs. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. When you cancel an instance refresh, this does not roll back any changes that it made. Use the RollbackInstanceRefresh API to roll back instead.
    @Sendable
    @inlinable
    public func cancelInstanceRefresh(_ input: CancelInstanceRefreshType, logger: Logger = AWSClient.loggingDisabled) async throws -> CancelInstanceRefreshAnswer {
        try await self.client.execute(
            operation: "CancelInstanceRefresh", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Cancels an instance refresh or rollback that is in progress. If an instance refresh or rollback is not in progress, an ActiveInstanceRefreshNotFound error occurs. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. When you cancel an instance refresh, this does not roll back any changes that it made. Use the RollbackInstanceRefresh API to roll back instead.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - logger: Logger use during operation
    @inlinable
    public func cancelInstanceRefresh(
        autoScalingGroupName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CancelInstanceRefreshAnswer {
        let input = CancelInstanceRefreshType(
            autoScalingGroupName: autoScalingGroupName
        )
        return try await self.cancelInstanceRefresh(input, logger: logger)
    }

    /// Completes the lifecycle action for the specified token or instance with the specified result. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.   Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.   If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.    If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.    For more information, see Complete a lifecycle action in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func completeLifecycleAction(_ input: CompleteLifecycleActionType, logger: Logger = AWSClient.loggingDisabled) async throws -> CompleteLifecycleActionAnswer {
        try await self.client.execute(
            operation: "CompleteLifecycleAction", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Completes the lifecycle action for the specified token or instance with the specified result. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.   Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.   If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.    If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.    For more information, see Complete a lifecycle action in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceId: The ID of the instance.
    ///   - lifecycleActionResult: The action for the group to take. You can specify either CONTINUE or ABANDON.
    ///   - lifecycleActionToken: A universally unique identifier (UUID) that identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target you specified when you created the lifecycle hook.
    ///   - lifecycleHookName: The name of the lifecycle hook.
    ///   - logger: Logger use during operation
    @inlinable
    public func completeLifecycleAction(
        autoScalingGroupName: String? = nil,
        instanceId: String? = nil,
        lifecycleActionResult: String? = nil,
        lifecycleActionToken: String? = nil,
        lifecycleHookName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> CompleteLifecycleActionAnswer {
        let input = CompleteLifecycleActionType(
            autoScalingGroupName: autoScalingGroupName, 
            instanceId: instanceId, 
            lifecycleActionResult: lifecycleActionResult, 
            lifecycleActionToken: lifecycleActionToken, 
            lifecycleHookName: lifecycleHookName
        )
        return try await self.completeLifecycleAction(input, logger: logger)
    }

    ///  We strongly recommend using a launch template when calling this operation to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.  Creates an Auto Scaling group with the specified name and attributes.  If you exceed your maximum limit of Auto Scaling groups, the call fails. To query this limit, call the DescribeAccountLimits API. For information about updating this limit, see Quotas for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. If you're new to Amazon EC2 Auto Scaling, see the introductory tutorials in Get started with Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Every Auto Scaling group has three size properties (DesiredCapacity, MaxSize, and MinSize). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances.
    @Sendable
    @inlinable
    public func createAutoScalingGroup(_ input: CreateAutoScalingGroupType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "CreateAutoScalingGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  We strongly recommend using a launch template when calling this operation to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.  Creates an Auto Scaling group with the specified name and attributes.  If you exceed your maximum limit of Auto Scaling groups, the call fails. To query this limit, call the DescribeAccountLimits API. For information about updating this limit, see Quotas for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. If you're new to Amazon EC2 Auto Scaling, see the introductory tutorials in Get started with Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Every Auto Scaling group has three size properties (DesiredCapacity, MaxSize, and MinSize). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group. This name must be unique per Region per account. The name can contain any ASCII character 33 to 126 including most punctuation characters, digits, and upper and lowercased letters.  You cannot use a colon (:) in the name.
    ///   - availabilityZoneDistribution: The instance capacity distribution across Availability Zones.
    ///   - availabilityZoneImpairmentPolicy:  The policy for Availability Zone impairment.
    ///   - availabilityZones: A list of Availability Zones where instances in the Auto Scaling group can be created. Used for launching into the default VPC subnet in each Availability Zone when not using the VPCZoneIdentifier property, or for attaching a network interface when an existing network interface ID is specified in a launch template.
    ///   - capacityRebalance: Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see Use Capacity Rebalancing to handle Amazon EC2 Spot Interruptions in the in the Amazon EC2 Auto Scaling User Guide.
    ///   - capacityReservationSpecification:  The capacity reservation specification for the Auto Scaling group.
    ///   - context: Reserved.
    ///   - defaultCooldown:  Only needed if you use simple scaling policies.  The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see Scaling cooldowns for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Default: 300 seconds
    ///   - defaultInstanceWarmup: The amount of time, in seconds, until a new instance is considered to have finished initializing and resource consumption to become stable after it enters the InService state.  During an instance refresh, Amazon EC2 Auto Scaling waits for the warm-up period after it replaces an instance before it moves on to replacing the next instance. Amazon EC2 Auto Scaling also waits for the warm-up period before aggregating the metrics for new instances with existing instances in the Amazon CloudWatch metrics that are used for scaling, resulting in more reliable usage data. For more information, see Set the default instance warmup for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.  To manage various warm-up settings at the group level, we recommend that you set the default instance warmup, even if it is set to 0 seconds. To remove a value that you previously set, include the property but specify -1 for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a value of 0 or other nominal value.  Default: None
    ///   - desiredCapacity: The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure auto scaling. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity, the default is the minimum size of the group.
    ///   - desiredCapacityType: The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports DesiredCapacityType for attribute-based instance type selection only. For more information, see Create a mixed instances group using attribute-based instance type selection in the Amazon EC2 Auto Scaling User Guide. By default, Amazon EC2 Auto Scaling specifies units, which translates into number of instances. Valid values: units | vcpu | memory-mib
    ///   - healthCheckGracePeriod: The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed health check. This is useful if your instances do not immediately pass their health checks after they enter the InService state. For more information, see Set the health check grace period for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide. Default: 0 seconds
    ///   - healthCheckType: A comma-separated value string of one or more health check types. The valid values are EC2, EBS, ELB, and VPC_LATTICE. EC2 is the default health check and cannot be disabled. For more information, see Health checks for instances in an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide. Only specify EC2 if you must clear a value that was previously set.
    ///   - instanceId: The ID of the instance used to base the launch configuration on. If specified, Amazon EC2 Auto Scaling uses the configuration values from the specified instance to create a new launch configuration. To get the instance ID, use the Amazon EC2 DescribeInstances API operation. For more information, see Create an Auto Scaling group using parameters from an existing instance in the Amazon EC2 Auto Scaling User Guide.
    ///   - instanceMaintenancePolicy: An instance maintenance policy. For more information, see Set instance maintenance policy in the Amazon EC2 Auto Scaling User Guide.
    ///   - launchConfigurationName: The name of the launch configuration to use to launch instances.  Conditional: You must specify either a launch template (LaunchTemplate or MixedInstancesPolicy) or a launch configuration (LaunchConfigurationName or InstanceId).
    ///   - launchTemplate: Information used to specify the launch template and version to use to launch instances.  Conditional: You must specify either a launch template (LaunchTemplate or MixedInstancesPolicy) or a launch configuration (LaunchConfigurationName or InstanceId).  The launch template that is specified must be configured for use with an Auto Scaling group. For more information, see Create a launch template for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///   - lifecycleHookSpecificationList: One or more lifecycle hooks to add to the Auto Scaling group before instances are launched.
    ///   - loadBalancerNames: A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the TargetGroupARNs property instead.
    ///   - maxInstanceLifetime: The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see Replace Auto Scaling instances based on maximum instance lifetime in the Amazon EC2 Auto Scaling User Guide.
    ///   - maxSize: The maximum size of the group.  With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above MaxSize to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above MaxSize by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).
    ///   - minSize: The minimum size of the group.
    ///   - mixedInstancesPolicy: The mixed instances policy. For more information, see Auto Scaling groups with multiple instance types and purchase options in the Amazon EC2 Auto Scaling User Guide.
    ///   - newInstancesProtectedFromScaleIn: Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see Use instance scale-in protection in the Amazon EC2 Auto Scaling User Guide.
    ///   - placementGroup: The name of the placement group into which to launch your instances. For more information, see Placement groups in the Amazon EC2 User Guide for Linux Instances.  A cluster placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group.
    ///   - serviceLinkedRoleARN: The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services service on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named AWSServiceRoleForAutoScaling, which it creates if it does not exist. For more information, see Service-linked roles in the Amazon EC2 Auto Scaling User Guide.
    ///   - skipZonalShiftValidation:  If you enable zonal shift with cross-zone disabled load balancers, capacity could become imbalanced across Availability Zones. To skip the validation, specify true. For more information, see Auto Scaling group zonal shift in the Amazon EC2 Auto Scaling User Guide.
    ///   - tags: One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see Tag Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    ///   - targetGroupARNs: The Amazon Resource Names (ARN) of the Elastic Load Balancing target groups to associate with the Auto Scaling group. Instances are registered as targets with the target groups. The target groups receive incoming traffic and route requests to one or more registered targets. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///   - terminationPolicies: A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see Configure termination policies for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Valid values: Default | AllocationStrategy | ClosestToNextInstanceHour | NewestInstance | OldestInstance | OldestLaunchConfiguration | OldestLaunchTemplate | arn:aws:lambda:region:account-id:function:my-function:my-alias
    ///   - trafficSources: The list of traffic sources to attach to this Auto Scaling group. You can use any of the following as traffic sources for an Auto Scaling group: Classic Load Balancer, Application Load Balancer, Gateway Load Balancer, Network Load Balancer, and VPC Lattice.
    ///   - vpcZoneIdentifier: A comma-separated list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If you specify VPCZoneIdentifier with AvailabilityZones, the subnets that you specify must reside in those Availability Zones.
    ///   - logger: Logger use during operation
    @inlinable
    public func createAutoScalingGroup(
        autoScalingGroupName: String? = nil,
        availabilityZoneDistribution: AvailabilityZoneDistribution? = nil,
        availabilityZoneImpairmentPolicy: AvailabilityZoneImpairmentPolicy? = nil,
        availabilityZones: [String]? = nil,
        capacityRebalance: Bool? = nil,
        capacityReservationSpecification: CapacityReservationSpecification? = nil,
        context: String? = nil,
        defaultCooldown: Int? = nil,
        defaultInstanceWarmup: Int? = nil,
        desiredCapacity: Int? = nil,
        desiredCapacityType: String? = nil,
        healthCheckGracePeriod: Int? = nil,
        healthCheckType: String? = nil,
        instanceId: String? = nil,
        instanceMaintenancePolicy: InstanceMaintenancePolicy? = nil,
        launchConfigurationName: String? = nil,
        launchTemplate: LaunchTemplateSpecification? = nil,
        lifecycleHookSpecificationList: [LifecycleHookSpecification]? = nil,
        loadBalancerNames: [String]? = nil,
        maxInstanceLifetime: Int? = nil,
        maxSize: Int? = nil,
        minSize: Int? = nil,
        mixedInstancesPolicy: MixedInstancesPolicy? = nil,
        newInstancesProtectedFromScaleIn: Bool? = nil,
        placementGroup: String? = nil,
        serviceLinkedRoleARN: String? = nil,
        skipZonalShiftValidation: Bool? = nil,
        tags: [Tag]? = nil,
        targetGroupARNs: [String]? = nil,
        terminationPolicies: [String]? = nil,
        trafficSources: [TrafficSourceIdentifier]? = nil,
        vpcZoneIdentifier: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = CreateAutoScalingGroupType(
            autoScalingGroupName: autoScalingGroupName, 
            availabilityZoneDistribution: availabilityZoneDistribution, 
            availabilityZoneImpairmentPolicy: availabilityZoneImpairmentPolicy, 
            availabilityZones: availabilityZones, 
            capacityRebalance: capacityRebalance, 
            capacityReservationSpecification: capacityReservationSpecification, 
            context: context, 
            defaultCooldown: defaultCooldown, 
            defaultInstanceWarmup: defaultInstanceWarmup, 
            desiredCapacity: desiredCapacity, 
            desiredCapacityType: desiredCapacityType, 
            healthCheckGracePeriod: healthCheckGracePeriod, 
            healthCheckType: healthCheckType, 
            instanceId: instanceId, 
            instanceMaintenancePolicy: instanceMaintenancePolicy, 
            launchConfigurationName: launchConfigurationName, 
            launchTemplate: launchTemplate, 
            lifecycleHookSpecificationList: lifecycleHookSpecificationList, 
            loadBalancerNames: loadBalancerNames, 
            maxInstanceLifetime: maxInstanceLifetime, 
            maxSize: maxSize, 
            minSize: minSize, 
            mixedInstancesPolicy: mixedInstancesPolicy, 
            newInstancesProtectedFromScaleIn: newInstancesProtectedFromScaleIn, 
            placementGroup: placementGroup, 
            serviceLinkedRoleARN: serviceLinkedRoleARN, 
            skipZonalShiftValidation: skipZonalShiftValidation, 
            tags: tags, 
            targetGroupARNs: targetGroupARNs, 
            terminationPolicies: terminationPolicies, 
            trafficSources: trafficSources, 
            vpcZoneIdentifier: vpcZoneIdentifier
        )
        return try await self.createAutoScalingGroup(input, logger: logger)
    }

    /// Creates a launch configuration. If you exceed your maximum limit of launch configurations, the call fails. To query this limit, call the DescribeAccountLimits API.  For information about updating this limit, see Quotas for   Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. For more information, see Launch configurations in the Amazon EC2 Auto Scaling User Guide.  Amazon EC2 Auto Scaling configures instances launched as part of an Auto Scaling group using either a launch template or a launch configuration. We strongly recommend that you do not use launch configurations. They do not provide full functionality for Amazon EC2 Auto Scaling or Amazon EC2. For information about using launch templates, see Launch templates in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func createLaunchConfiguration(_ input: CreateLaunchConfigurationType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "CreateLaunchConfiguration", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates a launch configuration. If you exceed your maximum limit of launch configurations, the call fails. To query this limit, call the DescribeAccountLimits API.  For information about updating this limit, see Quotas for   Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. For more information, see Launch configurations in the Amazon EC2 Auto Scaling User Guide.  Amazon EC2 Auto Scaling configures instances launched as part of an Auto Scaling group using either a launch template or a launch configuration. We strongly recommend that you do not use launch configurations. They do not provide full functionality for Amazon EC2 Auto Scaling or Amazon EC2. For information about using launch templates, see Launch templates in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - associatePublicIpAddress: Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. If you specify true, each instance in the Auto Scaling group receives a unique public IPv4 address. For more information, see Provide network connectivity for your Auto Scaling instances using Amazon VPC in the Amazon EC2 Auto Scaling User Guide. If you specify this property, you must specify at least one subnet for VPCZoneIdentifier when you create your group.
    ///   - blockDeviceMappings: The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see Block device mappings in the Amazon EC2 User Guide for Linux Instances.
    ///   - classicLinkVPCId: Available for backward compatibility.
    ///   - classicLinkVPCSecurityGroups: Available for backward compatibility.
    ///   - ebsOptimized: Specifies whether the launch configuration is optimized for EBS I/O (true) or not (false). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see Amazon EBS-optimized instances in the Amazon EC2 User Guide for Linux Instances. The default value is false.
    ///   - iamInstanceProfile: The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see IAM role for applications that run on Amazon EC2 instances in the Amazon EC2 Auto Scaling User Guide.
    ///   - imageId: The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see Find a Linux AMI in the Amazon EC2 User Guide for Linux Instances. If you specify InstanceId, an ImageId is not required.
    ///   - instanceId: The ID of the instance to use to create the launch configuration. The new launch configuration derives attributes from the instance, except for the block device mapping. To create a launch configuration with a block device mapping or override any other instance attributes, specify them as part of the same request. For more information, see Create a launch configuration in the Amazon EC2 Auto Scaling User Guide.
    ///   - instanceMonitoring: Controls whether instances in this group are launched with detailed (true) or basic (false) monitoring. The default value is true (enabled).  When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see Configure monitoring for Auto Scaling instances in the Amazon EC2 Auto Scaling User Guide.
    ///   - instanceType: Specifies the instance type of the EC2 instance. For information about available instance types, see Available instance types in the Amazon EC2 User Guide for Linux Instances. If you specify InstanceId, an InstanceType is not required.
    ///   - kernelId: The ID of the kernel associated with the AMI.  We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see User provided kernels in the Amazon EC2 User Guide for Linux Instances.
    ///   - keyName: The name of the key pair. For more information, see Amazon EC2 key pairs and Amazon EC2 instances in the Amazon EC2 User Guide for Linux Instances.
    ///   - launchConfigurationName: The name of the launch configuration. This name must be unique per Region per account.
    ///   - metadataOptions: The metadata options for the instances. For more information, see Configure the instance metadata options in the Amazon EC2 Auto Scaling User Guide.
    ///   - placementTenancy: The tenancy of the instance, either default or dedicated. An instance with dedicated tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC. To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to default), you must set the value of this property to dedicated. If you specify PlacementTenancy, you must specify at least one subnet for VPCZoneIdentifier when you create your group. Valid values: default | dedicated
    ///   - ramdiskId: The ID of the RAM disk to select.  We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see User provided kernels in the Amazon EC2 User Guide for Linux Instances.
    ///   - securityGroups: A list that contains the security group IDs to assign to the instances in the Auto Scaling group. For more information, see Control traffic to your Amazon Web Services resources using security groups in the Amazon Virtual Private Cloud User Guide.
    ///   - spotPrice: The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see Request Spot Instances for fault-tolerant and flexible applications in the Amazon EC2 Auto Scaling User Guide. Valid Range: Minimum value of 0.001  When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.
    ///   - userData: The user data to make available to the launched EC2 instances. For more information, see Instance metadata and user data (Linux) and Instance metadata and user data (Windows). If you are using a command line tool, base64-encoding is performed for you, and you can load the text from a file. Otherwise, you must provide base64-encoded text. User data is limited to 16 KB.
    ///   - logger: Logger use during operation
    @inlinable
    public func createLaunchConfiguration(
        associatePublicIpAddress: Bool? = nil,
        blockDeviceMappings: [BlockDeviceMapping]? = nil,
        classicLinkVPCId: String? = nil,
        classicLinkVPCSecurityGroups: [String]? = nil,
        ebsOptimized: Bool? = nil,
        iamInstanceProfile: String? = nil,
        imageId: String? = nil,
        instanceId: String? = nil,
        instanceMonitoring: InstanceMonitoring? = nil,
        instanceType: String? = nil,
        kernelId: String? = nil,
        keyName: String? = nil,
        launchConfigurationName: String? = nil,
        metadataOptions: InstanceMetadataOptions? = nil,
        placementTenancy: String? = nil,
        ramdiskId: String? = nil,
        securityGroups: [String]? = nil,
        spotPrice: String? = nil,
        userData: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = CreateLaunchConfigurationType(
            associatePublicIpAddress: associatePublicIpAddress, 
            blockDeviceMappings: blockDeviceMappings, 
            classicLinkVPCId: classicLinkVPCId, 
            classicLinkVPCSecurityGroups: classicLinkVPCSecurityGroups, 
            ebsOptimized: ebsOptimized, 
            iamInstanceProfile: iamInstanceProfile, 
            imageId: imageId, 
            instanceId: instanceId, 
            instanceMonitoring: instanceMonitoring, 
            instanceType: instanceType, 
            kernelId: kernelId, 
            keyName: keyName, 
            launchConfigurationName: launchConfigurationName, 
            metadataOptions: metadataOptions, 
            placementTenancy: placementTenancy, 
            ramdiskId: ramdiskId, 
            securityGroups: securityGroups, 
            spotPrice: spotPrice, 
            userData: userData
        )
        return try await self.createLaunchConfiguration(input, logger: logger)
    }

    /// Creates or updates tags for the specified Auto Scaling group. When you specify a tag with a key that already exists, the operation overwrites the previous tag definition, and you do not get an error message. For more information, see Tag Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func createOrUpdateTags(_ input: CreateOrUpdateTagsType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "CreateOrUpdateTags", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates tags for the specified Auto Scaling group. When you specify a tag with a key that already exists, the operation overwrites the previous tag definition, and you do not get an error message. For more information, see Tag Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - tags: One or more tags.
    ///   - logger: Logger use during operation
    @inlinable
    public func createOrUpdateTags(
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = CreateOrUpdateTagsType(
            tags: tags
        )
        return try await self.createOrUpdateTags(input, logger: logger)
    }

    /// Deletes the specified Auto Scaling group. If the group has instances or scaling activities in progress, you must specify the option to force the deletion in order for it to succeed. The force delete operation will also terminate the EC2 instances. If the group has a warm pool, the force delete option also deletes the warm pool. To remove instances from the Auto Scaling group before deleting it, call the  DetachInstances API with the list of instances and the option to decrement the desired capacity. This ensures that Amazon EC2 Auto Scaling does not launch replacement instances. To terminate all instances before deleting the Auto Scaling group, call the  UpdateAutoScalingGroup API and set the minimum size and desired capacity of the Auto Scaling group to zero. If the group has scaling policies, deleting the group deletes the policies, the underlying alarm actions, and any alarm that no longer has an associated action. For more information, see Delete your Auto Scaling infrastructure in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func deleteAutoScalingGroup(_ input: DeleteAutoScalingGroupType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteAutoScalingGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified Auto Scaling group. If the group has instances or scaling activities in progress, you must specify the option to force the deletion in order for it to succeed. The force delete operation will also terminate the EC2 instances. If the group has a warm pool, the force delete option also deletes the warm pool. To remove instances from the Auto Scaling group before deleting it, call the  DetachInstances API with the list of instances and the option to decrement the desired capacity. This ensures that Amazon EC2 Auto Scaling does not launch replacement instances. To terminate all instances before deleting the Auto Scaling group, call the  UpdateAutoScalingGroup API and set the minimum size and desired capacity of the Auto Scaling group to zero. If the group has scaling policies, deleting the group deletes the policies, the underlying alarm actions, and any alarm that no longer has an associated action. For more information, see Delete your Auto Scaling infrastructure in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - forceDelete: Specifies that the group is to be deleted along with all instances associated with the group, without waiting for all instances to be terminated. This action also deletes any outstanding lifecycle actions associated with the group.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteAutoScalingGroup(
        autoScalingGroupName: String? = nil,
        forceDelete: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteAutoScalingGroupType(
            autoScalingGroupName: autoScalingGroupName, 
            forceDelete: forceDelete
        )
        return try await self.deleteAutoScalingGroup(input, logger: logger)
    }

    /// Deletes the specified launch configuration. The launch configuration must not be attached to an Auto Scaling group. When this call completes, the launch configuration is no longer available for use.
    @Sendable
    @inlinable
    public func deleteLaunchConfiguration(_ input: LaunchConfigurationNameType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteLaunchConfiguration", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified launch configuration. The launch configuration must not be attached to an Auto Scaling group. When this call completes, the launch configuration is no longer available for use.
    ///
    /// Parameters:
    ///   - launchConfigurationName: The name of the launch configuration.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteLaunchConfiguration(
        launchConfigurationName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = LaunchConfigurationNameType(
            launchConfigurationName: launchConfigurationName
        )
        return try await self.deleteLaunchConfiguration(input, logger: logger)
    }

    /// Deletes the specified lifecycle hook. If there are any outstanding lifecycle actions, they are completed first (ABANDON for launching instances, CONTINUE for terminating instances).
    @Sendable
    @inlinable
    public func deleteLifecycleHook(_ input: DeleteLifecycleHookType, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteLifecycleHookAnswer {
        try await self.client.execute(
            operation: "DeleteLifecycleHook", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified lifecycle hook. If there are any outstanding lifecycle actions, they are completed first (ABANDON for launching instances, CONTINUE for terminating instances).
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - lifecycleHookName: The name of the lifecycle hook.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteLifecycleHook(
        autoScalingGroupName: String? = nil,
        lifecycleHookName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteLifecycleHookAnswer {
        let input = DeleteLifecycleHookType(
            autoScalingGroupName: autoScalingGroupName, 
            lifecycleHookName: lifecycleHookName
        )
        return try await self.deleteLifecycleHook(input, logger: logger)
    }

    /// Deletes the specified notification.
    @Sendable
    @inlinable
    public func deleteNotificationConfiguration(_ input: DeleteNotificationConfigurationType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteNotificationConfiguration", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified notification.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - topicARN: The Amazon Resource Name (ARN) of the Amazon SNS topic.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteNotificationConfiguration(
        autoScalingGroupName: String? = nil,
        topicARN: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteNotificationConfigurationType(
            autoScalingGroupName: autoScalingGroupName, 
            topicARN: topicARN
        )
        return try await self.deleteNotificationConfiguration(input, logger: logger)
    }

    /// Deletes the specified scaling policy. Deleting either a step scaling policy or a simple scaling policy deletes the underlying alarm action, but does not delete the alarm, even if it no longer has an associated action. For more information, see Delete a scaling policy in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func deletePolicy(_ input: DeletePolicyType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeletePolicy", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified scaling policy. Deleting either a step scaling policy or a simple scaling policy deletes the underlying alarm action, but does not delete the alarm, even if it no longer has an associated action. For more information, see Delete a scaling policy in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - policyName: The name or Amazon Resource Name (ARN) of the policy.
    ///   - logger: Logger use during operation
    @inlinable
    public func deletePolicy(
        autoScalingGroupName: String? = nil,
        policyName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeletePolicyType(
            autoScalingGroupName: autoScalingGroupName, 
            policyName: policyName
        )
        return try await self.deletePolicy(input, logger: logger)
    }

    /// Deletes the specified scheduled action.
    @Sendable
    @inlinable
    public func deleteScheduledAction(_ input: DeleteScheduledActionType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteScheduledAction", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified scheduled action.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - scheduledActionName: The name of the action to delete.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteScheduledAction(
        autoScalingGroupName: String? = nil,
        scheduledActionName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteScheduledActionType(
            autoScalingGroupName: autoScalingGroupName, 
            scheduledActionName: scheduledActionName
        )
        return try await self.deleteScheduledAction(input, logger: logger)
    }

    /// Deletes the specified tags.
    @Sendable
    @inlinable
    public func deleteTags(_ input: DeleteTagsType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DeleteTags", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the specified tags.
    ///
    /// Parameters:
    ///   - tags: One or more tags.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteTags(
        tags: [Tag]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DeleteTagsType(
            tags: tags
        )
        return try await self.deleteTags(input, logger: logger)
    }

    /// Deletes the warm pool for the specified Auto Scaling group. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func deleteWarmPool(_ input: DeleteWarmPoolType, logger: Logger = AWSClient.loggingDisabled) async throws -> DeleteWarmPoolAnswer {
        try await self.client.execute(
            operation: "DeleteWarmPool", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Deletes the warm pool for the specified Auto Scaling group. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - forceDelete: Specifies that the warm pool is to be deleted along with all of its associated instances, without waiting for all instances to be terminated. This parameter also deletes any outstanding lifecycle actions associated with the warm pool instances.
    ///   - logger: Logger use during operation
    @inlinable
    public func deleteWarmPool(
        autoScalingGroupName: String? = nil,
        forceDelete: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DeleteWarmPoolAnswer {
        let input = DeleteWarmPoolType(
            autoScalingGroupName: autoScalingGroupName, 
            forceDelete: forceDelete
        )
        return try await self.deleteWarmPool(input, logger: logger)
    }

    /// Describes the current Amazon EC2 Auto Scaling resource quotas for your account. When you establish an Amazon Web Services account, the account has initial quotas on the maximum number of Auto Scaling groups and launch configurations that you can create in a given Region. For more information, see Quotas for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeAccountLimits(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeAccountLimitsAnswer {
        try await self.client.execute(
            operation: "DescribeAccountLimits", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Describes the available adjustment types for step scaling and simple scaling policies. The following adjustment types are supported:    ChangeInCapacity     ExactCapacity     PercentChangeInCapacity
    @Sendable
    @inlinable
    public func describeAdjustmentTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeAdjustmentTypesAnswer {
        try await self.client.execute(
            operation: "DescribeAdjustmentTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the Auto Scaling groups in the account and Region. If you specify Auto Scaling group names, the output includes information for only the specified Auto Scaling groups. If you specify filters, the output includes information for only those Auto Scaling groups that meet the filter criteria. If you do not specify group names or filters, the output includes information for all Auto Scaling groups.  This operation also returns information about instances in Auto Scaling groups. To retrieve information about the instances in a warm pool, you must call the  DescribeWarmPool API.
    @Sendable
    @inlinable
    public func describeAutoScalingGroups(_ input: AutoScalingGroupNamesType, logger: Logger = AWSClient.loggingDisabled) async throws -> AutoScalingGroupsType {
        try await self.client.execute(
            operation: "DescribeAutoScalingGroups", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the Auto Scaling groups in the account and Region. If you specify Auto Scaling group names, the output includes information for only the specified Auto Scaling groups. If you specify filters, the output includes information for only those Auto Scaling groups that meet the filter criteria. If you do not specify group names or filters, the output includes information for all Auto Scaling groups.  This operation also returns information about instances in Auto Scaling groups. To retrieve information about the instances in a warm pool, you must call the  DescribeWarmPool API.
    ///
    /// Parameters:
    ///   - autoScalingGroupNames: The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the MaxRecords property. If you omit this property, all Auto Scaling groups are described.
    ///   - filters: One or more filters to limit the results based on specific tags.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeAutoScalingGroups(
        autoScalingGroupNames: [String]? = nil,
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> AutoScalingGroupsType {
        let input = AutoScalingGroupNamesType(
            autoScalingGroupNames: autoScalingGroupNames, 
            filters: filters, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeAutoScalingGroups(input, logger: logger)
    }

    /// Gets information about the Auto Scaling instances in the account and Region.
    @Sendable
    @inlinable
    public func describeAutoScalingInstances(_ input: DescribeAutoScalingInstancesType, logger: Logger = AWSClient.loggingDisabled) async throws -> AutoScalingInstancesType {
        try await self.client.execute(
            operation: "DescribeAutoScalingInstances", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the Auto Scaling instances in the account and Region.
    ///
    /// Parameters:
    ///   - instanceIds: The IDs of the instances. If you omit this property, all Auto Scaling instances are described. If you specify an ID that does not exist, it is ignored with no error. Array Members: Maximum number of 50 items.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 50.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeAutoScalingInstances(
        instanceIds: [String]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> AutoScalingInstancesType {
        let input = DescribeAutoScalingInstancesType(
            instanceIds: instanceIds, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeAutoScalingInstances(input, logger: logger)
    }

    /// Describes the notification types that are supported by Amazon EC2 Auto Scaling.
    @Sendable
    @inlinable
    public func describeAutoScalingNotificationTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeAutoScalingNotificationTypesAnswer {
        try await self.client.execute(
            operation: "DescribeAutoScalingNotificationTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the instance refreshes for the specified Auto Scaling group from the previous six weeks. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. To help you determine the status of an instance refresh, Amazon EC2 Auto Scaling returns information about the instance refreshes you previously initiated, including their status, start time, end time, the percentage of the instance refresh that is complete, and the number of instances remaining to update before the instance refresh is complete. If a rollback is initiated while an instance refresh is in progress, Amazon EC2 Auto Scaling also returns information about the rollback of the instance refresh.
    @Sendable
    @inlinable
    public func describeInstanceRefreshes(_ input: DescribeInstanceRefreshesType, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeInstanceRefreshesAnswer {
        try await self.client.execute(
            operation: "DescribeInstanceRefreshes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the instance refreshes for the specified Auto Scaling group from the previous six weeks. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. To help you determine the status of an instance refresh, Amazon EC2 Auto Scaling returns information about the instance refreshes you previously initiated, including their status, start time, end time, the percentage of the instance refresh that is complete, and the number of instances remaining to update before the instance refresh is complete. If a rollback is initiated while an instance refresh is in progress, Amazon EC2 Auto Scaling also returns information about the rollback of the instance refresh.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceRefreshIds: One or more instance refresh IDs.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeInstanceRefreshes(
        autoScalingGroupName: String? = nil,
        instanceRefreshIds: [String]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeInstanceRefreshesAnswer {
        let input = DescribeInstanceRefreshesType(
            autoScalingGroupName: autoScalingGroupName, 
            instanceRefreshIds: instanceRefreshIds, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeInstanceRefreshes(input, logger: logger)
    }

    /// Gets information about the launch configurations in the account and Region.
    @Sendable
    @inlinable
    public func describeLaunchConfigurations(_ input: LaunchConfigurationNamesType, logger: Logger = AWSClient.loggingDisabled) async throws -> LaunchConfigurationsType {
        try await self.client.execute(
            operation: "DescribeLaunchConfigurations", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the launch configurations in the account and Region.
    ///
    /// Parameters:
    ///   - launchConfigurationNames: The launch configuration names. If you omit this property, all launch configurations are described. Array Members: Maximum number of 50 items.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeLaunchConfigurations(
        launchConfigurationNames: [String]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> LaunchConfigurationsType {
        let input = LaunchConfigurationNamesType(
            launchConfigurationNames: launchConfigurationNames, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeLaunchConfigurations(input, logger: logger)
    }

    /// Describes the available types of lifecycle hooks. The following hook types are supported:    autoscaling:EC2_INSTANCE_LAUNCHING     autoscaling:EC2_INSTANCE_TERMINATING
    @Sendable
    @inlinable
    public func describeLifecycleHookTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeLifecycleHookTypesAnswer {
        try await self.client.execute(
            operation: "DescribeLifecycleHookTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the lifecycle hooks for the specified Auto Scaling group.
    @Sendable
    @inlinable
    public func describeLifecycleHooks(_ input: DescribeLifecycleHooksType, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeLifecycleHooksAnswer {
        try await self.client.execute(
            operation: "DescribeLifecycleHooks", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the lifecycle hooks for the specified Auto Scaling group.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - lifecycleHookNames: The names of one or more lifecycle hooks. If you omit this property, all lifecycle hooks are described.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeLifecycleHooks(
        autoScalingGroupName: String? = nil,
        lifecycleHookNames: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeLifecycleHooksAnswer {
        let input = DescribeLifecycleHooksType(
            autoScalingGroupName: autoScalingGroupName, 
            lifecycleHookNames: lifecycleHookNames
        )
        return try await self.describeLifecycleHooks(input, logger: logger)
    }

    ///  This API operation is superseded by DescribeTrafficSources, which can describe multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DescribeLoadBalancerTargetGroups. You can use both the original DescribeLoadBalancerTargetGroups API operation and DescribeTrafficSources on the same Auto Scaling group.  Gets information about the Elastic Load Balancing target groups for the specified Auto Scaling group. To determine the attachment status of the target group, use the State element in the response. When you attach a target group to an Auto Scaling group, the initial State value is Adding. The state transitions to Added after all Auto Scaling instances are registered with the target group. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to InService after at least one Auto Scaling instance passes the health check. When the target group is in the InService state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the target group doesn't enter the InService state.  Target groups also have an InService state if you attach them in the CreateAutoScalingGroup API call. If your target group state is InService, but it is not working properly, check the scaling activities by calling DescribeScalingActivities and take any corrective actions necessary. For help with failed health checks, see Troubleshooting Amazon EC2 Auto Scaling: Health checks in the Amazon EC2 Auto Scaling User Guide. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.   You can use this operation to describe target groups that were attached by using AttachLoadBalancerTargetGroups, but not for target groups that were attached by using AttachTrafficSources.
    @Sendable
    @inlinable
    public func describeLoadBalancerTargetGroups(_ input: DescribeLoadBalancerTargetGroupsRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeLoadBalancerTargetGroupsResponse {
        try await self.client.execute(
            operation: "DescribeLoadBalancerTargetGroups", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by DescribeTrafficSources, which can describe multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DescribeLoadBalancerTargetGroups. You can use both the original DescribeLoadBalancerTargetGroups API operation and DescribeTrafficSources on the same Auto Scaling group.  Gets information about the Elastic Load Balancing target groups for the specified Auto Scaling group. To determine the attachment status of the target group, use the State element in the response. When you attach a target group to an Auto Scaling group, the initial State value is Adding. The state transitions to Added after all Auto Scaling instances are registered with the target group. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to InService after at least one Auto Scaling instance passes the health check. When the target group is in the InService state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the target group doesn't enter the InService state.  Target groups also have an InService state if you attach them in the CreateAutoScalingGroup API call. If your target group state is InService, but it is not working properly, check the scaling activities by calling DescribeScalingActivities and take any corrective actions necessary. For help with failed health checks, see Troubleshooting Amazon EC2 Auto Scaling: Health checks in the Amazon EC2 Auto Scaling User Guide. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.   You can use this operation to describe target groups that were attached by using AttachLoadBalancerTargetGroups, but not for target groups that were attached by using AttachTrafficSources.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeLoadBalancerTargetGroups(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeLoadBalancerTargetGroupsResponse {
        let input = DescribeLoadBalancerTargetGroupsRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeLoadBalancerTargetGroups(input, logger: logger)
    }

    ///  This API operation is superseded by DescribeTrafficSources, which can describe multiple traffic sources types. We recommend using DescribeTrafficSources to simplify how you manage traffic sources. However, we continue to support DescribeLoadBalancers. You can use both the original DescribeLoadBalancers API operation and DescribeTrafficSources on the same Auto Scaling group.  Gets information about the load balancers for the specified Auto Scaling group. This operation describes only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the DescribeLoadBalancerTargetGroups API instead. To determine the attachment status of the load balancer, use the State element in the response. When you attach a load balancer to an Auto Scaling group, the initial State value is Adding. The state transitions to Added after all Auto Scaling instances are registered with the load balancer. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to InService after at least one Auto Scaling instance passes the health check. When the load balancer is in the InService state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the load balancer doesn't enter the InService state.  Load balancers also have an InService state if you attach them in the CreateAutoScalingGroup API call. If your load balancer state is InService, but it is not working properly, check the scaling activities by calling DescribeScalingActivities and take any corrective actions necessary. For help with failed health checks, see Troubleshooting Amazon EC2 Auto Scaling: Health checks in the Amazon EC2 Auto Scaling User Guide. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeLoadBalancers(_ input: DescribeLoadBalancersRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeLoadBalancersResponse {
        try await self.client.execute(
            operation: "DescribeLoadBalancers", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by DescribeTrafficSources, which can describe multiple traffic sources types. We recommend using DescribeTrafficSources to simplify how you manage traffic sources. However, we continue to support DescribeLoadBalancers. You can use both the original DescribeLoadBalancers API operation and DescribeTrafficSources on the same Auto Scaling group.  Gets information about the load balancers for the specified Auto Scaling group. This operation describes only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the DescribeLoadBalancerTargetGroups API instead. To determine the attachment status of the load balancer, use the State element in the response. When you attach a load balancer to an Auto Scaling group, the initial State value is Adding. The state transitions to Added after all Auto Scaling instances are registered with the load balancer. If Elastic Load Balancing health checks are enabled for the Auto Scaling group, the state transitions to InService after at least one Auto Scaling instance passes the health check. When the load balancer is in the InService state, Amazon EC2 Auto Scaling can terminate and replace any instances that are reported as unhealthy. If no registered instances pass the health checks, the load balancer doesn't enter the InService state.  Load balancers also have an InService state if you attach them in the CreateAutoScalingGroup API call. If your load balancer state is InService, but it is not working properly, check the scaling activities by calling DescribeScalingActivities and take any corrective actions necessary. For help with failed health checks, see Troubleshooting Amazon EC2 Auto Scaling: Health checks in the Amazon EC2 Auto Scaling User Guide. For more information, see Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeLoadBalancers(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeLoadBalancersResponse {
        let input = DescribeLoadBalancersRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeLoadBalancers(input, logger: logger)
    }

    /// Describes the available CloudWatch metrics for Amazon EC2 Auto Scaling.
    @Sendable
    @inlinable
    public func describeMetricCollectionTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeMetricCollectionTypesAnswer {
        try await self.client.execute(
            operation: "DescribeMetricCollectionTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the Amazon SNS notifications that are configured for one or more Auto Scaling groups.
    @Sendable
    @inlinable
    public func describeNotificationConfigurations(_ input: DescribeNotificationConfigurationsType, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeNotificationConfigurationsAnswer {
        try await self.client.execute(
            operation: "DescribeNotificationConfigurations", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the Amazon SNS notifications that are configured for one or more Auto Scaling groups.
    ///
    /// Parameters:
    ///   - autoScalingGroupNames: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeNotificationConfigurations(
        autoScalingGroupNames: [String]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeNotificationConfigurationsAnswer {
        let input = DescribeNotificationConfigurationsType(
            autoScalingGroupNames: autoScalingGroupNames, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeNotificationConfigurations(input, logger: logger)
    }

    /// Gets information about the scaling policies in the account and Region.
    @Sendable
    @inlinable
    public func describePolicies(_ input: DescribePoliciesType, logger: Logger = AWSClient.loggingDisabled) async throws -> PoliciesType {
        try await self.client.execute(
            operation: "DescribePolicies", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the scaling policies in the account and Region.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to be returned with each call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - policyNames: The names of one or more policies. If you omit this property, all policies are described. If a group name is provided, the results are limited to that group. If you specify an unknown policy name, it is ignored with no error. Array Members: Maximum number of 50 items.
    ///   - policyTypes: One or more policy types. The valid values are SimpleScaling, StepScaling, TargetTrackingScaling, and PredictiveScaling.
    ///   - logger: Logger use during operation
    @inlinable
    public func describePolicies(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        policyNames: [String]? = nil,
        policyTypes: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> PoliciesType {
        let input = DescribePoliciesType(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            nextToken: nextToken, 
            policyNames: policyNames, 
            policyTypes: policyTypes
        )
        return try await self.describePolicies(input, logger: logger)
    }

    /// Gets information about the scaling activities in the account and Region. When scaling events occur, you see a record of the scaling activity in the scaling activities. For more information, see Verify a scaling activity for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide. If the scaling event succeeds, the value of the StatusCode element in the response is Successful. If an attempt to launch instances failed, the StatusCode value is Failed or Cancelled and the StatusMessage element in the response indicates the cause of the failure. For help interpreting the StatusMessage, see Troubleshooting Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeScalingActivities(_ input: DescribeScalingActivitiesType, logger: Logger = AWSClient.loggingDisabled) async throws -> ActivitiesType {
        try await self.client.execute(
            operation: "DescribeScalingActivities", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the scaling activities in the account and Region. When scaling events occur, you see a record of the scaling activity in the scaling activities. For more information, see Verify a scaling activity for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide. If the scaling event succeeds, the value of the StatusCode element in the response is Successful. If an attempt to launch instances failed, the StatusCode value is Failed or Cancelled and the StatusMessage element in the response indicates the cause of the failure. For help interpreting the StatusMessage, see Troubleshooting Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - activityIds: The activity IDs of the desired scaling activities. If you omit this property, all activities for the past six weeks are described. If unknown activities are requested, they are ignored with no error. If you specify an Auto Scaling group, the results are limited to that group. Array Members: Maximum number of 50 IDs.
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - includeDeletedGroups: Indicates whether to include scaling activity from deleted Auto Scaling groups.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeScalingActivities(
        activityIds: [String]? = nil,
        autoScalingGroupName: String? = nil,
        includeDeletedGroups: Bool? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ActivitiesType {
        let input = DescribeScalingActivitiesType(
            activityIds: activityIds, 
            autoScalingGroupName: autoScalingGroupName, 
            includeDeletedGroups: includeDeletedGroups, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeScalingActivities(input, logger: logger)
    }

    /// Describes the scaling process types for use with the ResumeProcesses  and SuspendProcesses APIs.
    @Sendable
    @inlinable
    public func describeScalingProcessTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> ProcessesType {
        try await self.client.execute(
            operation: "DescribeScalingProcessTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the scheduled actions that haven't run or that have not reached their end time. To describe the scaling activities for scheduled actions that have already run, call the DescribeScalingActivities API.
    @Sendable
    @inlinable
    public func describeScheduledActions(_ input: DescribeScheduledActionsType, logger: Logger = AWSClient.loggingDisabled) async throws -> ScheduledActionsType {
        try await self.client.execute(
            operation: "DescribeScheduledActions", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the scheduled actions that haven't run or that have not reached their end time. To describe the scaling activities for scheduled actions that have already run, call the DescribeScalingActivities API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - endTime: The latest scheduled start time to return. If scheduled action names are provided, this property is ignored.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - scheduledActionNames: The names of one or more scheduled actions. If you omit this property, all scheduled actions are described. If you specify an unknown scheduled action, it is ignored with no error. Array Members: Maximum number of 50 actions.
    ///   - startTime: The earliest scheduled start time to return. If scheduled action names are provided, this property is ignored.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeScheduledActions(
        autoScalingGroupName: String? = nil,
        endTime: Date? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        scheduledActionNames: [String]? = nil,
        startTime: Date? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ScheduledActionsType {
        let input = DescribeScheduledActionsType(
            autoScalingGroupName: autoScalingGroupName, 
            endTime: endTime, 
            maxRecords: maxRecords, 
            nextToken: nextToken, 
            scheduledActionNames: scheduledActionNames, 
            startTime: startTime
        )
        return try await self.describeScheduledActions(input, logger: logger)
    }

    /// Describes the specified tags. You can use filters to limit the results. For example, you can query for the tags for a specific Auto Scaling group. You can specify multiple values for a filter. A tag must match at least one of the specified values for it to be included in the results. You can also specify multiple filters. The result includes information for a particular tag only if it matches all the filters. If there's no match, no special message is returned. For more information, see Tag Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeTags(_ input: DescribeTagsType, logger: Logger = AWSClient.loggingDisabled) async throws -> TagsType {
        try await self.client.execute(
            operation: "DescribeTags", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Describes the specified tags. You can use filters to limit the results. For example, you can query for the tags for a specific Auto Scaling group. You can specify multiple values for a filter. A tag must match at least one of the specified values for it to be included in the results. You can also specify multiple filters. The result includes information for a particular tag only if it matches all the filters. If there's no match, no special message is returned. For more information, see Tag Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - filters: One or more filters to scope the tags to return. The maximum number of filters per filter type (for example, auto-scaling-group) is 1000.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeTags(
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> TagsType {
        let input = DescribeTagsType(
            filters: filters, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeTags(input, logger: logger)
    }

    /// Describes the termination policies supported by Amazon EC2 Auto Scaling. For more information, see Configure termination policies for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeTerminationPolicyTypes(logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeTerminationPolicyTypesAnswer {
        try await self.client.execute(
            operation: "DescribeTerminationPolicyTypes", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            logger: logger
        )
    }

    /// Gets information about the traffic sources for the specified Auto Scaling group. You can optionally provide a traffic source type. If you provide a traffic source type, then the results only include that traffic source type. If you do not provide a traffic source type, then the results include all the traffic sources for the specified Auto Scaling group.
    @Sendable
    @inlinable
    public func describeTrafficSources(_ input: DescribeTrafficSourcesRequest, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeTrafficSourcesResponse {
        try await self.client.execute(
            operation: "DescribeTrafficSources", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about the traffic sources for the specified Auto Scaling group. You can optionally provide a traffic source type. If you provide a traffic source type, then the results only include that traffic source type. If you do not provide a traffic source type, then the results include all the traffic sources for the specified Auto Scaling group.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The maximum value is 50.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - trafficSourceType: The traffic source type that you want to describe. The following lists the valid values:    elb if the traffic source is a Classic Load Balancer.    elbv2 if the traffic source is a Application Load Balancer, Gateway Load Balancer, or Network Load Balancer.    vpc-lattice if the traffic source is VPC Lattice.
    ///   - logger: Logger use during operation
    @inlinable
    public func describeTrafficSources(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        trafficSourceType: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeTrafficSourcesResponse {
        let input = DescribeTrafficSourcesRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            nextToken: nextToken, 
            trafficSourceType: trafficSourceType
        )
        return try await self.describeTrafficSources(input, logger: logger)
    }

    /// Gets information about a warm pool and its instances. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func describeWarmPool(_ input: DescribeWarmPoolType, logger: Logger = AWSClient.loggingDisabled) async throws -> DescribeWarmPoolAnswer {
        try await self.client.execute(
            operation: "DescribeWarmPool", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Gets information about a warm pool and its instances. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of instances to return with this call. The maximum value is 50.
    ///   - nextToken: The token for the next set of instances to return. (You received this token from a previous call.)
    ///   - logger: Logger use during operation
    @inlinable
    public func describeWarmPool(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DescribeWarmPoolAnswer {
        let input = DescribeWarmPoolType(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        return try await self.describeWarmPool(input, logger: logger)
    }

    /// Removes one or more instances from the specified Auto Scaling group. After the instances are detached, you can manage them independent of the Auto Scaling group. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are detached. If there is a Classic Load Balancer attached to the Auto Scaling group, the instances are deregistered from the load balancer. If there are target groups attached to the Auto Scaling group, the instances are deregistered from the target groups. For more information, see Detach or attach instances in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func detachInstances(_ input: DetachInstancesQuery, logger: Logger = AWSClient.loggingDisabled) async throws -> DetachInstancesAnswer {
        try await self.client.execute(
            operation: "DetachInstances", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Removes one or more instances from the specified Auto Scaling group. After the instances are detached, you can manage them independent of the Auto Scaling group. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are detached. If there is a Classic Load Balancer attached to the Auto Scaling group, the instances are deregistered from the load balancer. If there are target groups attached to the Auto Scaling group, the instances are deregistered from the target groups. For more information, see Detach or attach instances in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceIds: The IDs of the instances. You can specify up to 20 instances.
    ///   - shouldDecrementDesiredCapacity: Indicates whether the Auto Scaling group decrements the desired capacity value by the number of instances detached.
    ///   - logger: Logger use during operation
    @inlinable
    public func detachInstances(
        autoScalingGroupName: String? = nil,
        instanceIds: [String]? = nil,
        shouldDecrementDesiredCapacity: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DetachInstancesAnswer {
        let input = DetachInstancesQuery(
            autoScalingGroupName: autoScalingGroupName, 
            instanceIds: instanceIds, 
            shouldDecrementDesiredCapacity: shouldDecrementDesiredCapacity
        )
        return try await self.detachInstances(input, logger: logger)
    }

    ///  This API operation is superseded by DetachTrafficSources, which can detach multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DetachLoadBalancerTargetGroups. You can use both the original DetachLoadBalancerTargetGroups API operation and DetachTrafficSources on the same Auto Scaling group.  Detaches one or more target groups from the specified Auto Scaling group. When you detach a target group, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the target group using the  DescribeLoadBalancerTargetGroups API call. The instances remain running.  You can use this operation to detach target groups that were attached by using AttachLoadBalancerTargetGroups, but not for target groups that were attached by using AttachTrafficSources.
    @Sendable
    @inlinable
    public func detachLoadBalancerTargetGroups(_ input: DetachLoadBalancerTargetGroupsType, logger: Logger = AWSClient.loggingDisabled) async throws -> DetachLoadBalancerTargetGroupsResultType {
        try await self.client.execute(
            operation: "DetachLoadBalancerTargetGroups", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by DetachTrafficSources, which can detach multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DetachLoadBalancerTargetGroups. You can use both the original DetachLoadBalancerTargetGroups API operation and DetachTrafficSources on the same Auto Scaling group.  Detaches one or more target groups from the specified Auto Scaling group. When you detach a target group, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the target group using the  DescribeLoadBalancerTargetGroups API call. The instances remain running.  You can use this operation to detach target groups that were attached by using AttachLoadBalancerTargetGroups, but not for target groups that were attached by using AttachTrafficSources.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - targetGroupARNs: The Amazon Resource Names (ARN) of the target groups. You can specify up to 10 target groups.
    ///   - logger: Logger use during operation
    @inlinable
    public func detachLoadBalancerTargetGroups(
        autoScalingGroupName: String? = nil,
        targetGroupARNs: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DetachLoadBalancerTargetGroupsResultType {
        let input = DetachLoadBalancerTargetGroupsType(
            autoScalingGroupName: autoScalingGroupName, 
            targetGroupARNs: targetGroupARNs
        )
        return try await self.detachLoadBalancerTargetGroups(input, logger: logger)
    }

    ///  This API operation is superseded by DetachTrafficSources, which can detach multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DetachLoadBalancers. You can use both the original DetachLoadBalancers API operation and DetachTrafficSources on the same Auto Scaling group.  Detaches one or more Classic Load Balancers from the specified Auto Scaling group. This operation detaches only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the DetachLoadBalancerTargetGroups API instead. When you detach a load balancer, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the load balancer using the DescribeLoadBalancers API call. The instances remain running.
    @Sendable
    @inlinable
    public func detachLoadBalancers(_ input: DetachLoadBalancersType, logger: Logger = AWSClient.loggingDisabled) async throws -> DetachLoadBalancersResultType {
        try await self.client.execute(
            operation: "DetachLoadBalancers", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  This API operation is superseded by DetachTrafficSources, which can detach multiple traffic sources types. We recommend using DetachTrafficSources to simplify how you manage traffic sources. However, we continue to support DetachLoadBalancers. You can use both the original DetachLoadBalancers API operation and DetachTrafficSources on the same Auto Scaling group.  Detaches one or more Classic Load Balancers from the specified Auto Scaling group. This operation detaches only Classic Load Balancers. If you have Application Load Balancers, Network Load Balancers, or Gateway Load Balancers, use the DetachLoadBalancerTargetGroups API instead. When you detach a load balancer, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the load balancer using the DescribeLoadBalancers API call. The instances remain running.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - loadBalancerNames: The names of the load balancers. You can specify up to 10 load balancers.
    ///   - logger: Logger use during operation
    @inlinable
    public func detachLoadBalancers(
        autoScalingGroupName: String? = nil,
        loadBalancerNames: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DetachLoadBalancersResultType {
        let input = DetachLoadBalancersType(
            autoScalingGroupName: autoScalingGroupName, 
            loadBalancerNames: loadBalancerNames
        )
        return try await self.detachLoadBalancers(input, logger: logger)
    }

    /// Detaches one or more traffic sources from the specified Auto Scaling group. When you detach a traffic source, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the traffic source using the  DescribeTrafficSources API call. The instances continue to run.
    @Sendable
    @inlinable
    public func detachTrafficSources(_ input: DetachTrafficSourcesType, logger: Logger = AWSClient.loggingDisabled) async throws -> DetachTrafficSourcesResultType {
        try await self.client.execute(
            operation: "DetachTrafficSources", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Detaches one or more traffic sources from the specified Auto Scaling group. When you detach a traffic source, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the traffic source using the  DescribeTrafficSources API call. The instances continue to run.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - trafficSources: The unique identifiers of one or more traffic sources. You can specify up to 10 traffic sources.
    ///   - logger: Logger use during operation
    @inlinable
    public func detachTrafficSources(
        autoScalingGroupName: String? = nil,
        trafficSources: [TrafficSourceIdentifier]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> DetachTrafficSourcesResultType {
        let input = DetachTrafficSourcesType(
            autoScalingGroupName: autoScalingGroupName, 
            trafficSources: trafficSources
        )
        return try await self.detachTrafficSources(input, logger: logger)
    }

    /// Disables group metrics collection for the specified Auto Scaling group.
    @Sendable
    @inlinable
    public func disableMetricsCollection(_ input: DisableMetricsCollectionQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "DisableMetricsCollection", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Disables group metrics collection for the specified Auto Scaling group.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - metrics: Identifies the metrics to disable. You can specify one or more of the following metrics:    GroupMinSize     GroupMaxSize     GroupDesiredCapacity     GroupInServiceInstances     GroupPendingInstances     GroupStandbyInstances     GroupTerminatingInstances     GroupTotalInstances     GroupInServiceCapacity     GroupPendingCapacity     GroupStandbyCapacity     GroupTerminatingCapacity     GroupTotalCapacity     WarmPoolDesiredCapacity     WarmPoolWarmedCapacity     WarmPoolPendingCapacity     WarmPoolTerminatingCapacity     WarmPoolTotalCapacity     GroupAndWarmPoolDesiredCapacity     GroupAndWarmPoolTotalCapacity    If you omit this property, all metrics are disabled. For more information, see Amazon CloudWatch metrics for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func disableMetricsCollection(
        autoScalingGroupName: String? = nil,
        metrics: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = DisableMetricsCollectionQuery(
            autoScalingGroupName: autoScalingGroupName, 
            metrics: metrics
        )
        return try await self.disableMetricsCollection(input, logger: logger)
    }

    /// Enables group metrics collection for the specified Auto Scaling group. You can use these metrics to track changes in an Auto Scaling group and to set alarms on threshold values. You can view group metrics using the Amazon EC2 Auto Scaling console or the CloudWatch console. For more information, see Monitor CloudWatch metrics for your Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func enableMetricsCollection(_ input: EnableMetricsCollectionQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "EnableMetricsCollection", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Enables group metrics collection for the specified Auto Scaling group. You can use these metrics to track changes in an Auto Scaling group and to set alarms on threshold values. You can view group metrics using the Amazon EC2 Auto Scaling console or the CloudWatch console. For more information, see Monitor CloudWatch metrics for your Auto Scaling groups and instances in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - granularity: The frequency at which Amazon EC2 Auto Scaling sends aggregated data to CloudWatch. The only valid value is 1Minute.
    ///   - metrics: Identifies the metrics to enable. You can specify one or more of the following metrics:    GroupMinSize     GroupMaxSize     GroupDesiredCapacity     GroupInServiceInstances     GroupPendingInstances     GroupStandbyInstances     GroupTerminatingInstances     GroupTotalInstances     GroupInServiceCapacity     GroupPendingCapacity     GroupStandbyCapacity     GroupTerminatingCapacity     GroupTotalCapacity     WarmPoolDesiredCapacity     WarmPoolWarmedCapacity     WarmPoolPendingCapacity     WarmPoolTerminatingCapacity     WarmPoolTotalCapacity     GroupAndWarmPoolDesiredCapacity     GroupAndWarmPoolTotalCapacity    If you specify Granularity and don't specify any metrics, all metrics are enabled. For more information, see Amazon CloudWatch metrics for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func enableMetricsCollection(
        autoScalingGroupName: String? = nil,
        granularity: String? = nil,
        metrics: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = EnableMetricsCollectionQuery(
            autoScalingGroupName: autoScalingGroupName, 
            granularity: granularity, 
            metrics: metrics
        )
        return try await self.enableMetricsCollection(input, logger: logger)
    }

    /// Moves the specified instances into the standby state. If you choose to decrement the desired capacity of the Auto Scaling group, the instances can enter standby as long as the desired capacity of the Auto Scaling group after the instances are placed into standby is equal to or greater than the minimum capacity of the group. If you choose not to decrement the desired capacity of the Auto Scaling group, the Auto Scaling group launches new instances to replace the instances on standby. For more information, see Temporarily removing instances from your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func enterStandby(_ input: EnterStandbyQuery, logger: Logger = AWSClient.loggingDisabled) async throws -> EnterStandbyAnswer {
        try await self.client.execute(
            operation: "EnterStandby", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Moves the specified instances into the standby state. If you choose to decrement the desired capacity of the Auto Scaling group, the instances can enter standby as long as the desired capacity of the Auto Scaling group after the instances are placed into standby is equal to or greater than the minimum capacity of the group. If you choose not to decrement the desired capacity of the Auto Scaling group, the Auto Scaling group launches new instances to replace the instances on standby. For more information, see Temporarily removing instances from your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceIds: The IDs of the instances. You can specify up to 20 instances.
    ///   - shouldDecrementDesiredCapacity: Indicates whether to decrement the desired capacity of the Auto Scaling group by the number of instances moved to Standby mode.
    ///   - logger: Logger use during operation
    @inlinable
    public func enterStandby(
        autoScalingGroupName: String? = nil,
        instanceIds: [String]? = nil,
        shouldDecrementDesiredCapacity: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> EnterStandbyAnswer {
        let input = EnterStandbyQuery(
            autoScalingGroupName: autoScalingGroupName, 
            instanceIds: instanceIds, 
            shouldDecrementDesiredCapacity: shouldDecrementDesiredCapacity
        )
        return try await self.enterStandby(input, logger: logger)
    }

    /// Executes the specified policy. This can be useful for testing the design of your scaling policy.
    @Sendable
    @inlinable
    public func executePolicy(_ input: ExecutePolicyType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "ExecutePolicy", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Executes the specified policy. This can be useful for testing the design of your scaling policy.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - breachThreshold: The breach threshold for the alarm. Required if the policy type is StepScaling and not supported otherwise.
    ///   - honorCooldown: Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before executing the policy. Valid only if the policy type is SimpleScaling. For more information, see Scaling cooldowns for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///   - metricValue: The metric value to compare to BreachThreshold. This enables you to execute a policy of type StepScaling and determine which step adjustment to use. For example, if the breach threshold is 50 and you want to use a step adjustment with a lower bound of 0 and an upper bound of 10, you can set the metric value to 59. If you specify a metric value that doesn't correspond to a step adjustment for the policy, the call returns an error. Required if the policy type is StepScaling and not supported otherwise.
    ///   - policyName: The name or ARN of the policy.
    ///   - logger: Logger use during operation
    @inlinable
    public func executePolicy(
        autoScalingGroupName: String? = nil,
        breachThreshold: Double? = nil,
        honorCooldown: Bool? = nil,
        metricValue: Double? = nil,
        policyName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = ExecutePolicyType(
            autoScalingGroupName: autoScalingGroupName, 
            breachThreshold: breachThreshold, 
            honorCooldown: honorCooldown, 
            metricValue: metricValue, 
            policyName: policyName
        )
        return try await self.executePolicy(input, logger: logger)
    }

    /// Moves the specified instances out of the standby state. After you put the instances back in service, the desired capacity is incremented. For more information, see Temporarily removing instances from your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func exitStandby(_ input: ExitStandbyQuery, logger: Logger = AWSClient.loggingDisabled) async throws -> ExitStandbyAnswer {
        try await self.client.execute(
            operation: "ExitStandby", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Moves the specified instances out of the standby state. After you put the instances back in service, the desired capacity is incremented. For more information, see Temporarily removing instances from your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceIds: The IDs of the instances. You can specify up to 20 instances.
    ///   - logger: Logger use during operation
    @inlinable
    public func exitStandby(
        autoScalingGroupName: String? = nil,
        instanceIds: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ExitStandbyAnswer {
        let input = ExitStandbyQuery(
            autoScalingGroupName: autoScalingGroupName, 
            instanceIds: instanceIds
        )
        return try await self.exitStandby(input, logger: logger)
    }

    /// Retrieves the forecast data for a predictive scaling policy. Load forecasts are predictions of the hourly load values using historical load data from CloudWatch and an analysis of historical trends. Capacity forecasts are represented as predicted values for the minimum capacity that is needed on an hourly basis, based on the hourly load forecast. A minimum of 24 hours of data is required to create the initial forecasts. However, having a full 14 days of historical data results in more accurate forecasts. For more information, see Predictive scaling for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func getPredictiveScalingForecast(_ input: GetPredictiveScalingForecastType, logger: Logger = AWSClient.loggingDisabled) async throws -> GetPredictiveScalingForecastAnswer {
        try await self.client.execute(
            operation: "GetPredictiveScalingForecast", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Retrieves the forecast data for a predictive scaling policy. Load forecasts are predictions of the hourly load values using historical load data from CloudWatch and an analysis of historical trends. Capacity forecasts are represented as predicted values for the minimum capacity that is needed on an hourly basis, based on the hourly load forecast. A minimum of 24 hours of data is required to create the initial forecasts. However, having a full 14 days of historical data results in more accurate forecasts. For more information, see Predictive scaling for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - endTime: The exclusive end time of the time range for the forecast data to get. The maximum time duration between the start and end time is 30 days.  Although this parameter can accept a date and time that is more than two days in the future, the availability of forecast data has limits. Amazon EC2 Auto Scaling only issues forecasts for periods of two days in advance.
    ///   - policyName: The name of the policy.
    ///   - startTime: The inclusive start time of the time range for the forecast data to get. At most, the date and time can be one year before the current date and time.
    ///   - logger: Logger use during operation
    @inlinable
    public func getPredictiveScalingForecast(
        autoScalingGroupName: String? = nil,
        endTime: Date? = nil,
        policyName: String? = nil,
        startTime: Date? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> GetPredictiveScalingForecastAnswer {
        let input = GetPredictiveScalingForecastType(
            autoScalingGroupName: autoScalingGroupName, 
            endTime: endTime, 
            policyName: policyName, 
            startTime: startTime
        )
        return try await self.getPredictiveScalingForecast(input, logger: logger)
    }

    /// Creates or updates a lifecycle hook for the specified Auto Scaling group. Lifecycle hooks let you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then perform a custom action on instances when the corresponding lifecycle event occurs. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.    Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.    If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state using the RecordLifecycleActionHeartbeat API call.   If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.   For more information, see Amazon EC2 Auto Scaling lifecycle hooks in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of lifecycle hooks, which by default is 50 per Auto Scaling group, the call fails. You can view the lifecycle hooks for an Auto Scaling group using the  DescribeLifecycleHooks API call. If you are no longer using a lifecycle hook, you can delete it by calling the DeleteLifecycleHook API.
    @Sendable
    @inlinable
    public func putLifecycleHook(_ input: PutLifecycleHookType, logger: Logger = AWSClient.loggingDisabled) async throws -> PutLifecycleHookAnswer {
        try await self.client.execute(
            operation: "PutLifecycleHook", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates a lifecycle hook for the specified Auto Scaling group. Lifecycle hooks let you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then perform a custom action on instances when the corresponding lifecycle event occurs. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.    Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.    If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state using the RecordLifecycleActionHeartbeat API call.   If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.   For more information, see Amazon EC2 Auto Scaling lifecycle hooks in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of lifecycle hooks, which by default is 50 per Auto Scaling group, the call fails. You can view the lifecycle hooks for an Auto Scaling group using the  DescribeLifecycleHooks API call. If you are no longer using a lifecycle hook, you can delete it by calling the DeleteLifecycleHook API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - defaultResult: The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is ABANDON. Valid values: CONTINUE | ABANDON
    ///   - heartbeatTimeout: The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from 30 to 7200 seconds. The default value is 3600 seconds (1 hour).
    ///   - lifecycleHookName: The name of the lifecycle hook.
    ///   - lifecycleTransition: The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions.   To create a lifecycle hook for scale-out events, specify autoscaling:EC2_INSTANCE_LAUNCHING.   To create a lifecycle hook for scale-in events, specify autoscaling:EC2_INSTANCE_TERMINATING.   Required for new lifecycle hooks, but optional when updating existing hooks.
    ///   - notificationMetadata: Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.
    ///   - notificationTargetARN: The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling uses to notify you when an instance is in a wait state for the lifecycle hook. You can specify either an Amazon SNS topic or an Amazon SQS queue. If you specify an empty string, this overrides the current ARN. This operation uses the JSON format when sending notifications to an Amazon SQS queue, and an email key-value pair format when sending notifications to an Amazon SNS topic. When you specify a notification target, Amazon EC2 Auto Scaling sends it a test message. Test messages contain the following additional key-value pair: "Event": "autoscaling:TEST_NOTIFICATION".
    ///   - roleARN: The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue. Required for new lifecycle hooks, but optional when updating existing hooks.
    ///   - logger: Logger use during operation
    @inlinable
    public func putLifecycleHook(
        autoScalingGroupName: String? = nil,
        defaultResult: String? = nil,
        heartbeatTimeout: Int? = nil,
        lifecycleHookName: String? = nil,
        lifecycleTransition: String? = nil,
        notificationMetadata: String? = nil,
        notificationTargetARN: String? = nil,
        roleARN: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> PutLifecycleHookAnswer {
        let input = PutLifecycleHookType(
            autoScalingGroupName: autoScalingGroupName, 
            defaultResult: defaultResult, 
            heartbeatTimeout: heartbeatTimeout, 
            lifecycleHookName: lifecycleHookName, 
            lifecycleTransition: lifecycleTransition, 
            notificationMetadata: notificationMetadata, 
            notificationTargetARN: notificationTargetARN, 
            roleARN: roleARN
        )
        return try await self.putLifecycleHook(input, logger: logger)
    }

    /// Configures an Auto Scaling group to send notifications when specified events take place. Subscribers to the specified topic can have messages delivered to an endpoint such as a web server or an email address. This configuration overwrites any existing configuration. For more information, see Amazon SNS notification options for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of SNS topics, which is 10 per Auto Scaling group, the call fails.
    @Sendable
    @inlinable
    public func putNotificationConfiguration(_ input: PutNotificationConfigurationType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "PutNotificationConfiguration", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Configures an Auto Scaling group to send notifications when specified events take place. Subscribers to the specified topic can have messages delivered to an endpoint such as a web server or an email address. This configuration overwrites any existing configuration. For more information, see Amazon SNS notification options for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of SNS topics, which is 10 per Auto Scaling group, the call fails.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - notificationTypes: The type of event that causes the notification to be sent. To query the notification types supported by Amazon EC2 Auto Scaling, call the DescribeAutoScalingNotificationTypes API.
    ///   - topicARN: The Amazon Resource Name (ARN) of the Amazon SNS topic.
    ///   - logger: Logger use during operation
    @inlinable
    public func putNotificationConfiguration(
        autoScalingGroupName: String? = nil,
        notificationTypes: [String]? = nil,
        topicARN: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = PutNotificationConfigurationType(
            autoScalingGroupName: autoScalingGroupName, 
            notificationTypes: notificationTypes, 
            topicARN: topicARN
        )
        return try await self.putNotificationConfiguration(input, logger: logger)
    }

    /// Creates or updates a scaling policy for an Auto Scaling group. Scaling policies are used to scale an Auto Scaling group based on configurable metrics. If no policies are defined, the dynamic scaling and predictive scaling features are not used.  For more information about using dynamic scaling, see Target tracking scaling policies and Step and simple scaling policies in the Amazon EC2 Auto Scaling User Guide. For more information about using predictive scaling, see Predictive scaling for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. You can view the scaling policies for an Auto Scaling group using the  DescribePolicies API call. If you are no longer using a scaling policy, you can delete it by calling the DeletePolicy API.
    @Sendable
    @inlinable
    public func putScalingPolicy(_ input: PutScalingPolicyType, logger: Logger = AWSClient.loggingDisabled) async throws -> PolicyARNType {
        try await self.client.execute(
            operation: "PutScalingPolicy", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates a scaling policy for an Auto Scaling group. Scaling policies are used to scale an Auto Scaling group based on configurable metrics. If no policies are defined, the dynamic scaling and predictive scaling features are not used.  For more information about using dynamic scaling, see Target tracking scaling policies and Step and simple scaling policies in the Amazon EC2 Auto Scaling User Guide. For more information about using predictive scaling, see Predictive scaling for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. You can view the scaling policies for an Auto Scaling group using the  DescribePolicies API call. If you are no longer using a scaling policy, you can delete it by calling the DeletePolicy API.
    ///
    /// Parameters:
    ///   - adjustmentType: Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are ChangeInCapacity, ExactCapacity, and PercentChangeInCapacity. Required if the policy type is StepScaling or SimpleScaling. For more information, see Scaling adjustment types in the Amazon EC2 Auto Scaling User Guide.
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - cooldown: A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown. Valid only if the policy type is SimpleScaling. For more information, see Scaling cooldowns for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Default: None
    ///   - enabled: Indicates whether the scaling policy is enabled or disabled. The default is enabled. For more information, see Disable a scaling policy for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///   - estimatedInstanceWarmup:  Not needed if the default instance warmup is defined for the group.  The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup. Valid only if the policy type is TargetTrackingScaling or StepScaling.  The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then EstimatedInstanceWarmup falls back to the value of default cooldown.
    ///   - metricAggregationType: The aggregation type for the CloudWatch metrics. The valid values are Minimum, Maximum, and Average. If the aggregation type is null, the value is treated as Average. Valid only if the policy type is StepScaling.
    ///   - minAdjustmentMagnitude: The minimum value to scale by when the adjustment type is PercentChangeInCapacity. For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a MinAdjustmentMagnitude of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a MinAdjustmentMagnitude of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances. Valid only if the policy type is StepScaling or SimpleScaling. For more information, see Scaling adjustment types in the Amazon EC2 Auto Scaling User Guide.  Some Auto Scaling groups use instance weights. In this case, set the MinAdjustmentMagnitude to a value that is at least as large as your largest instance weight.
    ///   - minAdjustmentStep: Available for backward compatibility. Use MinAdjustmentMagnitude instead.
    ///   - policyName: The name of the policy.
    ///   - policyType: One of the following policy types:     TargetTrackingScaling     StepScaling     SimpleScaling (default)    PredictiveScaling
    ///   - predictiveScalingConfiguration: A predictive scaling policy. Provides support for predefined and custom metrics. Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count. For more information, see PredictiveScalingConfiguration in the Amazon EC2 Auto Scaling API Reference. Required if the policy type is PredictiveScaling.
    ///   - scalingAdjustment: The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a non-negative value. Required if the policy type is SimpleScaling. (Not used with any other policy type.)
    ///   - stepAdjustments: A set of adjustments that enable you to scale based on the size of the alarm breach. Required if the policy type is StepScaling. (Not used with any other policy type.)
    ///   - targetTrackingConfiguration: A target tracking scaling policy. Provides support for predefined or custom metrics. The following predefined metrics are available:    ASGAverageCPUUtilization     ASGAverageNetworkIn     ASGAverageNetworkOut     ALBRequestCountPerTarget    If you specify ALBRequestCountPerTarget for the metric, you must specify the ResourceLabel property with the PredefinedMetricSpecification. For more information, see TargetTrackingConfiguration in the Amazon EC2 Auto Scaling API Reference. Required if the policy type is TargetTrackingScaling.
    ///   - logger: Logger use during operation
    @inlinable
    public func putScalingPolicy(
        adjustmentType: String? = nil,
        autoScalingGroupName: String? = nil,
        cooldown: Int? = nil,
        enabled: Bool? = nil,
        estimatedInstanceWarmup: Int? = nil,
        metricAggregationType: String? = nil,
        minAdjustmentMagnitude: Int? = nil,
        minAdjustmentStep: Int? = nil,
        policyName: String? = nil,
        policyType: String? = nil,
        predictiveScalingConfiguration: PredictiveScalingConfiguration? = nil,
        scalingAdjustment: Int? = nil,
        stepAdjustments: [StepAdjustment]? = nil,
        targetTrackingConfiguration: TargetTrackingConfiguration? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> PolicyARNType {
        let input = PutScalingPolicyType(
            adjustmentType: adjustmentType, 
            autoScalingGroupName: autoScalingGroupName, 
            cooldown: cooldown, 
            enabled: enabled, 
            estimatedInstanceWarmup: estimatedInstanceWarmup, 
            metricAggregationType: metricAggregationType, 
            minAdjustmentMagnitude: minAdjustmentMagnitude, 
            minAdjustmentStep: minAdjustmentStep, 
            policyName: policyName, 
            policyType: policyType, 
            predictiveScalingConfiguration: predictiveScalingConfiguration, 
            scalingAdjustment: scalingAdjustment, 
            stepAdjustments: stepAdjustments, 
            targetTrackingConfiguration: targetTrackingConfiguration
        )
        return try await self.putScalingPolicy(input, logger: logger)
    }

    /// Creates or updates a scheduled scaling action for an Auto Scaling group. For more information, see Scheduled scaling in the Amazon EC2 Auto Scaling User Guide. You can view the scheduled actions for an Auto Scaling group using the  DescribeScheduledActions API call. If you are no longer using a scheduled action, you can delete it by calling the  DeleteScheduledAction API. If you try to schedule your action in the past, Amazon EC2 Auto Scaling returns an error message.
    @Sendable
    @inlinable
    public func putScheduledUpdateGroupAction(_ input: PutScheduledUpdateGroupActionType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "PutScheduledUpdateGroupAction", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates a scheduled scaling action for an Auto Scaling group. For more information, see Scheduled scaling in the Amazon EC2 Auto Scaling User Guide. You can view the scheduled actions for an Auto Scaling group using the  DescribeScheduledActions API call. If you are no longer using a scheduled action, you can delete it by calling the  DeleteScheduledAction API. If you try to schedule your action in the past, Amazon EC2 Auto Scaling returns an error message.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - desiredCapacity: The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions.   You must specify at least one of the following properties: MaxSize, MinSize, or DesiredCapacity.
    ///   - endTime: The date and time for the recurring schedule to end, in UTC. For example, "2021-06-01T00:00:00Z".
    ///   - maxSize: The maximum size of the Auto Scaling group.
    ///   - minSize: The minimum size of the Auto Scaling group.
    ///   - recurrence: The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, "30 0 1 1,6,12 *"). For more information about this format, see Crontab. When StartTime and EndTime are specified with Recurrence, they form the boundaries of when the recurring action starts and stops. Cron expressions use Universal Coordinated Time (UTC) by default.
    ///   - scheduledActionName: The name of this scaling action.
    ///   - startTime: The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, "2021-06-01T00:00:00Z"). If you specify Recurrence and StartTime, Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.
    ///   - time: This property is no longer used.
    ///   - timeZone: Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default.  Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as Etc/GMT+9 or Pacific/Tahiti). For more information, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones.
    ///   - logger: Logger use during operation
    @inlinable
    public func putScheduledUpdateGroupAction(
        autoScalingGroupName: String? = nil,
        desiredCapacity: Int? = nil,
        endTime: Date? = nil,
        maxSize: Int? = nil,
        minSize: Int? = nil,
        recurrence: String? = nil,
        scheduledActionName: String? = nil,
        startTime: Date? = nil,
        time: Date? = nil,
        timeZone: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = PutScheduledUpdateGroupActionType(
            autoScalingGroupName: autoScalingGroupName, 
            desiredCapacity: desiredCapacity, 
            endTime: endTime, 
            maxSize: maxSize, 
            minSize: minSize, 
            recurrence: recurrence, 
            scheduledActionName: scheduledActionName, 
            startTime: startTime, 
            time: time, 
            timeZone: timeZone
        )
        return try await self.putScheduledUpdateGroupAction(input, logger: logger)
    }

    /// Creates or updates a warm pool for the specified Auto Scaling group. A warm pool is a pool of pre-initialized EC2 instances that sits alongside the Auto Scaling group. Whenever your application needs to scale out, the Auto Scaling group can draw on the warm pool to meet its new desired capacity. This operation must be called from the Region in which the Auto Scaling group was created. You can view the instances in the warm pool using the DescribeWarmPool API call. If you are no longer using a warm pool, you can delete it by calling the DeleteWarmPool API. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func putWarmPool(_ input: PutWarmPoolType, logger: Logger = AWSClient.loggingDisabled) async throws -> PutWarmPoolAnswer {
        try await self.client.execute(
            operation: "PutWarmPool", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Creates or updates a warm pool for the specified Auto Scaling group. A warm pool is a pool of pre-initialized EC2 instances that sits alongside the Auto Scaling group. Whenever your application needs to scale out, the Auto Scaling group can draw on the warm pool to meet its new desired capacity. This operation must be called from the Region in which the Auto Scaling group was created. You can view the instances in the warm pool using the DescribeWarmPool API call. If you are no longer using a warm pool, you can delete it by calling the DeleteWarmPool API. For more information, see Warm pools for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceReusePolicy: Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.
    ///   - maxGroupPreparedCapacity: Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity.   If a value for MaxGroupPreparedCapacity is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for MaxGroupPreparedCapacity, Amazon EC2 Auto Scaling uses the difference between the MaxGroupPreparedCapacity and the desired capacity instead.  The size of the warm pool is dynamic. Only when MaxGroupPreparedCapacity and MinSize are set to the same value does the warm pool have an absolute size.  If the desired capacity of the Auto Scaling group is higher than the MaxGroupPreparedCapacity, the capacity of the warm pool is 0, unless you specify a value for MinSize. To remove a value that you previously set, include the property but specify -1 for the value.
    ///   - minSize: Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.
    ///   - poolState: Sets the instance state to transition to after the lifecycle actions are complete. Default is Stopped.
    ///   - logger: Logger use during operation
    @inlinable
    public func putWarmPool(
        autoScalingGroupName: String? = nil,
        instanceReusePolicy: InstanceReusePolicy? = nil,
        maxGroupPreparedCapacity: Int? = nil,
        minSize: Int? = nil,
        poolState: WarmPoolState? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> PutWarmPoolAnswer {
        let input = PutWarmPoolType(
            autoScalingGroupName: autoScalingGroupName, 
            instanceReusePolicy: instanceReusePolicy, 
            maxGroupPreparedCapacity: maxGroupPreparedCapacity, 
            minSize: minSize, 
            poolState: poolState
        )
        return try await self.putWarmPool(input, logger: logger)
    }

    /// Records a heartbeat for the lifecycle action associated with the specified token or instance. This extends the timeout by the length of time defined using the  PutLifecycleHook API call. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.   Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.    If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.    If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.   For more information, see Amazon EC2 Auto Scaling lifecycle hooks in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func recordLifecycleActionHeartbeat(_ input: RecordLifecycleActionHeartbeatType, logger: Logger = AWSClient.loggingDisabled) async throws -> RecordLifecycleActionHeartbeatAnswer {
        try await self.client.execute(
            operation: "RecordLifecycleActionHeartbeat", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Records a heartbeat for the lifecycle action associated with the specified token or instance. This extends the timeout by the length of time defined using the  PutLifecycleHook API call. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group:   (Optional) Create a launch template or launch configuration with a user data script that runs while an instance is in a wait state due to a lifecycle hook.   (Optional) Create a Lambda function and a rule that allows Amazon EventBridge to invoke your Lambda function when an instance is put into a wait state due to a lifecycle hook.   (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target.   Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate.    If you need more time, record the lifecycle action heartbeat to keep the instance in a wait state.    If you finish before the timeout period ends, send a callback by using the CompleteLifecycleAction API call.   For more information, see Amazon EC2 Auto Scaling lifecycle hooks in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceId: The ID of the instance.
    ///   - lifecycleActionToken: A token that uniquely identifies a specific lifecycle action associated with an instance. Amazon EC2 Auto Scaling sends this token to the notification target that you specified when you created the lifecycle hook.
    ///   - lifecycleHookName: The name of the lifecycle hook.
    ///   - logger: Logger use during operation
    @inlinable
    public func recordLifecycleActionHeartbeat(
        autoScalingGroupName: String? = nil,
        instanceId: String? = nil,
        lifecycleActionToken: String? = nil,
        lifecycleHookName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> RecordLifecycleActionHeartbeatAnswer {
        let input = RecordLifecycleActionHeartbeatType(
            autoScalingGroupName: autoScalingGroupName, 
            instanceId: instanceId, 
            lifecycleActionToken: lifecycleActionToken, 
            lifecycleHookName: lifecycleHookName
        )
        return try await self.recordLifecycleActionHeartbeat(input, logger: logger)
    }

    /// Resumes the specified suspended auto scaling processes, or all suspended process, for the specified Auto Scaling group. For more information, see Suspend and resume Amazon EC2 Auto Scaling processes in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func resumeProcesses(_ input: ScalingProcessQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "ResumeProcesses", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Resumes the specified suspended auto scaling processes, or all suspended process, for the specified Auto Scaling group. For more information, see Suspend and resume Amazon EC2 Auto Scaling processes in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - scalingProcesses: One or more of the following processes:    Launch     Terminate     AddToLoadBalancer     AlarmNotification     AZRebalance     HealthCheck     InstanceRefresh     ReplaceUnhealthy     ScheduledActions    If you omit this property, all processes are specified.
    ///   - logger: Logger use during operation
    @inlinable
    public func resumeProcesses(
        autoScalingGroupName: String? = nil,
        scalingProcesses: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = ScalingProcessQuery(
            autoScalingGroupName: autoScalingGroupName, 
            scalingProcesses: scalingProcesses
        )
        return try await self.resumeProcesses(input, logger: logger)
    }

    /// Cancels an instance refresh that is in progress and rolls back any changes that it made. Amazon EC2 Auto Scaling replaces any instances that were replaced during the instance refresh. This restores your Auto Scaling group to the configuration that it was using before the start of the instance refresh.  This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. A rollback is not supported in the following situations:    There is no desired configuration specified for the instance refresh.   The Auto Scaling group has a launch template that uses an Amazon Web Services Systems Manager parameter instead of an AMI ID for the ImageId property.   The Auto Scaling group uses the launch template's $Latest or $Default version.   When you receive a successful response from this operation, Amazon EC2 Auto Scaling immediately begins replacing instances. You can check the status of this operation through the  DescribeInstanceRefreshes API operation.
    @Sendable
    @inlinable
    public func rollbackInstanceRefresh(_ input: RollbackInstanceRefreshType, logger: Logger = AWSClient.loggingDisabled) async throws -> RollbackInstanceRefreshAnswer {
        try await self.client.execute(
            operation: "RollbackInstanceRefresh", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Cancels an instance refresh that is in progress and rolls back any changes that it made. Amazon EC2 Auto Scaling replaces any instances that were replaced during the instance refresh. This restores your Auto Scaling group to the configuration that it was using before the start of the instance refresh.  This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group after you make configuration changes. A rollback is not supported in the following situations:    There is no desired configuration specified for the instance refresh.   The Auto Scaling group has a launch template that uses an Amazon Web Services Systems Manager parameter instead of an AMI ID for the ImageId property.   The Auto Scaling group uses the launch template's $Latest or $Default version.   When you receive a successful response from this operation, Amazon EC2 Auto Scaling immediately begins replacing instances. You can check the status of this operation through the  DescribeInstanceRefreshes API operation.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - logger: Logger use during operation
    @inlinable
    public func rollbackInstanceRefresh(
        autoScalingGroupName: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> RollbackInstanceRefreshAnswer {
        let input = RollbackInstanceRefreshType(
            autoScalingGroupName: autoScalingGroupName
        )
        return try await self.rollbackInstanceRefresh(input, logger: logger)
    }

    /// Sets the size of the specified Auto Scaling group. If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate.  For more information, see Manual scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func setDesiredCapacity(_ input: SetDesiredCapacityType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "SetDesiredCapacity", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Sets the size of the specified Auto Scaling group. If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate.  For more information, see Manual scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - desiredCapacity: The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain.
    ///   - honorCooldown: Indicates whether Amazon EC2 Auto Scaling waits for the cooldown period to complete before initiating a scaling activity to set your Auto Scaling group to its new capacity. By default, Amazon EC2 Auto Scaling does not honor the cooldown period during manual scaling activities.
    ///   - logger: Logger use during operation
    @inlinable
    public func setDesiredCapacity(
        autoScalingGroupName: String? = nil,
        desiredCapacity: Int? = nil,
        honorCooldown: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = SetDesiredCapacityType(
            autoScalingGroupName: autoScalingGroupName, 
            desiredCapacity: desiredCapacity, 
            honorCooldown: honorCooldown
        )
        return try await self.setDesiredCapacity(input, logger: logger)
    }

    /// Sets the health status of the specified instance. For more information, see Set up a custom health check for your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func setInstanceHealth(_ input: SetInstanceHealthQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "SetInstanceHealth", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Sets the health status of the specified instance. For more information, see Set up a custom health check for your Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - healthStatus: The health status of the instance. Set to Healthy to have the instance remain in service. Set to Unhealthy to have the instance be out of service. Amazon EC2 Auto Scaling terminates and replaces the unhealthy instance.
    ///   - instanceId: The ID of the instance.
    ///   - shouldRespectGracePeriod: If the Auto Scaling group of the specified instance has a HealthCheckGracePeriod specified for the group, by default, this call respects the grace period. Set this to False, to have the call not respect the grace period associated with the group. For more information about the health check grace period, see Set the health check grace period for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///   - logger: Logger use during operation
    @inlinable
    public func setInstanceHealth(
        healthStatus: String? = nil,
        instanceId: String? = nil,
        shouldRespectGracePeriod: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = SetInstanceHealthQuery(
            healthStatus: healthStatus, 
            instanceId: instanceId, 
            shouldRespectGracePeriod: shouldRespectGracePeriod
        )
        return try await self.setInstanceHealth(input, logger: logger)
    }

    /// Updates the instance protection settings of the specified instances. This operation cannot be called on instances in a warm pool. For more information, see Use instance scale-in protection in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of instance IDs, which is 50 per Auto Scaling group, the call fails.
    @Sendable
    @inlinable
    public func setInstanceProtection(_ input: SetInstanceProtectionQuery, logger: Logger = AWSClient.loggingDisabled) async throws -> SetInstanceProtectionAnswer {
        try await self.client.execute(
            operation: "SetInstanceProtection", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Updates the instance protection settings of the specified instances. This operation cannot be called on instances in a warm pool. For more information, see Use instance scale-in protection in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of instance IDs, which is 50 per Auto Scaling group, the call fails.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceIds: One or more instance IDs. You can specify up to 50 instances.
    ///   - protectedFromScaleIn: Indicates whether the instance is protected from termination by Amazon EC2 Auto Scaling when scaling in.
    ///   - logger: Logger use during operation
    @inlinable
    public func setInstanceProtection(
        autoScalingGroupName: String? = nil,
        instanceIds: [String]? = nil,
        protectedFromScaleIn: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> SetInstanceProtectionAnswer {
        let input = SetInstanceProtectionQuery(
            autoScalingGroupName: autoScalingGroupName, 
            instanceIds: instanceIds, 
            protectedFromScaleIn: protectedFromScaleIn
        )
        return try await self.setInstanceProtection(input, logger: logger)
    }

    /// Starts an instance refresh. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group. This feature is helpful, for example, when you have a new AMI or a new user data script. You just need to create a new launch template that specifies the new AMI or user data script. Then start an instance refresh to immediately begin the process of updating instances in the group.  If successful, the request's response contains a unique ID that you can use to track the progress of the instance refresh. To query its status, call the DescribeInstanceRefreshes API. To describe the instance refreshes that have already run, call the DescribeInstanceRefreshes API. To cancel an instance refresh that is in progress, use the CancelInstanceRefresh API.  An instance refresh might fail for several reasons, such as EC2 launch failures, misconfigured health checks, or not ignoring or allowing the termination of instances that are in Standby state or protected from scale in. You can monitor for failed EC2 launches using the scaling activities. To find the scaling activities, call the DescribeScalingActivities API. If you enable auto rollback, your Auto Scaling group will be rolled back automatically when the instance refresh fails. You can enable this feature before starting an instance refresh by specifying the AutoRollback property in the instance refresh preferences. Otherwise, to roll back an instance refresh before it finishes, use the RollbackInstanceRefresh API.
    @Sendable
    @inlinable
    public func startInstanceRefresh(_ input: StartInstanceRefreshType, logger: Logger = AWSClient.loggingDisabled) async throws -> StartInstanceRefreshAnswer {
        try await self.client.execute(
            operation: "StartInstanceRefresh", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Starts an instance refresh. This operation is part of the instance refresh feature in Amazon EC2 Auto Scaling, which helps you update instances in your Auto Scaling group. This feature is helpful, for example, when you have a new AMI or a new user data script. You just need to create a new launch template that specifies the new AMI or user data script. Then start an instance refresh to immediately begin the process of updating instances in the group.  If successful, the request's response contains a unique ID that you can use to track the progress of the instance refresh. To query its status, call the DescribeInstanceRefreshes API. To describe the instance refreshes that have already run, call the DescribeInstanceRefreshes API. To cancel an instance refresh that is in progress, use the CancelInstanceRefresh API.  An instance refresh might fail for several reasons, such as EC2 launch failures, misconfigured health checks, or not ignoring or allowing the termination of instances that are in Standby state or protected from scale in. You can monitor for failed EC2 launches using the scaling activities. To find the scaling activities, call the DescribeScalingActivities API. If you enable auto rollback, your Auto Scaling group will be rolled back automatically when the instance refresh fails. You can enable this feature before starting an instance refresh by specifying the AutoRollback property in the instance refresh preferences. Otherwise, to roll back an instance refresh before it finishes, use the RollbackInstanceRefresh API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - desiredConfiguration: The desired configuration. For example, the desired configuration can specify a new launch template or a new version of the current launch template. Once the instance refresh succeeds, Amazon EC2 Auto Scaling updates the settings of the Auto Scaling group to reflect the new desired configuration.   When you specify a new launch template or a new version of the current launch template for your desired configuration, consider enabling the SkipMatching property in preferences. If it's enabled, Amazon EC2 Auto Scaling skips replacing instances that already use the specified launch template and instance types. This can help you reduce the number of replacements that are required to apply updates.
    ///   - preferences: Sets your preferences for the instance refresh so that it performs as expected when you start it. Includes the instance warmup time, the minimum and maximum healthy percentages, and the behaviors that you want Amazon EC2 Auto Scaling to use if instances that are in Standby state or protected from scale in are found. You can also choose to enable additional features, such as the following:   Auto rollback   Checkpoints   CloudWatch alarms   Skip matching   Bake time
    ///   - strategy: The strategy to use for the instance refresh. The only valid value is Rolling.
    ///   - logger: Logger use during operation
    @inlinable
    public func startInstanceRefresh(
        autoScalingGroupName: String? = nil,
        desiredConfiguration: DesiredConfiguration? = nil,
        preferences: RefreshPreferences? = nil,
        strategy: RefreshStrategy? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> StartInstanceRefreshAnswer {
        let input = StartInstanceRefreshType(
            autoScalingGroupName: autoScalingGroupName, 
            desiredConfiguration: desiredConfiguration, 
            preferences: preferences, 
            strategy: strategy
        )
        return try await self.startInstanceRefresh(input, logger: logger)
    }

    /// Suspends the specified auto scaling processes, or all processes, for the specified Auto Scaling group. If you suspend either the Launch or Terminate process types, it can prevent other process types from functioning properly. For more information, see Suspend and resume Amazon EC2 Auto Scaling processes in the Amazon EC2 Auto Scaling User Guide. To resume processes that have been suspended, call the ResumeProcesses API.
    @Sendable
    @inlinable
    public func suspendProcesses(_ input: ScalingProcessQuery, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "SuspendProcesses", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Suspends the specified auto scaling processes, or all processes, for the specified Auto Scaling group. If you suspend either the Launch or Terminate process types, it can prevent other process types from functioning properly. For more information, see Suspend and resume Amazon EC2 Auto Scaling processes in the Amazon EC2 Auto Scaling User Guide. To resume processes that have been suspended, call the ResumeProcesses API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - scalingProcesses: One or more of the following processes:    Launch     Terminate     AddToLoadBalancer     AlarmNotification     AZRebalance     HealthCheck     InstanceRefresh     ReplaceUnhealthy     ScheduledActions    If you omit this property, all processes are specified.
    ///   - logger: Logger use during operation
    @inlinable
    public func suspendProcesses(
        autoScalingGroupName: String? = nil,
        scalingProcesses: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = ScalingProcessQuery(
            autoScalingGroupName: autoScalingGroupName, 
            scalingProcesses: scalingProcesses
        )
        return try await self.suspendProcesses(input, logger: logger)
    }

    /// Terminates the specified instance and optionally adjusts the desired group size. This operation cannot be called on instances in a warm pool. This call simply makes a termination request. The instance is not terminated immediately. When an instance is terminated, the instance status changes to terminated. You can't connect to or start an instance after you've terminated it. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are terminated.  By default, Amazon EC2 Auto Scaling balances instances across all Availability Zones. If you decrement the desired capacity, your Auto Scaling group can become unbalanced between Availability Zones. Amazon EC2 Auto Scaling tries to rebalance the group, and rebalancing might terminate instances in other zones. For more information, see Manual scaling in the Amazon EC2 Auto Scaling User Guide.
    @Sendable
    @inlinable
    public func terminateInstanceInAutoScalingGroup(_ input: TerminateInstanceInAutoScalingGroupType, logger: Logger = AWSClient.loggingDisabled) async throws -> ActivityType {
        try await self.client.execute(
            operation: "TerminateInstanceInAutoScalingGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    /// Terminates the specified instance and optionally adjusts the desired group size. This operation cannot be called on instances in a warm pool. This call simply makes a termination request. The instance is not terminated immediately. When an instance is terminated, the instance status changes to terminated. You can't connect to or start an instance after you've terminated it. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are terminated.  By default, Amazon EC2 Auto Scaling balances instances across all Availability Zones. If you decrement the desired capacity, your Auto Scaling group can become unbalanced between Availability Zones. Amazon EC2 Auto Scaling tries to rebalance the group, and rebalancing might terminate instances in other zones. For more information, see Manual scaling in the Amazon EC2 Auto Scaling User Guide.
    ///
    /// Parameters:
    ///   - instanceId: The ID of the instance.
    ///   - shouldDecrementDesiredCapacity: Indicates whether terminating the instance also decrements the size of the Auto Scaling group.
    ///   - logger: Logger use during operation
    @inlinable
    public func terminateInstanceInAutoScalingGroup(
        instanceId: String? = nil,
        shouldDecrementDesiredCapacity: Bool? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws -> ActivityType {
        let input = TerminateInstanceInAutoScalingGroupType(
            instanceId: instanceId, 
            shouldDecrementDesiredCapacity: shouldDecrementDesiredCapacity
        )
        return try await self.terminateInstanceInAutoScalingGroup(input, logger: logger)
    }

    ///  We strongly recommend that all Auto Scaling groups use launch templates to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.  Updates the configuration for the specified Auto Scaling group. To update an Auto Scaling group, specify the name of the group and the property that you want to change. Any properties that you don't specify are not changed by this update request. The new settings take effect on any scaling activities after this call returns.  If you associate a new launch configuration or template with an Auto Scaling group, all new instances will get the updated configuration. Existing instances continue to run with the configuration that they were originally launched with. When you update a group to specify a mixed instances policy instead of a launch configuration or template, existing instances may be replaced to match the new purchasing options that you specified in the policy. For example, if the group currently has 100% On-Demand capacity and the policy specifies 50% Spot capacity, this means that half of your instances will be gradually terminated and relaunched as Spot Instances. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, so that updating your group does not compromise the performance or availability of your application. Note the following about changing DesiredCapacity, MaxSize, or MinSize:   If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate.   If you specify a new value for MinSize without specifying a value for DesiredCapacity, and the new MinSize is larger than the current size of the group, this sets the group's DesiredCapacity to the new MinSize value.   If you specify a new value for MaxSize without specifying a value for DesiredCapacity, and the new MaxSize is smaller than the current size of the group, this sets the group's DesiredCapacity to the new MaxSize value.   To see which properties have been set, call the DescribeAutoScalingGroups API. To view the scaling policies for an Auto Scaling group, call the DescribePolicies API. If the group has scaling policies, you can update them by calling the PutScalingPolicy API.
    @Sendable
    @inlinable
    public func updateAutoScalingGroup(_ input: UpdateAutoScalingGroupType, logger: Logger = AWSClient.loggingDisabled) async throws {
        try await self.client.execute(
            operation: "UpdateAutoScalingGroup", 
            path: "/", 
            httpMethod: .POST, 
            serviceConfig: self.config, 
            input: input, 
            logger: logger
        )
    }
    ///  We strongly recommend that all Auto Scaling groups use launch templates to ensure full functionality for Amazon EC2 Auto Scaling and Amazon EC2.  Updates the configuration for the specified Auto Scaling group. To update an Auto Scaling group, specify the name of the group and the property that you want to change. Any properties that you don't specify are not changed by this update request. The new settings take effect on any scaling activities after this call returns.  If you associate a new launch configuration or template with an Auto Scaling group, all new instances will get the updated configuration. Existing instances continue to run with the configuration that they were originally launched with. When you update a group to specify a mixed instances policy instead of a launch configuration or template, existing instances may be replaced to match the new purchasing options that you specified in the policy. For example, if the group currently has 100% On-Demand capacity and the policy specifies 50% Spot capacity, this means that half of your instances will be gradually terminated and relaunched as Spot Instances. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, so that updating your group does not compromise the performance or availability of your application. Note the following about changing DesiredCapacity, MaxSize, or MinSize:   If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate.   If you specify a new value for MinSize without specifying a value for DesiredCapacity, and the new MinSize is larger than the current size of the group, this sets the group's DesiredCapacity to the new MinSize value.   If you specify a new value for MaxSize without specifying a value for DesiredCapacity, and the new MaxSize is smaller than the current size of the group, this sets the group's DesiredCapacity to the new MaxSize value.   To see which properties have been set, call the DescribeAutoScalingGroups API. To view the scaling policies for an Auto Scaling group, call the DescribePolicies API. If the group has scaling policies, you can update them by calling the PutScalingPolicy API.
    ///
    /// Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - availabilityZoneDistribution:  The instance capacity distribution across Availability Zones.
    ///   - availabilityZoneImpairmentPolicy:  The policy for Availability Zone impairment.
    ///   - availabilityZones: One or more Availability Zones for the group.
    ///   - capacityRebalance: Enables or disables Capacity Rebalancing. For more information, see Use Capacity Rebalancing to handle Amazon EC2 Spot Interruptions in the Amazon EC2 Auto Scaling User Guide.
    ///   - capacityReservationSpecification:  The capacity reservation specification for the Auto Scaling group.
    ///   - context: Reserved.
    ///   - defaultCooldown:  Only needed if you use simple scaling policies.  The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see Scaling cooldowns for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide.
    ///   - defaultInstanceWarmup: The amount of time, in seconds, until a new instance is considered to have finished initializing and resource consumption to become stable after it enters the InService state.  During an instance refresh, Amazon EC2 Auto Scaling waits for the warm-up period after it replaces an instance before it moves on to replacing the next instance. Amazon EC2 Auto Scaling also waits for the warm-up period before aggregating the metrics for new instances with existing instances in the Amazon CloudWatch metrics that are used for scaling, resulting in more reliable usage data. For more information, see Set the default instance warmup for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.  To manage various warm-up settings at the group level, we recommend that you set the default instance warmup, even if it is set to 0 seconds. To remove a value that you previously set, include the property but specify -1 for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a value of 0 or other nominal value.
    ///   - desiredCapacity: The desired capacity is the initial capacity of the Auto Scaling group after this operation completes and the capacity it attempts to maintain. This number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group.
    ///   - desiredCapacityType: The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports DesiredCapacityType for attribute-based instance type selection only. For more information, see Create a mixed instances group using attribute-based instance type selection in the Amazon EC2 Auto Scaling User Guide. By default, Amazon EC2 Auto Scaling specifies units, which translates into number of instances. Valid values: units | vcpu | memory-mib
    ///   - healthCheckGracePeriod: The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed health check. This is useful if your instances do not immediately pass their health checks after they enter the InService state. For more information, see Set the health check grace period for an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide.
    ///   - healthCheckType: A comma-separated value string of one or more health check types. The valid values are EC2, EBS, ELB, and VPC_LATTICE. EC2 is the default health check and cannot be disabled. For more information, see Health checks for instances in an Auto Scaling group in the Amazon EC2 Auto Scaling User Guide. Only specify EC2 if you must clear a value that was previously set.
    ///   - instanceMaintenancePolicy: An instance maintenance policy. For more information, see Set instance maintenance policy in the Amazon EC2 Auto Scaling User Guide.
    ///   - launchConfigurationName: The name of the launch configuration. If you specify LaunchConfigurationName in your update request, you can't specify LaunchTemplate or MixedInstancesPolicy.
    ///   - launchTemplate: The launch template and version to use to specify the updates. If you specify LaunchTemplate in your update request, you can't specify LaunchConfigurationName or MixedInstancesPolicy.
    ///   - maxInstanceLifetime: The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). To clear a previously set value, specify a new value of 0. For more information, see Replacing Auto Scaling instances based on maximum instance lifetime in the Amazon EC2 Auto Scaling User Guide.
    ///   - maxSize: The maximum size of the Auto Scaling group.  With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above MaxSize to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above MaxSize by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).
    ///   - minSize: The minimum size of the Auto Scaling group.
    ///   - mixedInstancesPolicy: The mixed instances policy. For more information, see Auto Scaling groups with multiple instance types and purchase options in the Amazon EC2 Auto Scaling User Guide.
    ///   - newInstancesProtectedFromScaleIn: Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see Use instance scale-in protection in the Amazon EC2 Auto Scaling User Guide.
    ///   - placementGroup: The name of an existing placement group into which to launch your instances. To remove the placement group setting, pass an empty string for placement-group. For more information about placement groups, see Placement groups in the Amazon EC2 User Guide for Linux Instances.  A cluster placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group.
    ///   - serviceLinkedRoleARN: The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other Amazon Web Services on your behalf. For more information, see Service-linked roles in the Amazon EC2 Auto Scaling User Guide.
    ///   - skipZonalShiftValidation:  If you enable zonal shift with cross-zone disabled load balancers, capacity could become imbalanced across Availability Zones. To skip the validation, specify true. For more information, see Auto Scaling group zonal shift in the Amazon EC2 Auto Scaling User Guide.
    ///   - terminationPolicies: A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. For more information, see Configure termination policies for Amazon EC2 Auto Scaling in the Amazon EC2 Auto Scaling User Guide. Valid values: Default | AllocationStrategy | ClosestToNextInstanceHour | NewestInstance | OldestInstance | OldestLaunchConfiguration | OldestLaunchTemplate | arn:aws:lambda:region:account-id:function:my-function:my-alias
    ///   - vpcZoneIdentifier: A comma-separated list of subnet IDs for a virtual private cloud (VPC). If you specify VPCZoneIdentifier with AvailabilityZones, the subnets that you specify must reside in those Availability Zones.
    ///   - logger: Logger use during operation
    @inlinable
    public func updateAutoScalingGroup(
        autoScalingGroupName: String? = nil,
        availabilityZoneDistribution: AvailabilityZoneDistribution? = nil,
        availabilityZoneImpairmentPolicy: AvailabilityZoneImpairmentPolicy? = nil,
        availabilityZones: [String]? = nil,
        capacityRebalance: Bool? = nil,
        capacityReservationSpecification: CapacityReservationSpecification? = nil,
        context: String? = nil,
        defaultCooldown: Int? = nil,
        defaultInstanceWarmup: Int? = nil,
        desiredCapacity: Int? = nil,
        desiredCapacityType: String? = nil,
        healthCheckGracePeriod: Int? = nil,
        healthCheckType: String? = nil,
        instanceMaintenancePolicy: InstanceMaintenancePolicy? = nil,
        launchConfigurationName: String? = nil,
        launchTemplate: LaunchTemplateSpecification? = nil,
        maxInstanceLifetime: Int? = nil,
        maxSize: Int? = nil,
        minSize: Int? = nil,
        mixedInstancesPolicy: MixedInstancesPolicy? = nil,
        newInstancesProtectedFromScaleIn: Bool? = nil,
        placementGroup: String? = nil,
        serviceLinkedRoleARN: String? = nil,
        skipZonalShiftValidation: Bool? = nil,
        terminationPolicies: [String]? = nil,
        vpcZoneIdentifier: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = UpdateAutoScalingGroupType(
            autoScalingGroupName: autoScalingGroupName, 
            availabilityZoneDistribution: availabilityZoneDistribution, 
            availabilityZoneImpairmentPolicy: availabilityZoneImpairmentPolicy, 
            availabilityZones: availabilityZones, 
            capacityRebalance: capacityRebalance, 
            capacityReservationSpecification: capacityReservationSpecification, 
            context: context, 
            defaultCooldown: defaultCooldown, 
            defaultInstanceWarmup: defaultInstanceWarmup, 
            desiredCapacity: desiredCapacity, 
            desiredCapacityType: desiredCapacityType, 
            healthCheckGracePeriod: healthCheckGracePeriod, 
            healthCheckType: healthCheckType, 
            instanceMaintenancePolicy: instanceMaintenancePolicy, 
            launchConfigurationName: launchConfigurationName, 
            launchTemplate: launchTemplate, 
            maxInstanceLifetime: maxInstanceLifetime, 
            maxSize: maxSize, 
            minSize: minSize, 
            mixedInstancesPolicy: mixedInstancesPolicy, 
            newInstancesProtectedFromScaleIn: newInstancesProtectedFromScaleIn, 
            placementGroup: placementGroup, 
            serviceLinkedRoleARN: serviceLinkedRoleARN, 
            skipZonalShiftValidation: skipZonalShiftValidation, 
            terminationPolicies: terminationPolicies, 
            vpcZoneIdentifier: vpcZoneIdentifier
        )
        return try await self.updateAutoScalingGroup(input, logger: logger)
    }
}

extension AutoScaling {
    /// Initializer required by `AWSService.with(middlewares:timeout:byteBufferAllocator:options)`. You are not able to use this initializer directly as there are not public
    /// initializers for `AWSServiceConfig.Patch`. Please use `AWSService.with(middlewares:timeout:byteBufferAllocator:options)` instead.
    public init(from: AutoScaling, patch: AWSServiceConfig.Patch) {
        self.client = from.client
        self.config = from.config.with(patch: patch)
    }
}

// MARK: Paginators

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension AutoScaling {
    /// Return PaginatorSequence for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeAutoScalingGroupsPaginator(
        _ input: AutoScalingGroupNamesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<AutoScalingGroupNamesType, AutoScalingGroupsType> {
        return .init(
            input: input,
            command: self.describeAutoScalingGroups,
            inputKey: \AutoScalingGroupNamesType.nextToken,
            outputKey: \AutoScalingGroupsType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupNames: The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the MaxRecords property. If you omit this property, all Auto Scaling groups are described.
    ///   - filters: One or more filters to limit the results based on specific tags.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeAutoScalingGroupsPaginator(
        autoScalingGroupNames: [String]? = nil,
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<AutoScalingGroupNamesType, AutoScalingGroupsType> {
        let input = AutoScalingGroupNamesType(
            autoScalingGroupNames: autoScalingGroupNames, 
            filters: filters, 
            maxRecords: maxRecords
        )
        return self.describeAutoScalingGroupsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeAutoScalingInstances(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeAutoScalingInstancesPaginator(
        _ input: DescribeAutoScalingInstancesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeAutoScalingInstancesType, AutoScalingInstancesType> {
        return .init(
            input: input,
            command: self.describeAutoScalingInstances,
            inputKey: \DescribeAutoScalingInstancesType.nextToken,
            outputKey: \AutoScalingInstancesType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeAutoScalingInstances(_:logger:)``.
    ///
    /// - Parameters:
    ///   - instanceIds: The IDs of the instances. If you omit this property, all Auto Scaling instances are described. If you specify an ID that does not exist, it is ignored with no error. Array Members: Maximum number of 50 items.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 50.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeAutoScalingInstancesPaginator(
        instanceIds: [String]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeAutoScalingInstancesType, AutoScalingInstancesType> {
        let input = DescribeAutoScalingInstancesType(
            instanceIds: instanceIds, 
            maxRecords: maxRecords
        )
        return self.describeAutoScalingInstancesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeInstanceRefreshes(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeInstanceRefreshesPaginator(
        _ input: DescribeInstanceRefreshesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeInstanceRefreshesType, DescribeInstanceRefreshesAnswer> {
        return .init(
            input: input,
            command: self.describeInstanceRefreshes,
            inputKey: \DescribeInstanceRefreshesType.nextToken,
            outputKey: \DescribeInstanceRefreshesAnswer.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeInstanceRefreshes(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - instanceRefreshIds: One or more instance refresh IDs.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeInstanceRefreshesPaginator(
        autoScalingGroupName: String? = nil,
        instanceRefreshIds: [String]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeInstanceRefreshesType, DescribeInstanceRefreshesAnswer> {
        let input = DescribeInstanceRefreshesType(
            autoScalingGroupName: autoScalingGroupName, 
            instanceRefreshIds: instanceRefreshIds, 
            maxRecords: maxRecords
        )
        return self.describeInstanceRefreshesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeLaunchConfigurations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLaunchConfigurationsPaginator(
        _ input: LaunchConfigurationNamesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<LaunchConfigurationNamesType, LaunchConfigurationsType> {
        return .init(
            input: input,
            command: self.describeLaunchConfigurations,
            inputKey: \LaunchConfigurationNamesType.nextToken,
            outputKey: \LaunchConfigurationsType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeLaunchConfigurations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - launchConfigurationNames: The launch configuration names. If you omit this property, all launch configurations are described. Array Members: Maximum number of 50 items.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLaunchConfigurationsPaginator(
        launchConfigurationNames: [String]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<LaunchConfigurationNamesType, LaunchConfigurationsType> {
        let input = LaunchConfigurationNamesType(
            launchConfigurationNames: launchConfigurationNames, 
            maxRecords: maxRecords
        )
        return self.describeLaunchConfigurationsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeLoadBalancerTargetGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLoadBalancerTargetGroupsPaginator(
        _ input: DescribeLoadBalancerTargetGroupsRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeLoadBalancerTargetGroupsRequest, DescribeLoadBalancerTargetGroupsResponse> {
        return .init(
            input: input,
            command: self.describeLoadBalancerTargetGroups,
            inputKey: \DescribeLoadBalancerTargetGroupsRequest.nextToken,
            outputKey: \DescribeLoadBalancerTargetGroupsResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeLoadBalancerTargetGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLoadBalancerTargetGroupsPaginator(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeLoadBalancerTargetGroupsRequest, DescribeLoadBalancerTargetGroupsResponse> {
        let input = DescribeLoadBalancerTargetGroupsRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords
        )
        return self.describeLoadBalancerTargetGroupsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeLoadBalancers(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLoadBalancersPaginator(
        _ input: DescribeLoadBalancersRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeLoadBalancersRequest, DescribeLoadBalancersResponse> {
        return .init(
            input: input,
            command: self.describeLoadBalancers,
            inputKey: \DescribeLoadBalancersRequest.nextToken,
            outputKey: \DescribeLoadBalancersResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeLoadBalancers(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeLoadBalancersPaginator(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeLoadBalancersRequest, DescribeLoadBalancersResponse> {
        let input = DescribeLoadBalancersRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords
        )
        return self.describeLoadBalancersPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeNotificationConfigurations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeNotificationConfigurationsPaginator(
        _ input: DescribeNotificationConfigurationsType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeNotificationConfigurationsType, DescribeNotificationConfigurationsAnswer> {
        return .init(
            input: input,
            command: self.describeNotificationConfigurations,
            inputKey: \DescribeNotificationConfigurationsType.nextToken,
            outputKey: \DescribeNotificationConfigurationsAnswer.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeNotificationConfigurations(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupNames: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeNotificationConfigurationsPaginator(
        autoScalingGroupNames: [String]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeNotificationConfigurationsType, DescribeNotificationConfigurationsAnswer> {
        let input = DescribeNotificationConfigurationsType(
            autoScalingGroupNames: autoScalingGroupNames, 
            maxRecords: maxRecords
        )
        return self.describeNotificationConfigurationsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describePolicies(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describePoliciesPaginator(
        _ input: DescribePoliciesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribePoliciesType, PoliciesType> {
        return .init(
            input: input,
            command: self.describePolicies,
            inputKey: \DescribePoliciesType.nextToken,
            outputKey: \PoliciesType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describePolicies(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to be returned with each call. The default value is 50 and the maximum value is 100.
    ///   - policyNames: The names of one or more policies. If you omit this property, all policies are described. If a group name is provided, the results are limited to that group. If you specify an unknown policy name, it is ignored with no error. Array Members: Maximum number of 50 items.
    ///   - policyTypes: One or more policy types. The valid values are SimpleScaling, StepScaling, TargetTrackingScaling, and PredictiveScaling.
    ///   - logger: Logger used for logging
    @inlinable
    public func describePoliciesPaginator(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        policyNames: [String]? = nil,
        policyTypes: [String]? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribePoliciesType, PoliciesType> {
        let input = DescribePoliciesType(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            policyNames: policyNames, 
            policyTypes: policyTypes
        )
        return self.describePoliciesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeScalingActivities(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeScalingActivitiesPaginator(
        _ input: DescribeScalingActivitiesType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeScalingActivitiesType, ActivitiesType> {
        return .init(
            input: input,
            command: self.describeScalingActivities,
            inputKey: \DescribeScalingActivitiesType.nextToken,
            outputKey: \ActivitiesType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeScalingActivities(_:logger:)``.
    ///
    /// - Parameters:
    ///   - activityIds: The activity IDs of the desired scaling activities. If you omit this property, all activities for the past six weeks are described. If unknown activities are requested, they are ignored with no error. If you specify an Auto Scaling group, the results are limited to that group. Array Members: Maximum number of 50 IDs.
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - includeDeletedGroups: Indicates whether to include scaling activity from deleted Auto Scaling groups.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 100 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeScalingActivitiesPaginator(
        activityIds: [String]? = nil,
        autoScalingGroupName: String? = nil,
        includeDeletedGroups: Bool? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeScalingActivitiesType, ActivitiesType> {
        let input = DescribeScalingActivitiesType(
            activityIds: activityIds, 
            autoScalingGroupName: autoScalingGroupName, 
            includeDeletedGroups: includeDeletedGroups, 
            maxRecords: maxRecords
        )
        return self.describeScalingActivitiesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeScheduledActions(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeScheduledActionsPaginator(
        _ input: DescribeScheduledActionsType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeScheduledActionsType, ScheduledActionsType> {
        return .init(
            input: input,
            command: self.describeScheduledActions,
            inputKey: \DescribeScheduledActionsType.nextToken,
            outputKey: \ScheduledActionsType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeScheduledActions(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - endTime: The latest scheduled start time to return. If scheduled action names are provided, this property is ignored.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - scheduledActionNames: The names of one or more scheduled actions. If you omit this property, all scheduled actions are described. If you specify an unknown scheduled action, it is ignored with no error. Array Members: Maximum number of 50 actions.
    ///   - startTime: The earliest scheduled start time to return. If scheduled action names are provided, this property is ignored.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeScheduledActionsPaginator(
        autoScalingGroupName: String? = nil,
        endTime: Date? = nil,
        maxRecords: Int? = nil,
        scheduledActionNames: [String]? = nil,
        startTime: Date? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeScheduledActionsType, ScheduledActionsType> {
        let input = DescribeScheduledActionsType(
            autoScalingGroupName: autoScalingGroupName, 
            endTime: endTime, 
            maxRecords: maxRecords, 
            scheduledActionNames: scheduledActionNames, 
            startTime: startTime
        )
        return self.describeScheduledActionsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeTags(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeTagsPaginator(
        _ input: DescribeTagsType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeTagsType, TagsType> {
        return .init(
            input: input,
            command: self.describeTags,
            inputKey: \DescribeTagsType.nextToken,
            outputKey: \TagsType.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeTags(_:logger:)``.
    ///
    /// - Parameters:
    ///   - filters: One or more filters to scope the tags to return. The maximum number of filters per filter type (for example, auto-scaling-group) is 1000.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeTagsPaginator(
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeTagsType, TagsType> {
        let input = DescribeTagsType(
            filters: filters, 
            maxRecords: maxRecords
        )
        return self.describeTagsPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeTrafficSources(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeTrafficSourcesPaginator(
        _ input: DescribeTrafficSourcesRequest,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeTrafficSourcesRequest, DescribeTrafficSourcesResponse> {
        return .init(
            input: input,
            command: self.describeTrafficSources,
            inputKey: \DescribeTrafficSourcesRequest.nextToken,
            outputKey: \DescribeTrafficSourcesResponse.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeTrafficSources(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of items to return with this call. The maximum value is 50.
    ///   - trafficSourceType: The traffic source type that you want to describe. The following lists the valid values:    elb if the traffic source is a Classic Load Balancer.    elbv2 if the traffic source is a Application Load Balancer, Gateway Load Balancer, or Network Load Balancer.    vpc-lattice if the traffic source is VPC Lattice.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeTrafficSourcesPaginator(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        trafficSourceType: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeTrafficSourcesRequest, DescribeTrafficSourcesResponse> {
        let input = DescribeTrafficSourcesRequest(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords, 
            trafficSourceType: trafficSourceType
        )
        return self.describeTrafficSourcesPaginator(input, logger: logger)
    }

    /// Return PaginatorSequence for operation ``describeWarmPool(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func describeWarmPoolPaginator(
        _ input: DescribeWarmPoolType,
        logger: Logger = AWSClient.loggingDisabled
    ) -> AWSClient.PaginatorSequence<DescribeWarmPoolType, DescribeWarmPoolAnswer> {
        return .init(
            input: input,
            command: self.describeWarmPool,
            inputKey: \DescribeWarmPoolType.nextToken,
            outputKey: \DescribeWarmPoolAnswer.nextToken,
            logger: logger
        )
    }
    /// Return PaginatorSequence for operation ``describeWarmPool(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupName: The name of the Auto Scaling group.
    ///   - maxRecords: The maximum number of instances to return with this call. The maximum value is 50.
    ///   - logger: Logger used for logging
    @inlinable
    public func describeWarmPoolPaginator(
        autoScalingGroupName: String? = nil,
        maxRecords: Int? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) -> AWSClient.PaginatorSequence<DescribeWarmPoolType, DescribeWarmPoolAnswer> {
        let input = DescribeWarmPoolType(
            autoScalingGroupName: autoScalingGroupName, 
            maxRecords: maxRecords
        )
        return self.describeWarmPoolPaginator(input, logger: logger)
    }
}

extension AutoScaling.AutoScalingGroupNamesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.AutoScalingGroupNamesType {
        return .init(
            autoScalingGroupNames: self.autoScalingGroupNames,
            filters: self.filters,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeAutoScalingInstancesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeAutoScalingInstancesType {
        return .init(
            instanceIds: self.instanceIds,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeInstanceRefreshesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeInstanceRefreshesType {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            instanceRefreshIds: self.instanceRefreshIds,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeLoadBalancerTargetGroupsRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeLoadBalancerTargetGroupsRequest {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeLoadBalancersRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeLoadBalancersRequest {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeNotificationConfigurationsType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeNotificationConfigurationsType {
        return .init(
            autoScalingGroupNames: self.autoScalingGroupNames,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribePoliciesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribePoliciesType {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            maxRecords: self.maxRecords,
            nextToken: token,
            policyNames: self.policyNames,
            policyTypes: self.policyTypes
        )
    }
}

extension AutoScaling.DescribeScalingActivitiesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeScalingActivitiesType {
        return .init(
            activityIds: self.activityIds,
            autoScalingGroupName: self.autoScalingGroupName,
            includeDeletedGroups: self.includeDeletedGroups,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeScheduledActionsType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeScheduledActionsType {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            endTime: self.endTime,
            maxRecords: self.maxRecords,
            nextToken: token,
            scheduledActionNames: self.scheduledActionNames,
            startTime: self.startTime
        )
    }
}

extension AutoScaling.DescribeTagsType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeTagsType {
        return .init(
            filters: self.filters,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.DescribeTrafficSourcesRequest: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeTrafficSourcesRequest {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            maxRecords: self.maxRecords,
            nextToken: token,
            trafficSourceType: self.trafficSourceType
        )
    }
}

extension AutoScaling.DescribeWarmPoolType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.DescribeWarmPoolType {
        return .init(
            autoScalingGroupName: self.autoScalingGroupName,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

extension AutoScaling.LaunchConfigurationNamesType: AWSPaginateToken {
    @inlinable
    public func usingPaginationToken(_ token: String) -> AutoScaling.LaunchConfigurationNamesType {
        return .init(
            launchConfigurationNames: self.launchConfigurationNames,
            maxRecords: self.maxRecords,
            nextToken: token
        )
    }
}

// MARK: Waiters

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension AutoScaling {
    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupExists(
        _ input: AutoScalingGroupNamesType,
        maxWaitTime: TimeAmount? = nil,
        logger: Logger = AWSClient.loggingDisabled
    ) async throws {
        let waiter = AWSClient.Waiter<AutoScalingGroupNamesType, _>(
            acceptors: [
                .init(state: .success, matcher: try! JMESPathMatcher("length(autoScalingGroups) > `0`", expected: "true")),
                .init(state: .retry, matcher: try! JMESPathMatcher("length(autoScalingGroups) > `0`", expected: "false")),
            ],
            minDelayTime: .seconds(5),
            command: self.describeAutoScalingGroups
        )
        return try await self.client.waitUntil(input, waiter: waiter, maxWaitTime: maxWaitTime, logger: logger)
    }
    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupNames: The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the MaxRecords property. If you omit this property, all Auto Scaling groups are described.
    ///   - filters: One or more filters to limit the results based on specific tags.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupExists(
        autoScalingGroupNames: [String]? = nil,
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = AutoScalingGroupNamesType(
            autoScalingGroupNames: autoScalingGroupNames, 
            filters: filters, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        try await self.waitUntilGroupExists(input, logger: logger)
    }

    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupInService(
        _ input: AutoScalingGroupNamesType,
        maxWaitTime: TimeAmount? = nil,
        logger: Logger = AWSClient.loggingDisabled
    ) async throws {
        let waiter = AWSClient.Waiter<AutoScalingGroupNamesType, _>(
            acceptors: [
                .init(state: .success, matcher: try! JMESPathMatcher("contains(autoScalingGroups[].[length(instances[?lifecycleState=='inService']) >= minSize][], `false`)", expected: "false")),
                .init(state: .retry, matcher: try! JMESPathMatcher("contains(autoScalingGroups[].[length(instances[?lifecycleState=='inService']) >= minSize][], `false`)", expected: "true")),
            ],
            minDelayTime: .seconds(15),
            command: self.describeAutoScalingGroups
        )
        return try await self.client.waitUntil(input, waiter: waiter, maxWaitTime: maxWaitTime, logger: logger)
    }
    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupNames: The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the MaxRecords property. If you omit this property, all Auto Scaling groups are described.
    ///   - filters: One or more filters to limit the results based on specific tags.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupInService(
        autoScalingGroupNames: [String]? = nil,
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = AutoScalingGroupNamesType(
            autoScalingGroupNames: autoScalingGroupNames, 
            filters: filters, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        try await self.waitUntilGroupInService(input, logger: logger)
    }

    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - input: Input for operation
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupNotExists(
        _ input: AutoScalingGroupNamesType,
        maxWaitTime: TimeAmount? = nil,
        logger: Logger = AWSClient.loggingDisabled
    ) async throws {
        let waiter = AWSClient.Waiter<AutoScalingGroupNamesType, _>(
            acceptors: [
                .init(state: .success, matcher: try! JMESPathMatcher("length(autoScalingGroups) > `0`", expected: "false")),
                .init(state: .retry, matcher: try! JMESPathMatcher("length(autoScalingGroups) > `0`", expected: "true")),
            ],
            minDelayTime: .seconds(15),
            command: self.describeAutoScalingGroups
        )
        return try await self.client.waitUntil(input, waiter: waiter, maxWaitTime: maxWaitTime, logger: logger)
    }
    /// Waiter for operation ``describeAutoScalingGroups(_:logger:)``.
    ///
    /// - Parameters:
    ///   - autoScalingGroupNames: The names of the Auto Scaling groups. By default, you can only specify up to 50 names. You can optionally increase this limit using the MaxRecords property. If you omit this property, all Auto Scaling groups are described.
    ///   - filters: One or more filters to limit the results based on specific tags.
    ///   - maxRecords: The maximum number of items to return with this call. The default value is 50 and the maximum value is 100.
    ///   - nextToken: The token for the next set of items to return. (You received this token from a previous call.)
    ///   - logger: Logger used for logging
    @inlinable
    public func waitUntilGroupNotExists(
        autoScalingGroupNames: [String]? = nil,
        filters: [Filter]? = nil,
        maxRecords: Int? = nil,
        nextToken: String? = nil,
        logger: Logger = AWSClient.loggingDisabled        
    ) async throws {
        let input = AutoScalingGroupNamesType(
            autoScalingGroupNames: autoScalingGroupNames, 
            filters: filters, 
            maxRecords: maxRecords, 
            nextToken: nextToken
        )
        try await self.waitUntilGroupNotExists(input, logger: logger)
    }
}
