//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2024 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

#if canImport(FoundationEssentials)
import FoundationEssentials
#else
import Foundation
#endif
@_spi(SotoInternal) import SotoCore

extension TimestreamInfluxDB {
    // MARK: Enums

    public enum ClusterDeploymentType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case multiNodeReadReplicas = "MULTI_NODE_READ_REPLICAS"
        public var description: String { return self.rawValue }
    }

    public enum ClusterStatus: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case available = "AVAILABLE"
        case creating = "CREATING"
        case deleted = "DELETED"
        case deleting = "DELETING"
        case failed = "FAILED"
        case maintenance = "MAINTENANCE"
        case partiallyAvailable = "PARTIALLY_AVAILABLE"
        case rebootFailed = "REBOOT_FAILED"
        case rebooting = "REBOOTING"
        case updating = "UPDATING"
        case updatingInstanceType = "UPDATING_INSTANCE_TYPE"
        public var description: String { return self.rawValue }
    }

    public enum DataFusionRuntimeType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case multiThread = "multi-thread"
        case multiThreadAlt = "multi-thread-alt"
        public var description: String { return self.rawValue }
    }

    public enum DbInstanceType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case dbInflux12Xlarge = "db.influx.12xlarge"
        case dbInflux16Xlarge = "db.influx.16xlarge"
        case dbInflux24Xlarge = "db.influx.24xlarge"
        case dbInflux2Xlarge = "db.influx.2xlarge"
        case dbInflux4Xlarge = "db.influx.4xlarge"
        case dbInflux8Xlarge = "db.influx.8xlarge"
        case dbInfluxLarge = "db.influx.large"
        case dbInfluxMedium = "db.influx.medium"
        case dbInfluxXlarge = "db.influx.xlarge"
        public var description: String { return self.rawValue }
    }

    public enum DbStorageType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case influxIoIncludedT1 = "InfluxIOIncludedT1"
        case influxIoIncludedT2 = "InfluxIOIncludedT2"
        case influxIoIncludedT3 = "InfluxIOIncludedT3"
        public var description: String { return self.rawValue }
    }

    public enum DeploymentType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case singleAz = "SINGLE_AZ"
        case withMultiazStandby = "WITH_MULTIAZ_STANDBY"
        public var description: String { return self.rawValue }
    }

    public enum DurationType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case days = "days"
        case hours = "hours"
        case milliseconds = "milliseconds"
        case minutes = "minutes"
        case seconds = "seconds"
        public var description: String { return self.rawValue }
    }

    public enum EngineType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case influxdbV2 = "INFLUXDB_V2"
        case influxdbV3Core = "INFLUXDB_V3_CORE"
        case influxdbV3Enterprise = "INFLUXDB_V3_ENTERPRISE"
        public var description: String { return self.rawValue }
    }

    public enum FailoverMode: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case automatic = "AUTOMATIC"
        case noFailover = "NO_FAILOVER"
        public var description: String { return self.rawValue }
    }

    public enum InstanceMode: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case compact = "COMPACT"
        case ingest = "INGEST"
        case primary = "PRIMARY"
        case process = "PROCESS"
        case query = "QUERY"
        case replica = "REPLICA"
        case standby = "STANDBY"
        public var description: String { return self.rawValue }
    }

    public enum LogFormats: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case full = "full"
        public var description: String { return self.rawValue }
    }

    public enum LogLevel: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case debug = "debug"
        case error = "error"
        case info = "info"
        public var description: String { return self.rawValue }
    }

    public enum NetworkType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case dual = "DUAL"
        case ipv4 = "IPV4"
        public var description: String { return self.rawValue }
    }

    public enum Status: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case available = "AVAILABLE"
        case creating = "CREATING"
        case deleted = "DELETED"
        case deleting = "DELETING"
        case failed = "FAILED"
        case maintenance = "MAINTENANCE"
        case modifying = "MODIFYING"
        case rebootFailed = "REBOOT_FAILED"
        case rebooting = "REBOOTING"
        case updating = "UPDATING"
        case updatingDeploymentType = "UPDATING_DEPLOYMENT_TYPE"
        case updatingInstanceType = "UPDATING_INSTANCE_TYPE"
        public var description: String { return self.rawValue }
    }

    public enum TracingType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case disabled = "disabled"
        case jaeger = "jaeger"
        case log = "log"
        public var description: String { return self.rawValue }
    }

    public enum ValidationExceptionReason: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case fieldValidationFailed = "FIELD_VALIDATION_FAILED"
        case other = "OTHER"
        public var description: String { return self.rawValue }
    }

    public enum Parameters: AWSEncodableShape & AWSDecodableShape, Sendable {
        /// All the customer-modifiable InfluxDB v2 parameters in Timestream for InfluxDB.
        case influxDBv2(InfluxDBv2Parameters)
        /// All the customer-modifiable InfluxDB v3 Core parameters in Timestream for InfluxDB.
        case influxDBv3Core(InfluxDBv3CoreParameters)
        /// All the customer-modifiable InfluxDB v3 Enterprise parameters in Timestream for InfluxDB.
        case influxDBv3Enterprise(InfluxDBv3EnterpriseParameters)

        public init(from decoder: Decoder) throws {
            let container = try decoder.container(keyedBy: CodingKeys.self)
            guard container.allKeys.count == 1, let key = container.allKeys.first else {
                let context = DecodingError.Context(
                    codingPath: container.codingPath,
                    debugDescription: "Expected exactly one key, but got \(container.allKeys.count)"
                )
                throw DecodingError.dataCorrupted(context)
            }
            switch key {
            case .influxDBv2:
                let value = try container.decode(InfluxDBv2Parameters.self, forKey: .influxDBv2)
                self = .influxDBv2(value)
            case .influxDBv3Core:
                let value = try container.decode(InfluxDBv3CoreParameters.self, forKey: .influxDBv3Core)
                self = .influxDBv3Core(value)
            case .influxDBv3Enterprise:
                let value = try container.decode(InfluxDBv3EnterpriseParameters.self, forKey: .influxDBv3Enterprise)
                self = .influxDBv3Enterprise(value)
            }
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.container(keyedBy: CodingKeys.self)
            switch self {
            case .influxDBv2(let value):
                try container.encode(value, forKey: .influxDBv2)
            case .influxDBv3Core(let value):
                try container.encode(value, forKey: .influxDBv3Core)
            case .influxDBv3Enterprise(let value):
                try container.encode(value, forKey: .influxDBv3Enterprise)
            }
        }

        private enum CodingKeys: String, CodingKey {
            case influxDBv2 = "InfluxDBv2"
            case influxDBv3Core = "InfluxDBv3Core"
            case influxDBv3Enterprise = "InfluxDBv3Enterprise"
        }
    }

    public enum PercentOrAbsoluteLong: AWSEncodableShape & AWSDecodableShape, Sendable {
        /// Absolute long for InfluxDB parameters.
        case absolute(Int64)
        /// Percent for InfluxDB parameters.
        case percent(String)

        public init(from decoder: Decoder) throws {
            let container = try decoder.container(keyedBy: CodingKeys.self)
            guard container.allKeys.count == 1, let key = container.allKeys.first else {
                let context = DecodingError.Context(
                    codingPath: container.codingPath,
                    debugDescription: "Expected exactly one key, but got \(container.allKeys.count)"
                )
                throw DecodingError.dataCorrupted(context)
            }
            switch key {
            case .absolute:
                let value = try container.decode(Int64.self, forKey: .absolute)
                self = .absolute(value)
            case .percent:
                let value = try container.decode(String.self, forKey: .percent)
                self = .percent(value)
            }
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.container(keyedBy: CodingKeys.self)
            switch self {
            case .absolute(let value):
                try container.encode(value, forKey: .absolute)
            case .percent(let value):
                try container.encode(value, forKey: .percent)
            }
        }

        private enum CodingKeys: String, CodingKey {
            case absolute = "absolute"
            case percent = "percent"
        }
    }

    // MARK: Shapes

    public struct ConflictException: AWSErrorShape {
        public let message: String
        /// The identifier for the Timestream for InfluxDB resource associated with the request.
        public let resourceId: String
        /// The type of Timestream for InfluxDB resource associated with the request.
        public let resourceType: String

        @inlinable
        public init(message: String, resourceId: String, resourceType: String) {
            self.message = message
            self.resourceId = resourceId
            self.resourceType = resourceType
        }

        private enum CodingKeys: String, CodingKey {
            case message = "message"
            case resourceId = "resourceId"
            case resourceType = "resourceType"
        }
    }

    public struct CreateDbClusterInput: AWSEncodableShape {
        /// The amount of storage to allocate for your DB storage type in GiB (gibibytes).
        public let allocatedStorage: Int?
        /// The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.
        public let bucket: String?
        /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
        public let dbInstanceType: DbInstanceType
        /// The ID of the DB parameter group to assign to your DB cluster. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between three different types of provisioned Influx IOPS Included storage according to your workload requirements:   Influx I/O Included 3000 IOPS   Influx I/O Included 12000 IOPS   Influx I/O Included 16000 IOPS
        public let dbStorageType: DbStorageType?
        /// Specifies the type of cluster to create.
        public let deploymentType: ClusterDeploymentType?
        /// Specifies the behavior of failure recovery when the primary node of the cluster fails.
        public let failoverMode: FailoverMode?
        /// Configuration for sending InfluxDB engine logs to a specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The name that uniquely identifies the DB cluster when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB cluster names must be unique per customer and per region.
        public let name: String
        /// Specifies whether the network type of the Timestream for InfluxDB cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.
        public let organization: String?
        /// The password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a secret created in Secrets Manager in your account.
        public let password: String?
        /// The port number on which InfluxDB accepts connections. Valid Values: 1024-65535 Default: 8086 for InfluxDB v2, 8181 for InfluxDB v3 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
        public let port: Int?
        /// Configures the Timestream for InfluxDB cluster with a public IP to facilitate access from outside the VPC.
        public let publiclyAccessible: Bool?
        /// A list of key-value pairs to associate with the DB instance.
        public let tags: [String: String]?
        /// The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a secret created in Secrets Manager in your account.
        public let username: String?
        /// A list of VPC security group IDs to associate with the Timestream for InfluxDB cluster.
        public let vpcSecurityGroupIds: [String]
        /// A list of VPC subnet IDs to associate with the DB cluster. Provide at least two VPC subnet IDs in different Availability Zones when deploying with a Multi-AZ standby.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, bucket: String? = nil, dbInstanceType: DbInstanceType, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: ClusterDeploymentType? = nil, failoverMode: FailoverMode? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, organization: String? = nil, password: String? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, tags: [String: String]? = nil, username: String? = nil, vpcSecurityGroupIds: [String], vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.bucket = bucket
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.failoverMode = failoverMode
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.organization = organization
            self.password = password
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.tags = tags
            self.username = username
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        public func validate(name: String) throws {
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, max: 15360)
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, min: 20)
            try self.validate(self.bucket, name: "bucket", parent: name, max: 64)
            try self.validate(self.bucket, name: "bucket", parent: name, min: 2)
            try self.validate(self.bucket, name: "bucket", parent: name, pattern: "^[^_\"][^\"]*$")
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, max: 64)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, min: 3)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.name, name: "name", parent: name, max: 40)
            try self.validate(self.name, name: "name", parent: name, min: 3)
            try self.validate(self.name, name: "name", parent: name, pattern: "^[a-zA-z][a-zA-Z0-9]*(-[a-zA-Z0-9]+)*$")
            try self.validate(self.organization, name: "organization", parent: name, max: 64)
            try self.validate(self.organization, name: "organization", parent: name, min: 1)
            try self.validate(self.password, name: "password", parent: name, max: 64)
            try self.validate(self.password, name: "password", parent: name, min: 8)
            try self.validate(self.password, name: "password", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.port, name: "port", parent: name, max: 65535)
            try self.validate(self.port, name: "port", parent: name, min: 1024)
            try self.tags?.forEach {
                try validate($0.key, name: "tags.key", parent: name, max: 128)
                try validate($0.key, name: "tags.key", parent: name, min: 1)
                try validate($0.value, name: "tags[\"\($0.key)\"]", parent: name, max: 256)
            }
            try self.validate(self.tags, name: "tags", parent: name, max: 200)
            try self.validate(self.tags, name: "tags", parent: name, min: 1)
            try self.validate(self.username, name: "username", parent: name, max: 64)
            try self.validate(self.username, name: "username", parent: name, min: 1)
            try self.vpcSecurityGroupIds.forEach {
                try validate($0, name: "vpcSecurityGroupIds[]", parent: name, max: 64)
                try validate($0, name: "vpcSecurityGroupIds[]", parent: name, pattern: "^sg-[a-z0-9]+$")
            }
            try self.validate(self.vpcSecurityGroupIds, name: "vpcSecurityGroupIds", parent: name, max: 5)
            try self.validate(self.vpcSecurityGroupIds, name: "vpcSecurityGroupIds", parent: name, min: 1)
            try self.vpcSubnetIds.forEach {
                try validate($0, name: "vpcSubnetIds[]", parent: name, max: 64)
                try validate($0, name: "vpcSubnetIds[]", parent: name, pattern: "^subnet-[a-z0-9]+$")
            }
            try self.validate(self.vpcSubnetIds, name: "vpcSubnetIds", parent: name, max: 6)
            try self.validate(self.vpcSubnetIds, name: "vpcSubnetIds", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case bucket = "bucket"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case failoverMode = "failoverMode"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case organization = "organization"
            case password = "password"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case tags = "tags"
            case username = "username"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct CreateDbClusterOutput: AWSDecodableShape {
        /// A service-generated unique identifier.
        public let dbClusterId: String?
        /// The status of the DB cluster.
        public let dbClusterStatus: ClusterStatus?

        @inlinable
        public init(dbClusterId: String? = nil, dbClusterStatus: ClusterStatus? = nil) {
            self.dbClusterId = dbClusterId
            self.dbClusterStatus = dbClusterStatus
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
            case dbClusterStatus = "dbClusterStatus"
        }
    }

    public struct CreateDbInstanceInput: AWSEncodableShape {
        /// The amount of storage to allocate for your DB storage type in GiB (gibibytes).
        public let allocatedStorage: Int
        /// The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.
        public let bucket: String?
        /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
        public let dbInstanceType: DbInstanceType
        /// The id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements:   Influx IO Included 3000 IOPS   Influx IO Included 12000 IOPS   Influx IO Included 16000 IOPS
        public let dbStorageType: DbStorageType?
        /// Specifies whether the DB instance will be deployed as a standalone instance or with a Multi-AZ standby for high availability.
        public let deploymentType: DeploymentType?
        /// Configuration for sending InfluxDB engine logs to a specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB instance names must be unique per customer and per region.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.
        public let organization: String?
        /// The password of the initial admin user created in InfluxDB v2. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Secrets Manager in your account.
        public let password: String
        /// The port number on which InfluxDB accepts connections. Valid Values: 1024-65535 Default: 8086 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
        public let port: Int?
        /// Configures the DB instance with a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// A list of key-value pairs to associate with the DB instance.
        public let tags: [String: String]?
        /// The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon Secrets Manager in your account.
        public let username: String?
        /// A list of VPC security group IDs to associate with the DB instance.
        public let vpcSecurityGroupIds: [String]
        /// A list of VPC subnet IDs to associate with the DB instance. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int, bucket: String? = nil, dbInstanceType: DbInstanceType, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, organization: String? = nil, password: String, port: Int? = nil, publiclyAccessible: Bool? = nil, tags: [String: String]? = nil, username: String? = nil, vpcSecurityGroupIds: [String], vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.bucket = bucket
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.organization = organization
            self.password = password
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.tags = tags
            self.username = username
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        public func validate(name: String) throws {
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, max: 15360)
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, min: 20)
            try self.validate(self.bucket, name: "bucket", parent: name, max: 64)
            try self.validate(self.bucket, name: "bucket", parent: name, min: 2)
            try self.validate(self.bucket, name: "bucket", parent: name, pattern: "^[^_\"][^\"]*$")
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, max: 64)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, min: 3)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.name, name: "name", parent: name, max: 40)
            try self.validate(self.name, name: "name", parent: name, min: 3)
            try self.validate(self.name, name: "name", parent: name, pattern: "^[a-zA-Z][a-zA-Z0-9]*(-[a-zA-Z0-9]+)*$")
            try self.validate(self.organization, name: "organization", parent: name, max: 64)
            try self.validate(self.organization, name: "organization", parent: name, min: 1)
            try self.validate(self.password, name: "password", parent: name, max: 64)
            try self.validate(self.password, name: "password", parent: name, min: 8)
            try self.validate(self.password, name: "password", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.port, name: "port", parent: name, max: 65535)
            try self.validate(self.port, name: "port", parent: name, min: 1024)
            try self.tags?.forEach {
                try validate($0.key, name: "tags.key", parent: name, max: 128)
                try validate($0.key, name: "tags.key", parent: name, min: 1)
                try validate($0.value, name: "tags[\"\($0.key)\"]", parent: name, max: 256)
            }
            try self.validate(self.tags, name: "tags", parent: name, max: 200)
            try self.validate(self.tags, name: "tags", parent: name, min: 1)
            try self.validate(self.username, name: "username", parent: name, max: 64)
            try self.validate(self.username, name: "username", parent: name, min: 1)
            try self.vpcSecurityGroupIds.forEach {
                try validate($0, name: "vpcSecurityGroupIds[]", parent: name, max: 64)
                try validate($0, name: "vpcSecurityGroupIds[]", parent: name, pattern: "^sg-[a-z0-9]+$")
            }
            try self.validate(self.vpcSecurityGroupIds, name: "vpcSecurityGroupIds", parent: name, max: 5)
            try self.validate(self.vpcSecurityGroupIds, name: "vpcSecurityGroupIds", parent: name, min: 1)
            try self.vpcSubnetIds.forEach {
                try validate($0, name: "vpcSubnetIds[]", parent: name, max: 64)
                try validate($0, name: "vpcSubnetIds[]", parent: name, pattern: "^subnet-[a-z0-9]+$")
            }
            try self.validate(self.vpcSubnetIds, name: "vpcSubnetIds", parent: name, max: 6)
            try self.validate(self.vpcSubnetIds, name: "vpcSubnetIds", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case bucket = "bucket"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case organization = "organization"
            case password = "password"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case tags = "tags"
            case username = "username"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct CreateDbInstanceOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Availability Zone in which the DB instance resides.
        public let availabilityZone: String?
        /// Specifies the DbCluster to which this DbInstance belongs to.
        public let dbClusterId: String?
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group assigned to your DB instance.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Specifies the DbInstance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DbInstance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections. The default value is 8086.
        public let port: Int?
        /// Indicates if the DB instance has a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
        public let secondaryAvailabilityZone: String?
        /// The status of the DB instance.
        public let status: Status?
        /// A list of VPC security group IDs associated with the DB instance.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB instance.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, availabilityZone: String? = nil, dbClusterId: String? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, influxAuthParametersSecretArn: String? = nil, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, secondaryAvailabilityZone: String? = nil, status: Status? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.availabilityZone = availabilityZone
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.secondaryAvailabilityZone = secondaryAvailabilityZone
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case availabilityZone = "availabilityZone"
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case secondaryAvailabilityZone = "secondaryAvailabilityZone"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct CreateDbParameterGroupInput: AWSEncodableShape {
        /// A description of the DB parameter group.
        public let description: String?
        /// The name of the DB parameter group. The name must be unique per customer and per region.
        public let name: String
        /// A list of the parameters that comprise the DB parameter group.
        public let parameters: Parameters?
        /// A list of key-value pairs to associate with the DB parameter group.
        public let tags: [String: String]?

        @inlinable
        public init(description: String? = nil, name: String, parameters: Parameters? = nil, tags: [String: String]? = nil) {
            self.description = description
            self.name = name
            self.parameters = parameters
            self.tags = tags
        }

        public func validate(name: String) throws {
            try self.validate(self.name, name: "name", parent: name, max: 64)
            try self.validate(self.name, name: "name", parent: name, min: 3)
            try self.validate(self.name, name: "name", parent: name, pattern: "^[a-zA-Z][a-zA-Z0-9]*(-[a-zA-Z0-9]+)*$")
            try self.tags?.forEach {
                try validate($0.key, name: "tags.key", parent: name, max: 128)
                try validate($0.key, name: "tags.key", parent: name, min: 1)
                try validate($0.value, name: "tags[\"\($0.key)\"]", parent: name, max: 256)
            }
            try self.validate(self.tags, name: "tags", parent: name, max: 200)
            try self.validate(self.tags, name: "tags", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case description = "description"
            case name = "name"
            case parameters = "parameters"
            case tags = "tags"
        }
    }

    public struct CreateDbParameterGroupOutput: AWSDecodableShape {
        /// The Amazon Resource Name (ARM) of the DB parameter group.
        public let arn: String
        /// The description of the DB parameter group.
        public let description: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The customer-supplied name that uniquely identifies the DB parameter group when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// A list of the parameters that comprise the DB parameter group.
        public let parameters: Parameters?

        @inlinable
        public init(arn: String, description: String? = nil, id: String, name: String, parameters: Parameters? = nil) {
            self.arn = arn
            self.description = description
            self.id = id
            self.name = name
            self.parameters = parameters
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case description = "description"
            case id = "id"
            case name = "name"
            case parameters = "parameters"
        }
    }

    public struct DbClusterSummary: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB cluster.
        public let arn: String
        /// The Timestream for InfluxDB DB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Deployment type of the DB cluster
        public let deploymentType: ClusterDeploymentType?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for write and read operations.
        public let endpoint: String?
        /// The engine type of your DB cluster.
        public let engineType: EngineType?
        /// Service-generated unique identifier of the DB cluster to retrieve.
        public let id: String
        /// Customer supplied name of the Timestream for InfluxDB cluster.
        public let name: String
        /// Specifies whether the network type of the Timestream for InfluxDB Cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
        public let readerEndpoint: String?
        /// The status of the DB cluster.
        public let status: ClusterStatus?

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, dbInstanceType: DbInstanceType? = nil, dbStorageType: DbStorageType? = nil, deploymentType: ClusterDeploymentType? = nil, endpoint: String? = nil, engineType: EngineType? = nil, id: String, name: String, networkType: NetworkType? = nil, port: Int? = nil, readerEndpoint: String? = nil, status: ClusterStatus? = nil) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.engineType = engineType
            self.id = id
            self.name = name
            self.networkType = networkType
            self.port = port
            self.readerEndpoint = readerEndpoint
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case dbInstanceType = "dbInstanceType"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case engineType = "engineType"
            case id = "id"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case readerEndpoint = "readerEndpoint"
            case status = "status"
        }
    }

    public struct DbInstanceForClusterSummary: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type in GiB (gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Timestream for InfluxDB instance type to run InfluxDB on.
        public let dbInstanceType: DbInstanceType?
        /// The storage type for your DB instance.
        public let dbStorageType: DbStorageType?
        /// Specifies the deployment type if applicable.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// The service-generated unique identifier of the DB instance.
        public let id: String
        /// Specifies the DB instance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DB instance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// A service-generated name for the DB instance based on the customer-supplied name for the DB cluster.
        public let name: String
        /// Specifies whether the network type of the Timestream for InfluxDB instance is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// The status of the DB instance.
        public let status: Status?

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, dbInstanceType: DbInstanceType? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, status: Status? = nil) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.name = name
            self.networkType = networkType
            self.port = port
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case dbInstanceType = "dbInstanceType"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case status = "status"
        }
    }

    public struct DbInstanceSummary: AWSDecodableShape {
        /// The amount of storage to allocate for your DbStorageType in GiB (gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Timestream for InfluxDB instance type to run InfluxDB on.
        public let dbInstanceType: DbInstanceType?
        /// The storage type for your DB instance.
        public let dbStorageType: DbStorageType?
        /// Single-Instance or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// The service-generated unique identifier of the DB instance.
        public let id: String
        /// This customer-supplied name uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// The status of the DB instance.
        public let status: Status?

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, dbInstanceType: DbInstanceType? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, name: String, networkType: NetworkType? = nil, port: Int? = nil, status: Status? = nil) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.name = name
            self.networkType = networkType
            self.port = port
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case dbInstanceType = "dbInstanceType"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case status = "status"
        }
    }

    public struct DbParameterGroupSummary: AWSDecodableShape {
        /// The Amazon Resource Name (ARN) of the DB parameter group.
        public let arn: String
        /// A description of the DB parameter group.
        public let description: String?
        /// A service-generated unique identifier.
        public let id: String
        /// This customer-supplied name uniquely identifies the parameter group.
        public let name: String

        @inlinable
        public init(arn: String, description: String? = nil, id: String, name: String) {
            self.arn = arn
            self.description = description
            self.id = id
            self.name = name
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case description = "description"
            case id = "id"
            case name = "name"
        }
    }

    public struct DeleteDbClusterInput: AWSEncodableShape {
        /// Service-generated unique identifier of the DB cluster.
        public let dbClusterId: String

        @inlinable
        public init(dbClusterId: String) {
            self.dbClusterId = dbClusterId
        }

        public func validate(name: String) throws {
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, max: 64)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, min: 3)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
        }
    }

    public struct DeleteDbClusterOutput: AWSDecodableShape {
        /// The status of the DB cluster.
        public let dbClusterStatus: ClusterStatus?

        @inlinable
        public init(dbClusterStatus: ClusterStatus? = nil) {
            self.dbClusterStatus = dbClusterStatus
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterStatus = "dbClusterStatus"
        }
    }

    public struct DeleteDbInstanceInput: AWSEncodableShape {
        /// The id of the DB instance.
        public let identifier: String

        @inlinable
        public init(identifier: String) {
            self.identifier = identifier
        }

        public func validate(name: String) throws {
            try self.validate(self.identifier, name: "identifier", parent: name, max: 64)
            try self.validate(self.identifier, name: "identifier", parent: name, min: 3)
            try self.validate(self.identifier, name: "identifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case identifier = "identifier"
        }
    }

    public struct DeleteDbInstanceOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Availability Zone in which the DB instance resides.
        public let availabilityZone: String?
        /// Specifies the DbCluster to which this DbInstance belongs to.
        public let dbClusterId: String?
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group assigned to your DB instance.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Specifies the DbInstance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DbInstance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// Indicates if the DB instance has a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
        public let secondaryAvailabilityZone: String?
        /// The status of the DB instance.
        public let status: Status?
        /// A list of VPC security group IDs associated with the DB instance.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB instance.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, availabilityZone: String? = nil, dbClusterId: String? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, influxAuthParametersSecretArn: String? = nil, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, secondaryAvailabilityZone: String? = nil, status: Status? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.availabilityZone = availabilityZone
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.secondaryAvailabilityZone = secondaryAvailabilityZone
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case availabilityZone = "availabilityZone"
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case secondaryAvailabilityZone = "secondaryAvailabilityZone"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct Duration: AWSEncodableShape & AWSDecodableShape {
        /// The type of duration for InfluxDB parameters.
        public let durationType: DurationType
        /// The value of duration for InfluxDB parameters.
        public let value: Int64

        @inlinable
        public init(durationType: DurationType, value: Int64) {
            self.durationType = durationType
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case durationType = "durationType"
            case value = "value"
        }
    }

    public struct GetDbClusterInput: AWSEncodableShape {
        /// Service-generated unique identifier of the DB cluster to retrieve.
        public let dbClusterId: String

        @inlinable
        public init(dbClusterId: String) {
            self.dbClusterId = dbClusterId
        }

        public func validate(name: String) throws {
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, max: 64)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, min: 3)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
        }
    }

    public struct GetDbClusterOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB cluster.
        public let arn: String
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The ID of the DB parameter group assigned to your DB cluster.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Deployment type of the DB cluster.
        public let deploymentType: ClusterDeploymentType?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for write and read operations.
        public let endpoint: String?
        /// The engine type of your DB cluster.
        public let engineType: EngineType?
        /// The configured failover mode for the DB cluster.
        public let failoverMode: FailoverMode?
        /// Service-generated unique identifier of the DB cluster to retrieve.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// Customer-supplied name of the Timestream for InfluxDB cluster.
        public let name: String
        /// Specifies whether the network type of the Timestream for InfluxDB cluster is IPv4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// Indicates if the DB cluster has a public IP to facilitate access from outside the VPC.
        public let publiclyAccessible: Bool?
        /// The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
        public let readerEndpoint: String?
        /// The status of the DB cluster.
        public let status: ClusterStatus?
        /// A list of VPC security group IDs associated with the DB cluster.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB cluster.
        public let vpcSubnetIds: [String]?

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: ClusterDeploymentType? = nil, endpoint: String? = nil, engineType: EngineType? = nil, failoverMode: FailoverMode? = nil, id: String, influxAuthParametersSecretArn: String? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, readerEndpoint: String? = nil, status: ClusterStatus? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]? = nil) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.engineType = engineType
            self.failoverMode = failoverMode
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.readerEndpoint = readerEndpoint
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case engineType = "engineType"
            case failoverMode = "failoverMode"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case readerEndpoint = "readerEndpoint"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct GetDbInstanceInput: AWSEncodableShape {
        /// The id of the DB instance.
        public let identifier: String

        @inlinable
        public init(identifier: String) {
            self.identifier = identifier
        }

        public func validate(name: String) throws {
            try self.validate(self.identifier, name: "identifier", parent: name, max: 64)
            try self.validate(self.identifier, name: "identifier", parent: name, min: 3)
            try self.validate(self.identifier, name: "identifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case identifier = "identifier"
        }
    }

    public struct GetDbInstanceOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Availability Zone in which the DB instance resides.
        public let availabilityZone: String?
        /// Specifies the DbCluster to which this DbInstance belongs to.
        public let dbClusterId: String?
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group assigned to your DB instance.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Specifies the DbInstance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DbInstance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// Indicates if the DB instance has a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
        public let secondaryAvailabilityZone: String?
        /// The status of the DB instance.
        public let status: Status?
        /// A list of VPC security group IDs associated with the DB instance.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB instance.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, availabilityZone: String? = nil, dbClusterId: String? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, influxAuthParametersSecretArn: String? = nil, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, secondaryAvailabilityZone: String? = nil, status: Status? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.availabilityZone = availabilityZone
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.secondaryAvailabilityZone = secondaryAvailabilityZone
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case availabilityZone = "availabilityZone"
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case secondaryAvailabilityZone = "secondaryAvailabilityZone"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct GetDbParameterGroupInput: AWSEncodableShape {
        /// The id of the DB parameter group.
        public let identifier: String

        @inlinable
        public init(identifier: String) {
            self.identifier = identifier
        }

        public func validate(name: String) throws {
            try self.validate(self.identifier, name: "identifier", parent: name, max: 64)
            try self.validate(self.identifier, name: "identifier", parent: name, min: 3)
            try self.validate(self.identifier, name: "identifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case identifier = "identifier"
        }
    }

    public struct GetDbParameterGroupOutput: AWSDecodableShape {
        /// The Amazon Resource Name (ARN) of the DB parameter group.
        public let arn: String
        /// A description of the DB parameter group.
        public let description: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The customer-supplied name that uniquely identifies the DB parameter group when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// The parameters that comprise the DB parameter group.
        public let parameters: Parameters?

        @inlinable
        public init(arn: String, description: String? = nil, id: String, name: String, parameters: Parameters? = nil) {
            self.arn = arn
            self.description = description
            self.id = id
            self.name = name
            self.parameters = parameters
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case description = "description"
            case id = "id"
            case name = "name"
            case parameters = "parameters"
        }
    }

    public struct InfluxDBv2Parameters: AWSEncodableShape & AWSDecodableShape {
        /// Include option to show detailed logs for Flux queries. Default: false
        public let fluxLogEnabled: Bool?
        /// Maximum duration the server should keep established connections alive while waiting for new requests. Set to 0 for no timeout. Default: 3 minutes
        public let httpIdleTimeout: Duration?
        /// Maximum duration the server should try to read HTTP headers for new requests. Set to 0 for no timeout. Default: 10 seconds
        public let httpReadHeaderTimeout: Duration?
        /// Maximum duration the server should try to read the entirety of new requests. Set to 0 for no timeout. Default: 0
        public let httpReadTimeout: Duration?
        /// Maximum duration the server should spend processing and responding to write requests. Set to 0 for no timeout. Default: 0
        public let httpWriteTimeout: Duration?
        /// Maximum number of group by time buckets a SELECT statement can create. 0 allows an unlimited number of buckets. Default: 0
        public let influxqlMaxSelectBuckets: Int64?
        /// Maximum number of points a SELECT statement can process. 0 allows an unlimited number of points. InfluxDB checks the point count every second (so queries exceeding the maximum arent immediately aborted). Default: 0
        public let influxqlMaxSelectPoint: Int64?
        /// Maximum number of series a SELECT statement can return. 0 allows an unlimited number of series. Default: 0
        public let influxqlMaxSelectSeries: Int64?
        /// Log output level. InfluxDB outputs log entries with severity levels greater than or equal to the level specified. Default: info
        public let logLevel: LogLevel?
        /// Disable the HTTP /metrics endpoint which exposes internal InfluxDB metrics. Default: false
        public let metricsDisabled: Bool?
        /// Disable the task scheduler. If problematic tasks prevent InfluxDB from starting, use this option to start InfluxDB without scheduling or executing tasks. Default: false
        public let noTasks: Bool?
        /// Disable the /debug/pprof HTTP endpoint. This endpoint provides runtime profiling data and can be helpful when debugging. Default: true
        public let pprofDisabled: Bool?
        /// Number of queries allowed to execute concurrently. Setting to 0 allows an unlimited number of concurrent queries. Default: 0
        public let queryConcurrency: Int?
        /// Initial bytes of memory allocated for a query. Default: 0
        public let queryInitialMemoryBytes: Int64?
        /// Maximum number of queries allowed in execution queue. When queue limit is reached, new queries are rejected. Setting to 0 allows an unlimited number of queries in the queue. Default: 0
        public let queryMaxMemoryBytes: Int64?
        /// Maximum bytes of memory allowed for a single query. Must be greater or equal to queryInitialMemoryBytes. Default: 0
        public let queryMemoryBytes: Int64?
        /// Maximum number of queries allowed in execution queue. When queue limit is reached, new queries are rejected. Setting to 0 allows an unlimited number of queries in the queue. Default: 0
        public let queryQueueSize: Int?
        /// Specifies the Time to Live (TTL) in minutes for newly created user sessions. Default: 60
        public let sessionLength: Int?
        /// Disables automatically extending a users session TTL on each request. By default, every request sets the sessions expiration time to five minutes from now. When disabled, sessions expire after the specified session length and the user is redirected to the login page, even if recently active. Default: false
        public let sessionRenewDisabled: Bool?
        /// Maximum size (in bytes) a shards cache can reach before it starts rejecting writes. Must be greater than storageCacheSnapShotMemorySize and lower than instances total memory capacity. We recommend setting it to below 15% of the total memory capacity. Default: 1073741824
        public let storageCacheMaxMemorySize: Int64?
        /// Size (in bytes) at which the storage engine will snapshot the cache and write it to a TSM file to make more memory available. Must not be greater than storageCacheMaxMemorySize. Default: 26214400
        public let storageCacheSnapshotMemorySize: Int64?
        /// Duration at which the storage engine will snapshot the cache and write it to a new TSM file if the shard hasnt received writes or deletes. Default: 10 minutes
        public let storageCacheSnapshotWriteColdDuration: Duration?
        /// Duration at which the storage engine will compact all TSM files in a shard if it hasn't received writes or deletes. Default: 4 hours
        public let storageCompactFullWriteColdDuration: Duration?
        /// Rate limit (in bytes per second) that TSM compactions can write to disk. Default: 50331648
        public let storageCompactThroughputBurst: Int64?
        /// Maximum number of full and level compactions that can run concurrently. A value of 0 results in 50% of runtime.GOMAXPROCS(0) used at runtime. Any number greater than zero limits compactions to that value. This setting does not apply to cache snapshotting. Default: 0
        public let storageMaxConcurrentCompactions: Int?
        /// Size (in bytes) at which an index write-ahead log (WAL) file will compact into an index file. Lower sizes will cause log files to be compacted more quickly and result in lower heap usage at the expense of write throughput. Default: 1048576
        public let storageMaxIndexLogFileSize: Int64?
        /// Skip field size validation on incoming write requests. Default: false
        public let storageNoValidateFieldSize: Bool?
        /// Interval of retention policy enforcement checks. Must be greater than 0. Default: 30 minutes
        public let storageRetentionCheckInterval: Duration?
        /// Maximum number of snapshot compactions that can run concurrently across all series partitions in a database. Default: 0
        public let storageSeriesFileMaxConcurrentSnapshotCompactions: Int?
        /// Size of the internal cache used in the TSI index to store previously calculated series results. Cached results are returned quickly rather than needing to be recalculated when a subsequent query with the same tag key/value predicate is executed. Setting this value to 0 will disable the cache and may decrease query performance. Default: 100
        public let storageSeriesIdSetCacheSize: Int64?
        /// Maximum number writes to the WAL directory to attempt at the same time. Setting this value to 0 results in number of processing units available x2. Default: 0
        public let storageWalMaxConcurrentWrites: Int?
        /// Maximum amount of time a write request to the WAL directory will wait when the maximum number of concurrent active writes to the WAL directory has been met. Set to 0 to disable the timeout. Default: 10 minutes
        public let storageWalMaxWriteDelay: Duration?
        /// Enable tracing in InfluxDB and specifies the tracing type. Tracing is disabled by default.
        public let tracingType: TracingType?
        /// Disable the InfluxDB user interface (UI). The UI is enabled by default. Default: false
        public let uiDisabled: Bool?

        @inlinable
        public init(fluxLogEnabled: Bool? = nil, httpIdleTimeout: Duration? = nil, httpReadHeaderTimeout: Duration? = nil, httpReadTimeout: Duration? = nil, httpWriteTimeout: Duration? = nil, influxqlMaxSelectBuckets: Int64? = nil, influxqlMaxSelectPoint: Int64? = nil, influxqlMaxSelectSeries: Int64? = nil, logLevel: LogLevel? = nil, metricsDisabled: Bool? = nil, noTasks: Bool? = nil, pprofDisabled: Bool? = nil, queryConcurrency: Int? = nil, queryInitialMemoryBytes: Int64? = nil, queryMaxMemoryBytes: Int64? = nil, queryMemoryBytes: Int64? = nil, queryQueueSize: Int? = nil, sessionLength: Int? = nil, sessionRenewDisabled: Bool? = nil, storageCacheMaxMemorySize: Int64? = nil, storageCacheSnapshotMemorySize: Int64? = nil, storageCacheSnapshotWriteColdDuration: Duration? = nil, storageCompactFullWriteColdDuration: Duration? = nil, storageCompactThroughputBurst: Int64? = nil, storageMaxConcurrentCompactions: Int? = nil, storageMaxIndexLogFileSize: Int64? = nil, storageNoValidateFieldSize: Bool? = nil, storageRetentionCheckInterval: Duration? = nil, storageSeriesFileMaxConcurrentSnapshotCompactions: Int? = nil, storageSeriesIdSetCacheSize: Int64? = nil, storageWalMaxConcurrentWrites: Int? = nil, storageWalMaxWriteDelay: Duration? = nil, tracingType: TracingType? = nil, uiDisabled: Bool? = nil) {
            self.fluxLogEnabled = fluxLogEnabled
            self.httpIdleTimeout = httpIdleTimeout
            self.httpReadHeaderTimeout = httpReadHeaderTimeout
            self.httpReadTimeout = httpReadTimeout
            self.httpWriteTimeout = httpWriteTimeout
            self.influxqlMaxSelectBuckets = influxqlMaxSelectBuckets
            self.influxqlMaxSelectPoint = influxqlMaxSelectPoint
            self.influxqlMaxSelectSeries = influxqlMaxSelectSeries
            self.logLevel = logLevel
            self.metricsDisabled = metricsDisabled
            self.noTasks = noTasks
            self.pprofDisabled = pprofDisabled
            self.queryConcurrency = queryConcurrency
            self.queryInitialMemoryBytes = queryInitialMemoryBytes
            self.queryMaxMemoryBytes = queryMaxMemoryBytes
            self.queryMemoryBytes = queryMemoryBytes
            self.queryQueueSize = queryQueueSize
            self.sessionLength = sessionLength
            self.sessionRenewDisabled = sessionRenewDisabled
            self.storageCacheMaxMemorySize = storageCacheMaxMemorySize
            self.storageCacheSnapshotMemorySize = storageCacheSnapshotMemorySize
            self.storageCacheSnapshotWriteColdDuration = storageCacheSnapshotWriteColdDuration
            self.storageCompactFullWriteColdDuration = storageCompactFullWriteColdDuration
            self.storageCompactThroughputBurst = storageCompactThroughputBurst
            self.storageMaxConcurrentCompactions = storageMaxConcurrentCompactions
            self.storageMaxIndexLogFileSize = storageMaxIndexLogFileSize
            self.storageNoValidateFieldSize = storageNoValidateFieldSize
            self.storageRetentionCheckInterval = storageRetentionCheckInterval
            self.storageSeriesFileMaxConcurrentSnapshotCompactions = storageSeriesFileMaxConcurrentSnapshotCompactions
            self.storageSeriesIdSetCacheSize = storageSeriesIdSetCacheSize
            self.storageWalMaxConcurrentWrites = storageWalMaxConcurrentWrites
            self.storageWalMaxWriteDelay = storageWalMaxWriteDelay
            self.tracingType = tracingType
            self.uiDisabled = uiDisabled
        }

        private enum CodingKeys: String, CodingKey {
            case fluxLogEnabled = "fluxLogEnabled"
            case httpIdleTimeout = "httpIdleTimeout"
            case httpReadHeaderTimeout = "httpReadHeaderTimeout"
            case httpReadTimeout = "httpReadTimeout"
            case httpWriteTimeout = "httpWriteTimeout"
            case influxqlMaxSelectBuckets = "influxqlMaxSelectBuckets"
            case influxqlMaxSelectPoint = "influxqlMaxSelectPoint"
            case influxqlMaxSelectSeries = "influxqlMaxSelectSeries"
            case logLevel = "logLevel"
            case metricsDisabled = "metricsDisabled"
            case noTasks = "noTasks"
            case pprofDisabled = "pprofDisabled"
            case queryConcurrency = "queryConcurrency"
            case queryInitialMemoryBytes = "queryInitialMemoryBytes"
            case queryMaxMemoryBytes = "queryMaxMemoryBytes"
            case queryMemoryBytes = "queryMemoryBytes"
            case queryQueueSize = "queryQueueSize"
            case sessionLength = "sessionLength"
            case sessionRenewDisabled = "sessionRenewDisabled"
            case storageCacheMaxMemorySize = "storageCacheMaxMemorySize"
            case storageCacheSnapshotMemorySize = "storageCacheSnapshotMemorySize"
            case storageCacheSnapshotWriteColdDuration = "storageCacheSnapshotWriteColdDuration"
            case storageCompactFullWriteColdDuration = "storageCompactFullWriteColdDuration"
            case storageCompactThroughputBurst = "storageCompactThroughputBurst"
            case storageMaxConcurrentCompactions = "storageMaxConcurrentCompactions"
            case storageMaxIndexLogFileSize = "storageMaxIndexLogFileSize"
            case storageNoValidateFieldSize = "storageNoValidateFieldSize"
            case storageRetentionCheckInterval = "storageRetentionCheckInterval"
            case storageSeriesFileMaxConcurrentSnapshotCompactions = "storageSeriesFileMaxConcurrentSnapshotCompactions"
            case storageSeriesIdSetCacheSize = "storageSeriesIdSetCacheSize"
            case storageWalMaxConcurrentWrites = "storageWalMaxConcurrentWrites"
            case storageWalMaxWriteDelay = "storageWalMaxWriteDelay"
            case tracingType = "tracingType"
            case uiDisabled = "uiDisabled"
        }
    }

    public struct InfluxDBv3CoreParameters: AWSEncodableShape & AWSDecodableShape {
        /// Provides custom configuration to DataFusion as a comma-separated list of key:value pairs.
        public let dataFusionConfig: String?
        /// When multiple parquet files are required in a sorted way (deduplication for example), specifies the maximum fanout. Default: 1000
        public let dataFusionMaxParquetFanout: Int?
        /// Sets the maximum number of DataFusion runtime threads to use.
        public let dataFusionNumThreads: Int?
        /// Disables the LIFO slot of the DataFusion runtime.
        public let dataFusionRuntimeDisableLifoSlot: Bool?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion tokio runtime polls for external eventsfor example: timers, I/O.
        public let dataFusionRuntimeEventInterval: Int?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion runtime polls the global task queue.
        public let dataFusionRuntimeGlobalQueueInterval: Int?
        /// Specifies the limit for additional threads spawned by the DataFusion runtime.
        public let dataFusionRuntimeMaxBlockingThreads: Int?
        /// Configures the maximum number of events processed per tick by the tokio DataFusion runtime.
        public let dataFusionRuntimeMaxIoEventsPerTick: Int?
        /// Sets a custom timeout for a thread in the blocking pool of the tokio DataFusion runtime.
        public let dataFusionRuntimeThreadKeepAlive: Duration?
        /// Sets the thread priority for tokio DataFusion runtime workers. Default: 10
        public let dataFusionRuntimeThreadPriority: Int?
        /// Specifies the DataFusion tokio runtime type. Default: multi-thread
        public let dataFusionRuntimeType: DataFusionRuntimeType?
        /// Uses a cached parquet loader when reading parquet files from the object store.
        public let dataFusionUseCachedParquetLoader: Bool?
        /// Specifies the grace period before permanently deleting data. Default: 24h
        public let deleteGracePeriod: Duration?
        /// Disables the in-memory Parquet cache. By default, the cache is enabled.
        public let disableParquetMemCache: Bool?
        /// Specifies the interval to evict expired entries from the distinct value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public let distinctCacheEvictionInterval: Duration?
        /// Specifies the size of memory pool used during query execution. Can be given as absolute value in bytes or as a percentage of the total available memoryfor example: 8000000000 or 10%. Default: 20%
        public let execMemPoolBytes: PercentOrAbsoluteLong?
        /// Specifies the threshold for the internal memory buffer. Supports either a percentage (portion of available memory) or absolute value in MBfor example: 70% or 100 Default: 70%
        public let forceSnapshotMemThreshold: PercentOrAbsoluteLong?
        /// Specifies the duration that Parquet files are arranged into. Data timestamps land each row into a file of this duration. Supported durations are 1m, 5m, and 10m. These files are known as generation 1 files that the compactor in InfluxDB 3 Enterprise can merge into larger generations. Default: 10m
        public let gen1Duration: Duration?
        /// Specifies how far back to look when creating generation 1 Parquet files. Default: 24h
        public let gen1LookbackDuration: Duration?
        /// Sets the default duration for hard deletion of data. Default: 90d
        public let hardDeleteDefaultDuration: Duration?
        /// Specifies the interval to evict expired entries from the Last-N-Value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public let lastCacheEvictionInterval: Duration?
        /// Sets the filter directive for logs.
        public let logFilter: String?
        /// Defines the message format for logs. Default: full
        public let logFormat: LogFormats?
        /// Specifies the maximum size of HTTP requests. Default: 10485760
        public let maxHttpRequestSize: Int64?
        /// Sets the interval to check if the in-memory Parquet cache needs to be pruned. Default: 1s
        public let parquetMemCachePruneInterval: Duration?
        /// Specifies the percentage of entries to prune during a prune operation on the in-memory Parquet cache. Default: 0.1
        public let parquetMemCachePrunePercentage: Float?
        /// Specifies the time window for caching recent Parquet files in memory. Default: 5h
        public let parquetMemCacheQueryPathDuration: Duration?
        /// Specifies the size of the in-memory Parquet cache in megabytes or percentage of total available memory. Default: 20%
        public let parquetMemCacheSize: PercentOrAbsoluteLong?
        /// Specifies the interval to prefetch into the Parquet cache during compaction. Default: 3d
        public let preemptiveCacheAge: Duration?
        /// Limits the number of Parquet files a query can access. If a query attempts to read more than this limit, InfluxDB 3 returns an error. Default: 432
        public let queryFileLimit: Int?
        /// Defines the size of the query log. Up to this many queries remain in the log before older queries are evicted to make room for new ones. Default: 1000
        public let queryLogSize: Int?
        /// The interval at which retention policies are checked and enforced. Enter as a human-readable timefor example: 30m or 1h. Default: 30m
        public let retentionCheckInterval: Duration?
        /// Specifies the number of snapshotted WAL files to retain in the object store. Flushing the WAL files does not clear the WAL files immediately; they are deleted when the number of snapshotted WAL files exceeds this number. Default: 300
        public let snapshottedWalFilesToKeep: Int?
        /// Limits the concurrency level for table index cache operations. Default: 8
        public let tableIndexCacheConcurrencyLimit: Int?
        /// Specifies the maximum number of entries in the table index cache. Default: 1000
        public let tableIndexCacheMaxEntries: Int?
        /// Specifies the maximum number of write requests that can be buffered before a flush must be executed and succeed. Default: 100000
        public let walMaxWriteBufferSize: Int?
        /// Concurrency limit during WAL replay. Setting this number too high can lead to OOM. The default is dynamically determined. Default: max(num_cpus, 10)
        public let walReplayConcurrencyLimit: Int?
        /// Determines whether WAL replay should fail when encountering errors. Default: false
        public let walReplayFailOnError: Bool?
        /// Defines the number of WAL files to attempt to remove in a snapshot. This, multiplied by the interval, determines how often snapshots are taken. Default: 600
        public let walSnapshotSize: Int?

        @inlinable
        public init(dataFusionConfig: String? = nil, dataFusionMaxParquetFanout: Int? = nil, dataFusionNumThreads: Int? = nil, dataFusionRuntimeDisableLifoSlot: Bool? = nil, dataFusionRuntimeEventInterval: Int? = nil, dataFusionRuntimeGlobalQueueInterval: Int? = nil, dataFusionRuntimeMaxBlockingThreads: Int? = nil, dataFusionRuntimeMaxIoEventsPerTick: Int? = nil, dataFusionRuntimeThreadKeepAlive: Duration? = nil, dataFusionRuntimeThreadPriority: Int? = nil, dataFusionRuntimeType: DataFusionRuntimeType? = nil, dataFusionUseCachedParquetLoader: Bool? = nil, deleteGracePeriod: Duration? = nil, disableParquetMemCache: Bool? = nil, distinctCacheEvictionInterval: Duration? = nil, execMemPoolBytes: PercentOrAbsoluteLong? = nil, forceSnapshotMemThreshold: PercentOrAbsoluteLong? = nil, gen1Duration: Duration? = nil, gen1LookbackDuration: Duration? = nil, hardDeleteDefaultDuration: Duration? = nil, lastCacheEvictionInterval: Duration? = nil, logFilter: String? = nil, logFormat: LogFormats? = nil, maxHttpRequestSize: Int64? = nil, parquetMemCachePruneInterval: Duration? = nil, parquetMemCachePrunePercentage: Float? = nil, parquetMemCacheQueryPathDuration: Duration? = nil, parquetMemCacheSize: PercentOrAbsoluteLong? = nil, preemptiveCacheAge: Duration? = nil, queryFileLimit: Int? = nil, queryLogSize: Int? = nil, retentionCheckInterval: Duration? = nil, snapshottedWalFilesToKeep: Int? = nil, tableIndexCacheConcurrencyLimit: Int? = nil, tableIndexCacheMaxEntries: Int? = nil, walMaxWriteBufferSize: Int? = nil, walReplayConcurrencyLimit: Int? = nil, walReplayFailOnError: Bool? = nil, walSnapshotSize: Int? = nil) {
            self.dataFusionConfig = dataFusionConfig
            self.dataFusionMaxParquetFanout = dataFusionMaxParquetFanout
            self.dataFusionNumThreads = dataFusionNumThreads
            self.dataFusionRuntimeDisableLifoSlot = dataFusionRuntimeDisableLifoSlot
            self.dataFusionRuntimeEventInterval = dataFusionRuntimeEventInterval
            self.dataFusionRuntimeGlobalQueueInterval = dataFusionRuntimeGlobalQueueInterval
            self.dataFusionRuntimeMaxBlockingThreads = dataFusionRuntimeMaxBlockingThreads
            self.dataFusionRuntimeMaxIoEventsPerTick = dataFusionRuntimeMaxIoEventsPerTick
            self.dataFusionRuntimeThreadKeepAlive = dataFusionRuntimeThreadKeepAlive
            self.dataFusionRuntimeThreadPriority = dataFusionRuntimeThreadPriority
            self.dataFusionRuntimeType = dataFusionRuntimeType
            self.dataFusionUseCachedParquetLoader = dataFusionUseCachedParquetLoader
            self.deleteGracePeriod = deleteGracePeriod
            self.disableParquetMemCache = disableParquetMemCache
            self.distinctCacheEvictionInterval = distinctCacheEvictionInterval
            self.execMemPoolBytes = execMemPoolBytes
            self.forceSnapshotMemThreshold = forceSnapshotMemThreshold
            self.gen1Duration = gen1Duration
            self.gen1LookbackDuration = gen1LookbackDuration
            self.hardDeleteDefaultDuration = hardDeleteDefaultDuration
            self.lastCacheEvictionInterval = lastCacheEvictionInterval
            self.logFilter = logFilter
            self.logFormat = logFormat
            self.maxHttpRequestSize = maxHttpRequestSize
            self.parquetMemCachePruneInterval = parquetMemCachePruneInterval
            self.parquetMemCachePrunePercentage = parquetMemCachePrunePercentage
            self.parquetMemCacheQueryPathDuration = parquetMemCacheQueryPathDuration
            self.parquetMemCacheSize = parquetMemCacheSize
            self.preemptiveCacheAge = preemptiveCacheAge
            self.queryFileLimit = queryFileLimit
            self.queryLogSize = queryLogSize
            self.retentionCheckInterval = retentionCheckInterval
            self.snapshottedWalFilesToKeep = snapshottedWalFilesToKeep
            self.tableIndexCacheConcurrencyLimit = tableIndexCacheConcurrencyLimit
            self.tableIndexCacheMaxEntries = tableIndexCacheMaxEntries
            self.walMaxWriteBufferSize = walMaxWriteBufferSize
            self.walReplayConcurrencyLimit = walReplayConcurrencyLimit
            self.walReplayFailOnError = walReplayFailOnError
            self.walSnapshotSize = walSnapshotSize
        }

        private enum CodingKeys: String, CodingKey {
            case dataFusionConfig = "dataFusionConfig"
            case dataFusionMaxParquetFanout = "dataFusionMaxParquetFanout"
            case dataFusionNumThreads = "dataFusionNumThreads"
            case dataFusionRuntimeDisableLifoSlot = "dataFusionRuntimeDisableLifoSlot"
            case dataFusionRuntimeEventInterval = "dataFusionRuntimeEventInterval"
            case dataFusionRuntimeGlobalQueueInterval = "dataFusionRuntimeGlobalQueueInterval"
            case dataFusionRuntimeMaxBlockingThreads = "dataFusionRuntimeMaxBlockingThreads"
            case dataFusionRuntimeMaxIoEventsPerTick = "dataFusionRuntimeMaxIoEventsPerTick"
            case dataFusionRuntimeThreadKeepAlive = "dataFusionRuntimeThreadKeepAlive"
            case dataFusionRuntimeThreadPriority = "dataFusionRuntimeThreadPriority"
            case dataFusionRuntimeType = "dataFusionRuntimeType"
            case dataFusionUseCachedParquetLoader = "dataFusionUseCachedParquetLoader"
            case deleteGracePeriod = "deleteGracePeriod"
            case disableParquetMemCache = "disableParquetMemCache"
            case distinctCacheEvictionInterval = "distinctCacheEvictionInterval"
            case execMemPoolBytes = "execMemPoolBytes"
            case forceSnapshotMemThreshold = "forceSnapshotMemThreshold"
            case gen1Duration = "gen1Duration"
            case gen1LookbackDuration = "gen1LookbackDuration"
            case hardDeleteDefaultDuration = "hardDeleteDefaultDuration"
            case lastCacheEvictionInterval = "lastCacheEvictionInterval"
            case logFilter = "logFilter"
            case logFormat = "logFormat"
            case maxHttpRequestSize = "maxHttpRequestSize"
            case parquetMemCachePruneInterval = "parquetMemCachePruneInterval"
            case parquetMemCachePrunePercentage = "parquetMemCachePrunePercentage"
            case parquetMemCacheQueryPathDuration = "parquetMemCacheQueryPathDuration"
            case parquetMemCacheSize = "parquetMemCacheSize"
            case preemptiveCacheAge = "preemptiveCacheAge"
            case queryFileLimit = "queryFileLimit"
            case queryLogSize = "queryLogSize"
            case retentionCheckInterval = "retentionCheckInterval"
            case snapshottedWalFilesToKeep = "snapshottedWalFilesToKeep"
            case tableIndexCacheConcurrencyLimit = "tableIndexCacheConcurrencyLimit"
            case tableIndexCacheMaxEntries = "tableIndexCacheMaxEntries"
            case walMaxWriteBufferSize = "walMaxWriteBufferSize"
            case walReplayConcurrencyLimit = "walReplayConcurrencyLimit"
            case walReplayFailOnError = "walReplayFailOnError"
            case walSnapshotSize = "walSnapshotSize"
        }
    }

    public struct InfluxDBv3EnterpriseParameters: AWSEncodableShape & AWSDecodableShape {
        /// Defines how often the catalog synchronizes across cluster nodes. Default: 10s
        public let catalogSyncInterval: Duration?
        /// Specifies how often the compactor checks for new compaction work to perform. Default: 10s
        public let compactionCheckInterval: Duration?
        /// Specifies the amount of time that the compactor waits after finishing a compaction run to delete files marked as needing deletion during that compaction run. Default: 10m
        public let compactionCleanupWait: Duration?
        /// Specifies the duration of the first level of compaction (gen2). Later levels of compaction are multiples of this duration. This value should be equal to or greater than the gen1 duration. Default: 20m
        public let compactionGen2Duration: Duration?
        /// Sets the maximum number of files included in any compaction plan. Default: 500
        public let compactionMaxNumFilesPerPlan: Int?
        /// Specifies a comma-separated list of multiples defining the duration of each level of compaction. The number of elements in the list determines the number of compaction levels. The first element specifies the duration of the first level (gen3); subsequent levels are multiples of the previous level. Default: 3,4,6,5
        public let compactionMultipliers: String?
        /// Specifies the soft limit for the number of rows per file that the compactor writes. The compactor may write more rows than this limit. Default: 1000000
        public let compactionRowLimit: Int?
        /// Provides custom configuration to DataFusion as a comma-separated list of key:value pairs.
        public let dataFusionConfig: String?
        /// When multiple parquet files are required in a sorted way (deduplication for example), specifies the maximum fanout. Default: 1000
        public let dataFusionMaxParquetFanout: Int?
        /// Sets the maximum number of DataFusion runtime threads to use.
        public let dataFusionNumThreads: Int?
        /// Disables the LIFO slot of the DataFusion runtime.
        public let dataFusionRuntimeDisableLifoSlot: Bool?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion tokio runtime polls for external eventsfor example: timers, I/O.
        public let dataFusionRuntimeEventInterval: Int?
        /// Sets the number of scheduler ticks after which the scheduler of the DataFusion runtime polls the global task queue.
        public let dataFusionRuntimeGlobalQueueInterval: Int?
        /// Specifies the limit for additional threads spawned by the DataFusion runtime.
        public let dataFusionRuntimeMaxBlockingThreads: Int?
        /// Configures the maximum number of events processed per tick by the tokio DataFusion runtime.
        public let dataFusionRuntimeMaxIoEventsPerTick: Int?
        /// Sets a custom timeout for a thread in the blocking pool of the tokio DataFusion runtime.
        public let dataFusionRuntimeThreadKeepAlive: Duration?
        /// Sets the thread priority for tokio DataFusion runtime workers. Default: 10
        public let dataFusionRuntimeThreadPriority: Int?
        /// Specifies the DataFusion tokio runtime type. Default: multi-thread
        public let dataFusionRuntimeType: DataFusionRuntimeType?
        /// Uses a cached parquet loader when reading parquet files from the object store.
        public let dataFusionUseCachedParquetLoader: Bool?
        /// Specifies if the compactor instance should be a standalone instance or not.
        public let dedicatedCompactor: Bool
        /// Specifies the grace period before permanently deleting data. Default: 24h
        public let deleteGracePeriod: Duration?
        /// Disables the in-memory Parquet cache. By default, the cache is enabled.
        public let disableParquetMemCache: Bool?
        /// Specifies the interval to evict expired entries from the distinct value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public let distinctCacheEvictionInterval: Duration?
        /// Disables populating the distinct value cache from historical data. If disabled, the cache is still populated with data from the write-ahead log (WAL).
        public let distinctValueCacheDisableFromHistory: Bool?
        /// Specifies the size of memory pool used during query execution. Can be given as absolute value in bytes or as a percentage of the total available memoryfor example: 8000000000 or 10%. Default: 20%
        public let execMemPoolBytes: PercentOrAbsoluteLong?
        /// Specifies the threshold for the internal memory buffer. Supports either a percentage (portion of available memory) or absolute value in MBfor example: 70% or 100 Default: 70%
        public let forceSnapshotMemThreshold: PercentOrAbsoluteLong?
        /// Specifies the duration that Parquet files are arranged into. Data timestamps land each row into a file of this duration. Supported durations are 1m, 5m, and 10m. These files are known as generation 1 files, which the compactor can merge into larger generations. Default: 10m
        public let gen1Duration: Duration?
        /// Specifies how far back to look when creating generation 1 Parquet files. Default: 24h
        public let gen1LookbackDuration: Duration?
        /// Sets the default duration for hard deletion of data. Default: 90d
        public let hardDeleteDefaultDuration: Duration?
        /// Specifies number of instances in the DbCluster which can both ingest and query.
        public let ingestQueryInstances: Int
        /// Specifies the interval to evict expired entries from the Last-N-Value cache, expressed as a human-readable durationfor example: 20s, 1m, 1h. Default: 10s
        public let lastCacheEvictionInterval: Duration?
        /// Disables populating the last-N-value cache from historical data. If disabled, the cache is still populated with data from the write-ahead log (WAL).
        public let lastValueCacheDisableFromHistory: Bool?
        /// Sets the filter directive for logs.
        public let logFilter: String?
        /// Defines the message format for logs. Default: full
        public let logFormat: LogFormats?
        /// Specifies the maximum size of HTTP requests. Default: 10485760
        public let maxHttpRequestSize: Int64?
        /// Sets the interval to check if the in-memory Parquet cache needs to be pruned. Default: 1s
        public let parquetMemCachePruneInterval: Duration?
        /// Specifies the percentage of entries to prune during a prune operation on the in-memory Parquet cache. Default: 0.1
        public let parquetMemCachePrunePercentage: Float?
        /// Specifies the time window for caching recent Parquet files in memory. Default: 5h
        public let parquetMemCacheQueryPathDuration: Duration?
        /// Specifies the size of the in-memory Parquet cache in megabytes or percentage of total available memory. Default: 20%
        public let parquetMemCacheSize: PercentOrAbsoluteLong?
        /// Specifies the interval to prefetch into the Parquet cache during compaction. Default: 3d
        public let preemptiveCacheAge: Duration?
        /// Limits the number of Parquet files a query can access. If a query attempts to read more than this limit, InfluxDB 3 returns an error. Default: 432
        public let queryFileLimit: Int?
        /// Defines the size of the query log. Up to this many queries remain in the log before older queries are evicted to make room for new ones. Default: 1000
        public let queryLogSize: Int?
        /// Specifies number of instances in the DbCluster which can only query.
        public let queryOnlyInstances: Int
        /// Specifies the interval at which data replication occurs between cluster nodes. Default: 250ms
        public let replicationInterval: Duration?
        /// The interval at which retention policies are checked and enforced. Enter as a human-readable timefor example: 30m or 1h. Default: 30m
        public let retentionCheckInterval: Duration?
        /// Specifies the number of snapshotted WAL files to retain in the object store. Flushing the WAL files does not clear the WAL files immediately; they are deleted when the number of snapshotted WAL files exceeds this number. Default: 300
        public let snapshottedWalFilesToKeep: Int?
        /// Limits the concurrency level for table index cache operations. Default: 8
        public let tableIndexCacheConcurrencyLimit: Int?
        /// Specifies the maximum number of entries in the table index cache. Default: 1000
        public let tableIndexCacheMaxEntries: Int?
        /// Specifies the maximum number of write requests that can be buffered before a flush must be executed and succeed. Default: 100000
        public let walMaxWriteBufferSize: Int?
        /// Concurrency limit during WAL replay. Setting this number too high can lead to OOM. The default is dynamically determined. Default: max(num_cpus, 10)
        public let walReplayConcurrencyLimit: Int?
        /// Determines whether WAL replay should fail when encountering errors. Default: false
        public let walReplayFailOnError: Bool?
        /// Defines the number of WAL files to attempt to remove in a snapshot. This, multiplied by the interval, determines how often snapshots are taken. Default: 600
        public let walSnapshotSize: Int?

        @inlinable
        public init(catalogSyncInterval: Duration? = nil, compactionCheckInterval: Duration? = nil, compactionCleanupWait: Duration? = nil, compactionGen2Duration: Duration? = nil, compactionMaxNumFilesPerPlan: Int? = nil, compactionMultipliers: String? = nil, compactionRowLimit: Int? = nil, dataFusionConfig: String? = nil, dataFusionMaxParquetFanout: Int? = nil, dataFusionNumThreads: Int? = nil, dataFusionRuntimeDisableLifoSlot: Bool? = nil, dataFusionRuntimeEventInterval: Int? = nil, dataFusionRuntimeGlobalQueueInterval: Int? = nil, dataFusionRuntimeMaxBlockingThreads: Int? = nil, dataFusionRuntimeMaxIoEventsPerTick: Int? = nil, dataFusionRuntimeThreadKeepAlive: Duration? = nil, dataFusionRuntimeThreadPriority: Int? = nil, dataFusionRuntimeType: DataFusionRuntimeType? = nil, dataFusionUseCachedParquetLoader: Bool? = nil, dedicatedCompactor: Bool, deleteGracePeriod: Duration? = nil, disableParquetMemCache: Bool? = nil, distinctCacheEvictionInterval: Duration? = nil, distinctValueCacheDisableFromHistory: Bool? = nil, execMemPoolBytes: PercentOrAbsoluteLong? = nil, forceSnapshotMemThreshold: PercentOrAbsoluteLong? = nil, gen1Duration: Duration? = nil, gen1LookbackDuration: Duration? = nil, hardDeleteDefaultDuration: Duration? = nil, ingestQueryInstances: Int, lastCacheEvictionInterval: Duration? = nil, lastValueCacheDisableFromHistory: Bool? = nil, logFilter: String? = nil, logFormat: LogFormats? = nil, maxHttpRequestSize: Int64? = nil, parquetMemCachePruneInterval: Duration? = nil, parquetMemCachePrunePercentage: Float? = nil, parquetMemCacheQueryPathDuration: Duration? = nil, parquetMemCacheSize: PercentOrAbsoluteLong? = nil, preemptiveCacheAge: Duration? = nil, queryFileLimit: Int? = nil, queryLogSize: Int? = nil, queryOnlyInstances: Int, replicationInterval: Duration? = nil, retentionCheckInterval: Duration? = nil, snapshottedWalFilesToKeep: Int? = nil, tableIndexCacheConcurrencyLimit: Int? = nil, tableIndexCacheMaxEntries: Int? = nil, walMaxWriteBufferSize: Int? = nil, walReplayConcurrencyLimit: Int? = nil, walReplayFailOnError: Bool? = nil, walSnapshotSize: Int? = nil) {
            self.catalogSyncInterval = catalogSyncInterval
            self.compactionCheckInterval = compactionCheckInterval
            self.compactionCleanupWait = compactionCleanupWait
            self.compactionGen2Duration = compactionGen2Duration
            self.compactionMaxNumFilesPerPlan = compactionMaxNumFilesPerPlan
            self.compactionMultipliers = compactionMultipliers
            self.compactionRowLimit = compactionRowLimit
            self.dataFusionConfig = dataFusionConfig
            self.dataFusionMaxParquetFanout = dataFusionMaxParquetFanout
            self.dataFusionNumThreads = dataFusionNumThreads
            self.dataFusionRuntimeDisableLifoSlot = dataFusionRuntimeDisableLifoSlot
            self.dataFusionRuntimeEventInterval = dataFusionRuntimeEventInterval
            self.dataFusionRuntimeGlobalQueueInterval = dataFusionRuntimeGlobalQueueInterval
            self.dataFusionRuntimeMaxBlockingThreads = dataFusionRuntimeMaxBlockingThreads
            self.dataFusionRuntimeMaxIoEventsPerTick = dataFusionRuntimeMaxIoEventsPerTick
            self.dataFusionRuntimeThreadKeepAlive = dataFusionRuntimeThreadKeepAlive
            self.dataFusionRuntimeThreadPriority = dataFusionRuntimeThreadPriority
            self.dataFusionRuntimeType = dataFusionRuntimeType
            self.dataFusionUseCachedParquetLoader = dataFusionUseCachedParquetLoader
            self.dedicatedCompactor = dedicatedCompactor
            self.deleteGracePeriod = deleteGracePeriod
            self.disableParquetMemCache = disableParquetMemCache
            self.distinctCacheEvictionInterval = distinctCacheEvictionInterval
            self.distinctValueCacheDisableFromHistory = distinctValueCacheDisableFromHistory
            self.execMemPoolBytes = execMemPoolBytes
            self.forceSnapshotMemThreshold = forceSnapshotMemThreshold
            self.gen1Duration = gen1Duration
            self.gen1LookbackDuration = gen1LookbackDuration
            self.hardDeleteDefaultDuration = hardDeleteDefaultDuration
            self.ingestQueryInstances = ingestQueryInstances
            self.lastCacheEvictionInterval = lastCacheEvictionInterval
            self.lastValueCacheDisableFromHistory = lastValueCacheDisableFromHistory
            self.logFilter = logFilter
            self.logFormat = logFormat
            self.maxHttpRequestSize = maxHttpRequestSize
            self.parquetMemCachePruneInterval = parquetMemCachePruneInterval
            self.parquetMemCachePrunePercentage = parquetMemCachePrunePercentage
            self.parquetMemCacheQueryPathDuration = parquetMemCacheQueryPathDuration
            self.parquetMemCacheSize = parquetMemCacheSize
            self.preemptiveCacheAge = preemptiveCacheAge
            self.queryFileLimit = queryFileLimit
            self.queryLogSize = queryLogSize
            self.queryOnlyInstances = queryOnlyInstances
            self.replicationInterval = replicationInterval
            self.retentionCheckInterval = retentionCheckInterval
            self.snapshottedWalFilesToKeep = snapshottedWalFilesToKeep
            self.tableIndexCacheConcurrencyLimit = tableIndexCacheConcurrencyLimit
            self.tableIndexCacheMaxEntries = tableIndexCacheMaxEntries
            self.walMaxWriteBufferSize = walMaxWriteBufferSize
            self.walReplayConcurrencyLimit = walReplayConcurrencyLimit
            self.walReplayFailOnError = walReplayFailOnError
            self.walSnapshotSize = walSnapshotSize
        }

        private enum CodingKeys: String, CodingKey {
            case catalogSyncInterval = "catalogSyncInterval"
            case compactionCheckInterval = "compactionCheckInterval"
            case compactionCleanupWait = "compactionCleanupWait"
            case compactionGen2Duration = "compactionGen2Duration"
            case compactionMaxNumFilesPerPlan = "compactionMaxNumFilesPerPlan"
            case compactionMultipliers = "compactionMultipliers"
            case compactionRowLimit = "compactionRowLimit"
            case dataFusionConfig = "dataFusionConfig"
            case dataFusionMaxParquetFanout = "dataFusionMaxParquetFanout"
            case dataFusionNumThreads = "dataFusionNumThreads"
            case dataFusionRuntimeDisableLifoSlot = "dataFusionRuntimeDisableLifoSlot"
            case dataFusionRuntimeEventInterval = "dataFusionRuntimeEventInterval"
            case dataFusionRuntimeGlobalQueueInterval = "dataFusionRuntimeGlobalQueueInterval"
            case dataFusionRuntimeMaxBlockingThreads = "dataFusionRuntimeMaxBlockingThreads"
            case dataFusionRuntimeMaxIoEventsPerTick = "dataFusionRuntimeMaxIoEventsPerTick"
            case dataFusionRuntimeThreadKeepAlive = "dataFusionRuntimeThreadKeepAlive"
            case dataFusionRuntimeThreadPriority = "dataFusionRuntimeThreadPriority"
            case dataFusionRuntimeType = "dataFusionRuntimeType"
            case dataFusionUseCachedParquetLoader = "dataFusionUseCachedParquetLoader"
            case dedicatedCompactor = "dedicatedCompactor"
            case deleteGracePeriod = "deleteGracePeriod"
            case disableParquetMemCache = "disableParquetMemCache"
            case distinctCacheEvictionInterval = "distinctCacheEvictionInterval"
            case distinctValueCacheDisableFromHistory = "distinctValueCacheDisableFromHistory"
            case execMemPoolBytes = "execMemPoolBytes"
            case forceSnapshotMemThreshold = "forceSnapshotMemThreshold"
            case gen1Duration = "gen1Duration"
            case gen1LookbackDuration = "gen1LookbackDuration"
            case hardDeleteDefaultDuration = "hardDeleteDefaultDuration"
            case ingestQueryInstances = "ingestQueryInstances"
            case lastCacheEvictionInterval = "lastCacheEvictionInterval"
            case lastValueCacheDisableFromHistory = "lastValueCacheDisableFromHistory"
            case logFilter = "logFilter"
            case logFormat = "logFormat"
            case maxHttpRequestSize = "maxHttpRequestSize"
            case parquetMemCachePruneInterval = "parquetMemCachePruneInterval"
            case parquetMemCachePrunePercentage = "parquetMemCachePrunePercentage"
            case parquetMemCacheQueryPathDuration = "parquetMemCacheQueryPathDuration"
            case parquetMemCacheSize = "parquetMemCacheSize"
            case preemptiveCacheAge = "preemptiveCacheAge"
            case queryFileLimit = "queryFileLimit"
            case queryLogSize = "queryLogSize"
            case queryOnlyInstances = "queryOnlyInstances"
            case replicationInterval = "replicationInterval"
            case retentionCheckInterval = "retentionCheckInterval"
            case snapshottedWalFilesToKeep = "snapshottedWalFilesToKeep"
            case tableIndexCacheConcurrencyLimit = "tableIndexCacheConcurrencyLimit"
            case tableIndexCacheMaxEntries = "tableIndexCacheMaxEntries"
            case walMaxWriteBufferSize = "walMaxWriteBufferSize"
            case walReplayConcurrencyLimit = "walReplayConcurrencyLimit"
            case walReplayFailOnError = "walReplayFailOnError"
            case walSnapshotSize = "walSnapshotSize"
        }
    }

    public struct ListDbClustersInput: AWSEncodableShape {
        /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a nextToken is provided in the output. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
        public let maxResults: Int?
        /// The pagination token. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
        public let nextToken: String?

        @inlinable
        public init(maxResults: Int? = nil, nextToken: String? = nil) {
            self.maxResults = maxResults
            self.nextToken = nextToken
        }

        public func validate(name: String) throws {
            try self.validate(self.maxResults, name: "maxResults", parent: name, max: 100)
            try self.validate(self.maxResults, name: "maxResults", parent: name, min: 1)
            try self.validate(self.nextToken, name: "nextToken", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case maxResults = "maxResults"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbClustersOutput: AWSDecodableShape {
        /// A list of Timestream for InfluxDB cluster summaries.
        public let items: [DbClusterSummary]
        /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
        public let nextToken: String?

        @inlinable
        public init(items: [DbClusterSummary], nextToken: String? = nil) {
            self.items = items
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case items = "items"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbInstancesForClusterInput: AWSEncodableShape {
        /// Service-generated unique identifier of the DB cluster.
        public let dbClusterId: String
        /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a nextToken is provided in the output. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
        public let maxResults: Int?
        /// The pagination token. To resume pagination, provide the nextToken value as an argument of a subsequent API invocation.
        public let nextToken: String?

        @inlinable
        public init(dbClusterId: String, maxResults: Int? = nil, nextToken: String? = nil) {
            self.dbClusterId = dbClusterId
            self.maxResults = maxResults
            self.nextToken = nextToken
        }

        public func validate(name: String) throws {
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, max: 64)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, min: 3)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.maxResults, name: "maxResults", parent: name, max: 100)
            try self.validate(self.maxResults, name: "maxResults", parent: name, min: 1)
            try self.validate(self.nextToken, name: "nextToken", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
            case maxResults = "maxResults"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbInstancesForClusterOutput: AWSDecodableShape {
        /// A list of Timestream for InfluxDB instance summaries belonging to the cluster.
        public let items: [DbInstanceForClusterSummary]
        /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
        public let nextToken: String?

        @inlinable
        public init(items: [DbInstanceForClusterSummary], nextToken: String? = nil) {
            self.items = items
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case items = "items"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbInstancesInput: AWSEncodableShape {
        /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a NextToken is provided in the output. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
        public let maxResults: Int?
        /// The pagination token. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
        public let nextToken: String?

        @inlinable
        public init(maxResults: Int? = nil, nextToken: String? = nil) {
            self.maxResults = maxResults
            self.nextToken = nextToken
        }

        public func validate(name: String) throws {
            try self.validate(self.maxResults, name: "maxResults", parent: name, max: 100)
            try self.validate(self.maxResults, name: "maxResults", parent: name, min: 1)
            try self.validate(self.nextToken, name: "nextToken", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case maxResults = "maxResults"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbInstancesOutput: AWSDecodableShape {
        /// A list of Timestream for InfluxDB DB instance summaries.
        public let items: [DbInstanceSummary]
        /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
        public let nextToken: String?

        @inlinable
        public init(items: [DbInstanceSummary], nextToken: String? = nil) {
            self.items = items
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case items = "items"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbParameterGroupsInput: AWSEncodableShape {
        /// The maximum number of items to return in the output. If the total number of items available is more than the value specified, a NextToken is provided in the output. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
        public let maxResults: Int?
        /// The pagination token. To resume pagination, provide the NextToken value as argument of a subsequent API invocation.
        public let nextToken: String?

        @inlinable
        public init(maxResults: Int? = nil, nextToken: String? = nil) {
            self.maxResults = maxResults
            self.nextToken = nextToken
        }

        public func validate(name: String) throws {
            try self.validate(self.maxResults, name: "maxResults", parent: name, max: 100)
            try self.validate(self.maxResults, name: "maxResults", parent: name, min: 1)
            try self.validate(self.nextToken, name: "nextToken", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case maxResults = "maxResults"
            case nextToken = "nextToken"
        }
    }

    public struct ListDbParameterGroupsOutput: AWSDecodableShape {
        /// A list of Timestream for InfluxDB DB parameter group summaries.
        public let items: [DbParameterGroupSummary]
        /// Token from a previous call of the operation. When this value is provided, the service returns results from where the previous response left off.
        public let nextToken: String?

        @inlinable
        public init(items: [DbParameterGroupSummary], nextToken: String? = nil) {
            self.items = items
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case items = "items"
            case nextToken = "nextToken"
        }
    }

    public struct ListTagsForResourceRequest: AWSEncodableShape {
        /// The Amazon Resource Name (ARN) of the tagged resource.
        public let resourceArn: String

        @inlinable
        public init(resourceArn: String) {
            self.resourceArn = resourceArn
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, max: 1011)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, min: 1)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, pattern: "^arn:aws[a-z\\-]*:timestream\\-influxdb:[a-z0-9\\-]+:[0-9]{12}:(db\\-instance|db\\-cluster|db\\-parameter\\-group)/[a-zA-Z0-9]{3,64}$")
        }

        private enum CodingKeys: String, CodingKey {
            case resourceArn = "resourceArn"
        }
    }

    public struct ListTagsForResourceResponse: AWSDecodableShape {
        /// A list of tags used to categorize and track resources.
        public let tags: [String: String]?

        @inlinable
        public init(tags: [String: String]? = nil) {
            self.tags = tags
        }

        private enum CodingKeys: String, CodingKey {
            case tags = "tags"
        }
    }

    public struct LogDeliveryConfiguration: AWSEncodableShape & AWSDecodableShape {
        /// Configuration for S3 bucket log delivery.
        public let s3Configuration: S3Configuration

        @inlinable
        public init(s3Configuration: S3Configuration) {
            self.s3Configuration = s3Configuration
        }

        private enum CodingKeys: String, CodingKey {
            case s3Configuration = "s3Configuration"
        }
    }

    public struct RebootDbClusterInput: AWSEncodableShape {
        /// Service-generated unique identifier of the DB cluster to reboot.
        public let dbClusterId: String
        /// A list of service-generated unique DB Instance Ids belonging to the DB Cluster to reboot.
        public let instanceIds: [String]?

        @inlinable
        public init(dbClusterId: String, instanceIds: [String]? = nil) {
            self.dbClusterId = dbClusterId
            self.instanceIds = instanceIds
        }

        public func validate(name: String) throws {
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, max: 64)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, min: 3)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.instanceIds?.forEach {
                try validate($0, name: "instanceIds[]", parent: name, max: 64)
                try validate($0, name: "instanceIds[]", parent: name, min: 3)
                try validate($0, name: "instanceIds[]", parent: name, pattern: "^[a-zA-Z0-9]+$")
            }
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
            case instanceIds = "instanceIds"
        }
    }

    public struct RebootDbClusterOutput: AWSDecodableShape {
        /// The status of the DB Cluster.
        public let dbClusterStatus: ClusterStatus?

        @inlinable
        public init(dbClusterStatus: ClusterStatus? = nil) {
            self.dbClusterStatus = dbClusterStatus
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterStatus = "dbClusterStatus"
        }
    }

    public struct RebootDbInstanceInput: AWSEncodableShape {
        /// The id of the DB instance to reboot.
        public let identifier: String

        @inlinable
        public init(identifier: String) {
            self.identifier = identifier
        }

        public func validate(name: String) throws {
            try self.validate(self.identifier, name: "identifier", parent: name, max: 64)
            try self.validate(self.identifier, name: "identifier", parent: name, min: 3)
            try self.validate(self.identifier, name: "identifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
        }

        private enum CodingKeys: String, CodingKey {
            case identifier = "identifier"
        }
    }

    public struct RebootDbInstanceOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Availability Zone in which the DB instance resides.
        public let availabilityZone: String?
        /// Specifies the DbCluster to which this DbInstance belongs to.
        public let dbClusterId: String?
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group assigned to your DB instance.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Specifies the DbInstance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DbInstance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The customer-supplied name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// Indicates if the DB instance has a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
        public let secondaryAvailabilityZone: String?
        /// The status of the DB instance.
        public let status: Status?
        /// A list of VPC security group IDs associated with the DB instance.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB instance.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, availabilityZone: String? = nil, dbClusterId: String? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, influxAuthParametersSecretArn: String? = nil, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, secondaryAvailabilityZone: String? = nil, status: Status? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.availabilityZone = availabilityZone
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.secondaryAvailabilityZone = secondaryAvailabilityZone
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case availabilityZone = "availabilityZone"
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case secondaryAvailabilityZone = "secondaryAvailabilityZone"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct ResourceNotFoundException: AWSErrorShape {
        public let message: String
        /// The identifier for the Timestream for InfluxDB resource associated with the request.
        public let resourceId: String
        /// The type of Timestream for InfluxDB resource associated with the request.
        public let resourceType: String

        @inlinable
        public init(message: String, resourceId: String, resourceType: String) {
            self.message = message
            self.resourceId = resourceId
            self.resourceType = resourceType
        }

        private enum CodingKeys: String, CodingKey {
            case message = "message"
            case resourceId = "resourceId"
            case resourceType = "resourceType"
        }
    }

    public struct S3Configuration: AWSEncodableShape & AWSDecodableShape {
        /// The name of the S3 bucket to deliver logs to.
        public let bucketName: String
        /// Indicates whether log delivery to the S3 bucket is enabled.
        public let enabled: Bool

        @inlinable
        public init(bucketName: String, enabled: Bool) {
            self.bucketName = bucketName
            self.enabled = enabled
        }

        private enum CodingKeys: String, CodingKey {
            case bucketName = "bucketName"
            case enabled = "enabled"
        }
    }

    public struct TagResourceRequest: AWSEncodableShape {
        /// The Amazon Resource Name (ARN) of the tagged resource.
        public let resourceArn: String
        /// A list of tags used to categorize and track resources.
        public let tags: [String: String]

        @inlinable
        public init(resourceArn: String, tags: [String: String]) {
            self.resourceArn = resourceArn
            self.tags = tags
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, max: 1011)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, min: 1)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, pattern: "^arn:aws[a-z\\-]*:timestream\\-influxdb:[a-z0-9\\-]+:[0-9]{12}:(db\\-instance|db\\-cluster|db\\-parameter\\-group)/[a-zA-Z0-9]{3,64}$")
            try self.tags.forEach {
                try validate($0.key, name: "tags.key", parent: name, max: 128)
                try validate($0.key, name: "tags.key", parent: name, min: 1)
                try validate($0.value, name: "tags[\"\($0.key)\"]", parent: name, max: 256)
            }
            try self.validate(self.tags, name: "tags", parent: name, max: 200)
            try self.validate(self.tags, name: "tags", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case resourceArn = "resourceArn"
            case tags = "tags"
        }
    }

    public struct ThrottlingException: AWSErrorShape {
        public let message: String
        /// The number of seconds the caller should wait before retrying.
        public let retryAfterSeconds: Int?

        @inlinable
        public init(message: String, retryAfterSeconds: Int? = nil) {
            self.message = message
            self.retryAfterSeconds = retryAfterSeconds
        }

        public init(from decoder: Decoder) throws {
            let response = decoder.userInfo[.awsResponse]! as! ResponseDecodingContainer
            let container = try decoder.container(keyedBy: CodingKeys.self)
            self.message = try container.decode(String.self, forKey: .message)
            self.retryAfterSeconds = try response.decodeHeaderIfPresent(Int.self, key: "Retry-After")
        }

        private enum CodingKeys: String, CodingKey {
            case message = "message"
        }
    }

    public struct UntagResourceRequest: AWSEncodableShape {
        /// The Amazon Resource Name (ARN) of the tagged resource.
        public let resourceArn: String
        /// The keys used to identify the tags.
        public let tagKeys: [String]

        @inlinable
        public init(resourceArn: String, tagKeys: [String]) {
            self.resourceArn = resourceArn
            self.tagKeys = tagKeys
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            var container = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.resourceArn, key: "resourceArn")
            try container.encode(self.tagKeys, forKey: .tagKeys)
        }

        public func validate(name: String) throws {
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, max: 1011)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, min: 1)
            try self.validate(self.resourceArn, name: "resourceArn", parent: name, pattern: "^arn:aws[a-z\\-]*:timestream\\-influxdb:[a-z0-9\\-]+:[0-9]{12}:(db\\-instance|db\\-cluster|db\\-parameter\\-group)/[a-zA-Z0-9]{3,64}$")
            try self.tagKeys.forEach {
                try validate($0, name: "tagKeys[]", parent: name, max: 128)
                try validate($0, name: "tagKeys[]", parent: name, min: 1)
            }
            try self.validate(self.tagKeys, name: "tagKeys", parent: name, max: 200)
            try self.validate(self.tagKeys, name: "tagKeys", parent: name, min: 1)
        }

        private enum CodingKeys: String, CodingKey {
            case tagKeys = "tagKeys"
        }
    }

    public struct UpdateDbClusterInput: AWSEncodableShape {
        /// Service-generated unique identifier of the DB cluster to update.
        public let dbClusterId: String
        /// Update the DB cluster to use the specified DB instance Type.
        public let dbInstanceType: DbInstanceType?
        /// Update the DB cluster to use the specified DB parameter group.
        public let dbParameterGroupIdentifier: String?
        /// Update the DB cluster's failover behavior.
        public let failoverMode: FailoverMode?
        /// The log delivery configuration to apply to the DB cluster.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// Update the DB cluster to use the specified port.
        public let port: Int?

        @inlinable
        public init(dbClusterId: String, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, failoverMode: FailoverMode? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, port: Int? = nil) {
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.failoverMode = failoverMode
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.port = port
        }

        public func validate(name: String) throws {
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, max: 64)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, min: 3)
            try self.validate(self.dbClusterId, name: "dbClusterId", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, max: 64)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, min: 3)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.port, name: "port", parent: name, max: 65535)
            try self.validate(self.port, name: "port", parent: name, min: 1024)
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case failoverMode = "failoverMode"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case port = "port"
        }
    }

    public struct UpdateDbClusterOutput: AWSDecodableShape {
        /// The status of the DB cluster.
        public let dbClusterStatus: ClusterStatus?

        @inlinable
        public init(dbClusterStatus: ClusterStatus? = nil) {
            self.dbClusterStatus = dbClusterStatus
        }

        private enum CodingKeys: String, CodingKey {
            case dbClusterStatus = "dbClusterStatus"
        }
    }

    public struct UpdateDbInstanceInput: AWSEncodableShape {
        /// The amount of storage to allocate for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Timestream for InfluxDB DB instance type to run InfluxDB on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the DB instance will be deployed as a standalone instance or with a Multi-AZ standby for high availability.
        public let deploymentType: DeploymentType?
        /// The id of the DB instance.
        public let identifier: String
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// The port number on which InfluxDB accepts connections. If you change the Port value, your database restarts immediately. Valid Values: 1024-65535 Default: 8086 Constraints: The value can't be 2375-2376, 7788-7799, 8090, or 51678-51680
        public let port: Int?

        @inlinable
        public init(allocatedStorage: Int? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, identifier: String, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, port: Int? = nil) {
            self.allocatedStorage = allocatedStorage
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.identifier = identifier
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.port = port
        }

        public func validate(name: String) throws {
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, max: 15360)
            try self.validate(self.allocatedStorage, name: "allocatedStorage", parent: name, min: 20)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, max: 64)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, min: 3)
            try self.validate(self.dbParameterGroupIdentifier, name: "dbParameterGroupIdentifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.identifier, name: "identifier", parent: name, max: 64)
            try self.validate(self.identifier, name: "identifier", parent: name, min: 3)
            try self.validate(self.identifier, name: "identifier", parent: name, pattern: "^[a-zA-Z0-9]+$")
            try self.validate(self.port, name: "port", parent: name, max: 65535)
            try self.validate(self.port, name: "port", parent: name, min: 1024)
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case identifier = "identifier"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case port = "port"
        }
    }

    public struct UpdateDbInstanceOutput: AWSDecodableShape {
        /// The amount of storage allocated for your DB storage type (in gibibytes).
        public let allocatedStorage: Int?
        /// The Amazon Resource Name (ARN) of the DB instance.
        public let arn: String
        /// The Availability Zone in which the DB instance resides.
        public let availabilityZone: String?
        /// Specifies the DbCluster to which this DbInstance belongs to.
        public let dbClusterId: String?
        /// The Timestream for InfluxDB instance type that InfluxDB runs on.
        public let dbInstanceType: DbInstanceType?
        /// The id of the DB parameter group assigned to your DB instance.
        public let dbParameterGroupIdentifier: String?
        /// The Timestream for InfluxDB DB storage type that InfluxDB stores data on.
        public let dbStorageType: DbStorageType?
        /// Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.
        public let deploymentType: DeploymentType?
        /// The endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
        public let endpoint: String?
        /// A service-generated unique identifier.
        public let id: String
        /// The Amazon Resource Name (ARN) of the Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password.
        public let influxAuthParametersSecretArn: String?
        /// Specifies the DbInstance's role in the cluster.
        public let instanceMode: InstanceMode?
        /// Specifies the DbInstance's roles in the cluster.
        public let instanceModes: [InstanceMode]?
        /// Configuration for sending InfluxDB engine logs to send to specified S3 bucket.
        public let logDeliveryConfiguration: LogDeliveryConfiguration?
        /// This customer-supplied name uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands.
        public let name: String
        /// Specifies whether the networkType of the Timestream for InfluxDB instance is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
        public let networkType: NetworkType?
        /// The port number on which InfluxDB accepts connections.
        public let port: Int?
        /// Indicates if the DB instance has a public IP to facilitate access.
        public let publiclyAccessible: Bool?
        /// The Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
        public let secondaryAvailabilityZone: String?
        /// The status of the DB instance.
        public let status: Status?
        /// A list of VPC security group IDs associated with the DB instance.
        public let vpcSecurityGroupIds: [String]?
        /// A list of VPC subnet IDs associated with the DB instance.
        public let vpcSubnetIds: [String]

        @inlinable
        public init(allocatedStorage: Int? = nil, arn: String, availabilityZone: String? = nil, dbClusterId: String? = nil, dbInstanceType: DbInstanceType? = nil, dbParameterGroupIdentifier: String? = nil, dbStorageType: DbStorageType? = nil, deploymentType: DeploymentType? = nil, endpoint: String? = nil, id: String, influxAuthParametersSecretArn: String? = nil, instanceMode: InstanceMode? = nil, instanceModes: [InstanceMode]? = nil, logDeliveryConfiguration: LogDeliveryConfiguration? = nil, name: String, networkType: NetworkType? = nil, port: Int? = nil, publiclyAccessible: Bool? = nil, secondaryAvailabilityZone: String? = nil, status: Status? = nil, vpcSecurityGroupIds: [String]? = nil, vpcSubnetIds: [String]) {
            self.allocatedStorage = allocatedStorage
            self.arn = arn
            self.availabilityZone = availabilityZone
            self.dbClusterId = dbClusterId
            self.dbInstanceType = dbInstanceType
            self.dbParameterGroupIdentifier = dbParameterGroupIdentifier
            self.dbStorageType = dbStorageType
            self.deploymentType = deploymentType
            self.endpoint = endpoint
            self.id = id
            self.influxAuthParametersSecretArn = influxAuthParametersSecretArn
            self.instanceMode = instanceMode
            self.instanceModes = instanceModes
            self.logDeliveryConfiguration = logDeliveryConfiguration
            self.name = name
            self.networkType = networkType
            self.port = port
            self.publiclyAccessible = publiclyAccessible
            self.secondaryAvailabilityZone = secondaryAvailabilityZone
            self.status = status
            self.vpcSecurityGroupIds = vpcSecurityGroupIds
            self.vpcSubnetIds = vpcSubnetIds
        }

        private enum CodingKeys: String, CodingKey {
            case allocatedStorage = "allocatedStorage"
            case arn = "arn"
            case availabilityZone = "availabilityZone"
            case dbClusterId = "dbClusterId"
            case dbInstanceType = "dbInstanceType"
            case dbParameterGroupIdentifier = "dbParameterGroupIdentifier"
            case dbStorageType = "dbStorageType"
            case deploymentType = "deploymentType"
            case endpoint = "endpoint"
            case id = "id"
            case influxAuthParametersSecretArn = "influxAuthParametersSecretArn"
            case instanceMode = "instanceMode"
            case instanceModes = "instanceModes"
            case logDeliveryConfiguration = "logDeliveryConfiguration"
            case name = "name"
            case networkType = "networkType"
            case port = "port"
            case publiclyAccessible = "publiclyAccessible"
            case secondaryAvailabilityZone = "secondaryAvailabilityZone"
            case status = "status"
            case vpcSecurityGroupIds = "vpcSecurityGroupIds"
            case vpcSubnetIds = "vpcSubnetIds"
        }
    }

    public struct ValidationException: AWSErrorShape {
        public let message: String
        /// The reason that validation failed.
        public let reason: ValidationExceptionReason

        @inlinable
        public init(message: String, reason: ValidationExceptionReason) {
            self.message = message
            self.reason = reason
        }

        private enum CodingKeys: String, CodingKey {
            case message = "message"
            case reason = "reason"
        }
    }
}

// MARK: - Errors

/// Error enum for TimestreamInfluxDB
public struct TimestreamInfluxDBErrorType: AWSErrorType {
    enum Code: String {
        case accessDeniedException = "AccessDeniedException"
        case conflictException = "ConflictException"
        case internalServerException = "InternalServerException"
        case resourceNotFoundException = "ResourceNotFoundException"
        case serviceQuotaExceededException = "ServiceQuotaExceededException"
        case throttlingException = "ThrottlingException"
        case validationException = "ValidationException"
    }

    private let error: Code
    public let context: AWSErrorContext?

    /// initialize TimestreamInfluxDB
    public init?(errorCode: String, context: AWSErrorContext) {
        guard let error = Code(rawValue: errorCode) else { return nil }
        self.error = error
        self.context = context
    }

    internal init(_ error: Code) {
        self.error = error
        self.context = nil
    }

    /// return error code string
    public var errorCode: String { self.error.rawValue }

    /// You do not have sufficient access to perform this action.
    public static var accessDeniedException: Self { .init(.accessDeniedException) }
    /// The request conflicts with an existing resource in Timestream for InfluxDB.
    public static var conflictException: Self { .init(.conflictException) }
    /// The request processing has failed because of an unknown error, exception or failure.
    public static var internalServerException: Self { .init(.internalServerException) }
    /// The requested resource was not found or does not exist.
    public static var resourceNotFoundException: Self { .init(.resourceNotFoundException) }
    /// The request exceeds the service quota.
    public static var serviceQuotaExceededException: Self { .init(.serviceQuotaExceededException) }
    /// The request was denied due to request throttling.
    public static var throttlingException: Self { .init(.throttlingException) }
    /// The input fails to satisfy the constraints specified by Timestream for InfluxDB.
    public static var validationException: Self { .init(.validationException) }
}

extension TimestreamInfluxDBErrorType: AWSServiceErrorType {
    public static let errorCodeMap: [String: AWSErrorShape.Type] = [
        "ConflictException": TimestreamInfluxDB.ConflictException.self,
        "ResourceNotFoundException": TimestreamInfluxDB.ResourceNotFoundException.self,
        "ThrottlingException": TimestreamInfluxDB.ThrottlingException.self,
        "ValidationException": TimestreamInfluxDB.ValidationException.self
    ]
}

extension TimestreamInfluxDBErrorType: Equatable {
    public static func == (lhs: TimestreamInfluxDBErrorType, rhs: TimestreamInfluxDBErrorType) -> Bool {
        lhs.error == rhs.error
    }
}

extension TimestreamInfluxDBErrorType: CustomStringConvertible {
    public var description: String {
        return "\(self.error.rawValue): \(self.message ?? "")"
    }
}
