//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2023 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

@_exported import SotoCore

/// Service object for interacting with AWS Neptunedata service.
///
/// Neptune Data API The Amazon Neptune data API provides SDK support for more than 40 of Neptune's data operations, including data loading, query execution, data inquiry, and machine learning. It supports  the Gremlin and openCypher query languages, and is available in all SDK languages. It automatically signs API requests and greatly simplifies integrating Neptune into your applications.
/// API Reference: https://docs.aws.amazon.com/neptune/latest/userguide/intro.html
public struct Neptunedata: AWSService {
    // MARK: Member variables

    /// Client used for communication with AWS
    public let client: AWSClient
    /// Service configuration
    public let config: AWSServiceConfig

    // MARK: Initialization

    /// Initialize the Neptunedata client
    /// - parameters:
    ///     - client: AWSClient used to process requests
    ///     - region: Region of server you want to communicate with. This will override the partition parameter.
    ///     - partition: AWS partition where service resides, standard (.aws), china (.awscn), government (.awsusgov).
    ///     - endpoint: Custom endpoint URL to use instead of standard AWS servers
    ///     - timeout: Timeout value for HTTP requests
    public init(
        client: AWSClient,
        region: SotoCore.Region? = nil,
        partition: AWSPartition = .aws,
        endpoint: String? = nil,
        timeout: TimeAmount? = nil,
        byteBufferAllocator: ByteBufferAllocator = ByteBufferAllocator(),
        options: AWSServiceConfig.Options = []
    ) {
        self.client = client
        self.config = AWSServiceConfig(
            region: region,
            partition: region?.partition ?? partition,
            service: "neptune-db",
            serviceProtocol: .restjson,
            apiVersion: "2023-08-01",
            endpoint: endpoint,
            errorType: NeptunedataErrorType.self,
            timeout: timeout,
            byteBufferAllocator: byteBufferAllocator,
            options: options
        )
    }

    // MARK: API Calls

    /// Cancels a Gremlin query. See Gremlin query cancellation for more information.
    public func cancelGremlinQuery(_ input: CancelGremlinQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelGremlinQueryOutput> {
        return self.client.execute(operation: "CancelGremlinQuery", path: "/gremlin/status/{queryId}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels a specified load job. This is an HTTP DELETE request. See Neptune Loader Get-Status API for more information.
    public func cancelLoaderJob(_ input: CancelLoaderJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelLoaderJobOutput> {
        return self.client.execute(operation: "CancelLoaderJob", path: "/loader/{loadId}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels a Neptune ML data processing job. See The dataprocessing command.
    public func cancelMLDataProcessingJob(_ input: CancelMLDataProcessingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelMLDataProcessingJobOutput> {
        return self.client.execute(operation: "CancelMLDataProcessingJob", path: "/ml/dataprocessing/{id}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels a Neptune ML model training job. See Model training using the modeltraining command.
    public func cancelMLModelTrainingJob(_ input: CancelMLModelTrainingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelMLModelTrainingJobOutput> {
        return self.client.execute(operation: "CancelMLModelTrainingJob", path: "/ml/modeltraining/{id}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels a specified model transform job. See Use a trained model to generate new model artifacts.
    public func cancelMLModelTransformJob(_ input: CancelMLModelTransformJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelMLModelTransformJobOutput> {
        return self.client.execute(operation: "CancelMLModelTransformJob", path: "/ml/modeltransform/{id}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels a specified openCypher query. See Neptune openCypher status endpoint for more information.
    public func cancelOpenCypherQuery(_ input: CancelOpenCypherQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CancelOpenCypherQueryOutput> {
        return self.client.execute(operation: "CancelOpenCypherQuery", path: "/opencypher/status/{queryId}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Creates a new Neptune ML inference endpoint that lets you query one specific model that the model-training process constructed. See Managing inference endpoints using the endpoints command.
    public func createMLEndpoint(_ input: CreateMLEndpointInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<CreateMLEndpointOutput> {
        return self.client.execute(operation: "CreateMLEndpoint", path: "/ml/endpoints", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Cancels the creation of a Neptune ML inference endpoint. See Managing inference endpoints using the endpoints command.
    public func deleteMLEndpoint(_ input: DeleteMLEndpointInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<DeleteMLEndpointOutput> {
        return self.client.execute(operation: "DeleteMLEndpoint", path: "/ml/endpoints/{id}", httpMethod: .DELETE, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Deletes statistics for Gremlin and openCypher (property graph) data.
    public func deletePropertygraphStatistics(logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<DeletePropertygraphStatisticsOutput> {
        return self.client.execute(operation: "DeletePropertygraphStatistics", path: "/propertygraph/statistics", httpMethod: .DELETE, serviceConfig: self.config, logger: logger, on: eventLoop)
    }

    /// Deletes SPARQL statistics
    public func deleteSparqlStatistics(logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<DeleteSparqlStatisticsOutput> {
        return self.client.execute(operation: "DeleteSparqlStatistics", path: "/sparql/statistics", httpMethod: .DELETE, serviceConfig: self.config, logger: logger, on: eventLoop)
    }

    /// The fast reset REST API lets you reset a Neptune graph quicky and easily, removing all of its data. Neptune fast reset is a two-step process. First you call ExecuteFastReset with action set to initiateDatabaseReset. This returns a UUID token which you then include when calling ExecuteFastReset again with action set to performDatabaseReset. See Empty an Amazon Neptune DB cluster using the fast reset API.
    public func executeFastReset(_ input: ExecuteFastResetInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteFastResetOutput> {
        return self.client.execute(operation: "ExecuteFastReset", path: "/system", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Executes a Gremlin Explain query. Amazon Neptune has added a Gremlin feature named explain that provides is a self-service tool for understanding the execution approach being taken by the Neptune engine for the query. You invoke it by adding an explain parameter to an HTTP call that submits a Gremlin query. The explain feature provides information about the logical structure of query execution plans. You can use this information to identify potential evaluation and execution bottlenecks and to tune your query, as explained  in Tuning Gremlin queries. You can also use query hints to improve query execution plans.
    public func executeGremlinExplainQuery(_ input: ExecuteGremlinExplainQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteGremlinExplainQueryOutput> {
        return self.client.execute(operation: "ExecuteGremlinExplainQuery", path: "/gremlin/explain", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Executes a Gremlin Profile query, which runs a specified traversal, collects various metrics about the run, and produces a profile report as output. See Gremlin profile API in Neptune for details.
    public func executeGremlinProfileQuery(_ input: ExecuteGremlinProfileQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteGremlinProfileQueryOutput> {
        return self.client.execute(operation: "ExecuteGremlinProfileQuery", path: "/gremlin/profile", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// This commands executes a Gremlin query. Amazon Neptune is compatible with Apache TinkerPop3 and Gremlin, so you can use the Gremlin traversal language to query the graph, as described under The Graph in the Apache TinkerPop3 documentation. More details can also be found in Accessing a Neptune graph with Gremlin.
    public func executeGremlinQuery(_ input: ExecuteGremlinQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteGremlinQueryOutput> {
        return self.client.execute(operation: "ExecuteGremlinQuery", path: "/gremlin", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Executes an openCypher explain request. See The openCypher explain feature for more information.
    public func executeOpenCypherExplainQuery(_ input: ExecuteOpenCypherExplainQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteOpenCypherExplainQueryOutput> {
        return self.client.execute(operation: "ExecuteOpenCypherExplainQuery", path: "/opencypher/explain", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Executes an openCypher query. See Accessing the Neptune Graph with openCypher for more information. Neptune supports building graph applications using openCypher, which is currently one of the most popular query languages among developers working with graph databases. Developers, business analysts, and data scientists like openCypher's declarative, SQL-inspired syntax because it provides a familiar structure in which to querying property graphs. The openCypher language was originally developed by Neo4j, then open-sourced in 2015 and contributed to the openCypher project under an Apache 2 open-source license.
    public func executeOpenCypherQuery(_ input: ExecuteOpenCypherQueryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ExecuteOpenCypherQueryOutput> {
        return self.client.execute(operation: "ExecuteOpenCypherQuery", path: "/opencypher", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Check the status of the graph database on the host.
    public func getEngineStatus(logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetEngineStatusOutput> {
        return self.client.execute(operation: "GetEngineStatus", path: "/status", httpMethod: .GET, serviceConfig: self.config, logger: logger, on: eventLoop)
    }

    /// Gets the status of a specified Gremlin query.
    public func getGremlinQueryStatus(_ input: GetGremlinQueryStatusInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetGremlinQueryStatusOutput> {
        return self.client.execute(operation: "GetGremlinQueryStatus", path: "/gremlin/status/{queryId}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets status information about a specified load job. Neptune keeps track of the most recent 1,024 bulk load jobs, and stores the last 10,000 error details per job. See Neptune Loader Get-Status API for more information.
    public func getLoaderJobStatus(_ input: GetLoaderJobStatusInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetLoaderJobStatusOutput> {
        return self.client.execute(operation: "GetLoaderJobStatus", path: "/loader/{loadId}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Retrieves information about a specified data processing job. See The dataprocessing command.
    public func getMLDataProcessingJob(_ input: GetMLDataProcessingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetMLDataProcessingJobOutput> {
        return self.client.execute(operation: "GetMLDataProcessingJob", path: "/ml/dataprocessing/{id}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Retrieves details about an inference endpoint. See Managing inference endpoints using the endpoints command.
    public func getMLEndpoint(_ input: GetMLEndpointInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetMLEndpointOutput> {
        return self.client.execute(operation: "GetMLEndpoint", path: "/ml/endpoints/{id}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Retrieves information about a Neptune ML model training job. See Model training using the modeltraining command.
    public func getMLModelTrainingJob(_ input: GetMLModelTrainingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetMLModelTrainingJobOutput> {
        return self.client.execute(operation: "GetMLModelTrainingJob", path: "/ml/modeltraining/{id}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets information about a specified model transform job. See Use a trained model to generate new model artifacts.
    public func getMLModelTransformJob(_ input: GetMLModelTransformJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetMLModelTransformJobOutput> {
        return self.client.execute(operation: "GetMLModelTransformJob", path: "/ml/modeltransform/{id}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Retrieves the status of a specified openCypher query.
    public func getOpenCypherQueryStatus(_ input: GetOpenCypherQueryStatusInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetOpenCypherQueryStatusOutput> {
        return self.client.execute(operation: "GetOpenCypherQueryStatus", path: "/opencypher/status/{queryId}", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets property graph statistics (Gremlin and openCypher).
    public func getPropertygraphStatistics(logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetPropertygraphStatisticsOutput> {
        return self.client.execute(operation: "GetPropertygraphStatistics", path: "/propertygraph/statistics", httpMethod: .GET, serviceConfig: self.config, logger: logger, on: eventLoop)
    }

    /// Gets a stream for a property graph. With the Neptune Streams feature, you can generate a complete sequence of change-log entries that record every change made to your graph data as it happens. GetPropertygraphStream lets you collect these change-log entries for a property graph. The Neptune streams feature needs to be enabled on your Neptune DBcluster. To enable streams, set the neptune_streams DB cluster parameter to 1. See Capturing graph changes in real time using Neptune streams.
    public func getPropertygraphStream(_ input: GetPropertygraphStreamInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetPropertygraphStreamOutput> {
        return self.client.execute(operation: "GetPropertygraphStream", path: "/propertygraph/stream", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets a graph summary for a property graph.
    public func getPropertygraphSummary(_ input: GetPropertygraphSummaryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetPropertygraphSummaryOutput> {
        return self.client.execute(operation: "GetPropertygraphSummary", path: "/propertygraph/statistics/summary", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets a graph summary for an RDF graph.
    public func getRDFGraphSummary(_ input: GetRDFGraphSummaryInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetRDFGraphSummaryOutput> {
        return self.client.execute(operation: "GetRDFGraphSummary", path: "/rdf/statistics/summary", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Gets RDF statistics (SPARQL).
    public func getSparqlStatistics(logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetSparqlStatisticsOutput> {
        return self.client.execute(operation: "GetSparqlStatistics", path: "/sparql/statistics", httpMethod: .GET, serviceConfig: self.config, logger: logger, on: eventLoop)
    }

    /// Gets a stream for an RDF graph. With the Neptune Streams feature, you can generate a complete sequence of change-log entries that record every change made to your graph data as it happens. GetSparqlStream lets you collect these change-log entries for an RDF graph. The Neptune streams feature needs to be enabled on your Neptune DBcluster. To enable streams, set the neptune_streams DB cluster parameter to 1. See Capturing graph changes in real time using Neptune streams.
    public func getSparqlStream(_ input: GetSparqlStreamInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<GetSparqlStreamOutput> {
        return self.client.execute(operation: "GetSparqlStream", path: "/sparql/stream", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Lists active Gremlin queries. See Gremlin query status API for details about the output.
    public func listGremlinQueries(_ input: ListGremlinQueriesInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListGremlinQueriesOutput> {
        return self.client.execute(operation: "ListGremlinQueries", path: "/gremlin/status", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Retrieves a list of the loadIds for all active loader jobs.
    public func listLoaderJobs(_ input: ListLoaderJobsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListLoaderJobsOutput> {
        return self.client.execute(operation: "ListLoaderJobs", path: "/loader", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Returns a list of Neptune ML data processing jobs. See Listing active data-processing jobs using the Neptune ML dataprocessing command.
    public func listMLDataProcessingJobs(_ input: ListMLDataProcessingJobsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListMLDataProcessingJobsOutput> {
        return self.client.execute(operation: "ListMLDataProcessingJobs", path: "/ml/dataprocessing", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Lists existing inference endpoints. See Managing inference endpoints using the endpoints command.
    public func listMLEndpoints(_ input: ListMLEndpointsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListMLEndpointsOutput> {
        return self.client.execute(operation: "ListMLEndpoints", path: "/ml/endpoints", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Lists Neptune ML model-training jobs. See Model training using the modeltraining command.
    public func listMLModelTrainingJobs(_ input: ListMLModelTrainingJobsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListMLModelTrainingJobsOutput> {
        return self.client.execute(operation: "ListMLModelTrainingJobs", path: "/ml/modeltraining", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Returns a list of model transform job IDs. See Use a trained model to generate new model artifacts.
    public func listMLModelTransformJobs(_ input: ListMLModelTransformJobsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListMLModelTransformJobsOutput> {
        return self.client.execute(operation: "ListMLModelTransformJobs", path: "/ml/modeltransform", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Lists active openCypher queries. See Neptune openCypher status endpoint for more information.
    public func listOpenCypherQueries(_ input: ListOpenCypherQueriesInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ListOpenCypherQueriesOutput> {
        return self.client.execute(operation: "ListOpenCypherQueries", path: "/opencypher/status", httpMethod: .GET, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Manages the generation and use of property graph statistics.
    public func managePropertygraphStatistics(_ input: ManagePropertygraphStatisticsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ManagePropertygraphStatisticsOutput> {
        return self.client.execute(operation: "ManagePropertygraphStatistics", path: "/propertygraph/statistics", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Manages the generation and use of RDF graph statistics.
    public func manageSparqlStatistics(_ input: ManageSparqlStatisticsInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ManageSparqlStatisticsOutput> {
        return self.client.execute(operation: "ManageSparqlStatistics", path: "/sparql/statistics", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Starts a Neptune bulk loader job to load data from an Amazon S3 bucket into a Neptune DB instance. See Using the Amazon Neptune Bulk Loader to Ingest Data.
    public func startLoaderJob(_ input: StartLoaderJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<StartLoaderJobOutput> {
        return self.client.execute(operation: "StartLoaderJob", path: "/loader", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Creates a new Neptune ML data processing job for processing the graph data exported from Neptune for training. See The dataprocessing command.
    public func startMLDataProcessingJob(_ input: StartMLDataProcessingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<StartMLDataProcessingJobOutput> {
        return self.client.execute(operation: "StartMLDataProcessingJob", path: "/ml/dataprocessing", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Creates a new Neptune ML model training job. See Model training using the modeltraining command.
    public func startMLModelTrainingJob(_ input: StartMLModelTrainingJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<StartMLModelTrainingJobOutput> {
        return self.client.execute(operation: "StartMLModelTrainingJob", path: "/ml/modeltraining", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// Creates a new model transform job. See Use a trained model to generate new model artifacts.
    public func startMLModelTransformJob(_ input: StartMLModelTransformJobInput, logger: Logger = AWSClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<StartMLModelTransformJobOutput> {
        return self.client.execute(operation: "StartMLModelTransformJob", path: "/ml/modeltransform", httpMethod: .POST, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }
}

extension Neptunedata {
    /// Initializer required by `AWSService.with(middlewares:timeout:byteBufferAllocator:options)`. You are not able to use this initializer directly as there are no public
    /// initializers for `AWSServiceConfig.Patch`. Please use `AWSService.with(middlewares:timeout:byteBufferAllocator:options)` instead.
    public init(from: Neptunedata, patch: AWSServiceConfig.Patch) {
        self.client = from.client
        self.config = from.config.with(patch: patch)
    }
}
