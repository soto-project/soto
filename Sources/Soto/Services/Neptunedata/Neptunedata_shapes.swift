//===----------------------------------------------------------------------===//
//
// This source file is part of the Soto for AWS open source project
//
// Copyright (c) 2017-2023 the Soto project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
// See CONTRIBUTORS.txt for the list of Soto project authors
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/soto-project/soto-codegenerator.
// DO NOT EDIT.

#if os(Linux) && compiler(<5.10)
// swift-corelibs-foundation hasn't been updated with Sendable conformances
@preconcurrency import Foundation
#else
import Foundation
#endif
@_spi(SotoInternal) import SotoCore

extension Neptunedata {
    // MARK: Enums

    public enum Action: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case initializeReset = "initiateDatabaseReset"
        case performReset = "performDatabaseReset"
        public var description: String { return self.rawValue }
    }

    public enum Encoding: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case gzip = "gzip"
        public var description: String { return self.rawValue }
    }

    public enum Format: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case csv = "csv"
        case nquads = "nquads"
        case ntriples = "ntriples"
        case opencypher = "opencypher"
        case rdfxml = "rdfxml"
        case turtle = "turtle"
        public var description: String { return self.rawValue }
    }

    public enum GraphSummaryType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case basic = "basic"
        case detailed = "detailed"
        public var description: String { return self.rawValue }
    }

    public enum IteratorType: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case afterSequenceNumber = "AFTER_SEQUENCE_NUMBER"
        case atSequenceNumber = "AT_SEQUENCE_NUMBER"
        case latest = "LATEST"
        case trimHorizon = "TRIM_HORIZON"
        public var description: String { return self.rawValue }
    }

    public enum Mode: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case auto = "AUTO"
        case new = "NEW"
        case resume = "RESUME"
        public var description: String { return self.rawValue }
    }

    public enum OpenCypherExplainMode: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case `static` = "static"
        case details = "details"
        case dynamic = "dynamic"
        public var description: String { return self.rawValue }
    }

    public enum Parallelism: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case high = "HIGH"
        case low = "LOW"
        case medium = "MEDIUM"
        case oversubscribe = "OVERSUBSCRIBE"
        public var description: String { return self.rawValue }
    }

    public enum S3BucketRegion: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case afSouth1 = "af-south-1"
        case apEast1 = "ap-east-1"
        case apNortheast1 = "ap-northeast-1"
        case apNortheast2 = "ap-northeast-2"
        case apSouth1 = "ap-south-1"
        case apSoutheast1 = "ap-southeast-1"
        case apSoutheast2 = "ap-southeast-2"
        case caCentral1 = "ca-central-1"
        case cnNorth1 = "cn-north-1"
        case cnNorthwest1 = "cn-northwest-1"
        case euCentral1 = "eu-central-1"
        case euNorth1 = "eu-north-1"
        case euWest1 = "eu-west-1"
        case euWest2 = "eu-west-2"
        case euWest3 = "eu-west-3"
        case meSouth1 = "me-south-1"
        case saEast1 = "sa-east-1"
        case usEast1 = "us-east-1"
        case usEast2 = "us-east-2"
        case usGovEast1 = "us-gov-east-1"
        case usGovWest1 = "us-gov-west-1"
        case usWest1 = "us-west-1"
        case usWest2 = "us-west-2"
        public var description: String { return self.rawValue }
    }

    public enum StatisticsAutoGenerationMode: String, CustomStringConvertible, Codable, Sendable, CodingKeyRepresentable {
        case disableAutocompute = "disableAutoCompute"
        case enableAutocompute = "enableAutoCompute"
        case refresh = "refresh"
        public var description: String { return self.rawValue }
    }

    // MARK: Shapes

    public struct CancelGremlinQueryInput: AWSEncodableShape {
        /// The unique identifier that identifies the query to be canceled.
        public let queryId: String

        public init(queryId: String) {
            self.queryId = queryId
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.queryId, key: "queryId")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelGremlinQueryOutput: AWSDecodableShape {
        /// The status of the cancelation
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct CancelLoaderJobInput: AWSEncodableShape {
        /// The ID of the load job to be deleted.
        public let loadId: String

        public init(loadId: String) {
            self.loadId = loadId
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.loadId, key: "loadId")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelLoaderJobOutput: AWSDecodableShape {
        /// The cancellation status.
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct CancelMLDataProcessingJobInput: AWSEncodableShape {
        /// If set to TRUE, this flag specifies that all Neptune ML S3 artifacts should be deleted when the job is stopped. The default is FALSE.
        public let clean: Bool?
        /// The unique identifier of the data-processing job.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(clean: Bool? = nil, id: String, neptuneIamRoleArn: String? = nil) {
            self.clean = clean
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.clean, key: "clean")
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelMLDataProcessingJobOutput: AWSDecodableShape {
        /// The status of the cancellation request.
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct CancelMLModelTrainingJobInput: AWSEncodableShape {
        /// If set to TRUE, this flag specifies that all Amazon S3 artifacts should be deleted when the job is stopped. The default is FALSE.
        public let clean: Bool?
        /// The unique identifier of the model-training job to be canceled.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(clean: Bool? = nil, id: String, neptuneIamRoleArn: String? = nil) {
            self.clean = clean
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.clean, key: "clean")
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelMLModelTrainingJobOutput: AWSDecodableShape {
        /// The status of the cancellation.
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct CancelMLModelTransformJobInput: AWSEncodableShape {
        /// If this flag is set to TRUE, all Neptune ML S3 artifacts should be deleted when the job is stopped. The default is FALSE.
        public let clean: Bool?
        /// The unique ID of the model transform job to be canceled.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(clean: Bool? = nil, id: String, neptuneIamRoleArn: String? = nil) {
            self.clean = clean
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.clean, key: "clean")
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelMLModelTransformJobOutput: AWSDecodableShape {
        /// the status of the cancelation.
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct CancelOpenCypherQueryInput: AWSEncodableShape {
        /// The unique ID of the openCypher query to cancel.
        public let queryId: String
        /// If set to TRUE, causes the cancelation of the openCypher query to happen silently.
        public let silent: Bool?

        public init(queryId: String, silent: Bool? = nil) {
            self.queryId = queryId
            self.silent = silent
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.queryId, key: "queryId")
            request.encodeQuery(self.silent, key: "silent")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct CancelOpenCypherQueryOutput: AWSDecodableShape {
        /// The cancelation payload for the openCypher query.
        public let payload: Bool?
        /// The cancellation status of the openCypher query.
        public let status: String?

        public init(payload: Bool? = nil, status: String? = nil) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct CreateMLEndpointInput: AWSEncodableShape {
        /// A unique identifier for the new inference endpoint. The default is an autogenerated timestamped name.
        public let id: String?
        /// The minimum number of Amazon EC2 instances to deploy to an endpoint for prediction. The default is 1
        public let instanceCount: Int?
        /// The type of Neptune ML instance to use for online servicing. The default is ml.m5.xlarge. Choosing the ML instance for an inference endpoint depends on the task type, the graph size, and your budget.
        public let instanceType: String?
        /// The job Id of the completed model-training job that has created the model that the inference endpoint will point to. You must supply either the mlModelTrainingJobId or the mlModelTransformJobId.
        public let mlModelTrainingJobId: String?
        /// The job Id of the completed model-transform job. You must supply either the mlModelTrainingJobId or the mlModelTransformJobId.
        public let mlModelTransformJobId: String?
        /// Model type for training. By default the Neptune ML model is automatically based on the modelType used in data processing, but you can specify a different model type here. The default is rgcn for heterogeneous graphs and kge for knowledge graphs. The only valid value for heterogeneous graphs is rgcn. Valid values for knowledge graphs are: kge, transe, distmult, and rotate.
        public let modelName: String?
        /// The ARN of an IAM role providing Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will be thrown.
        public let neptuneIamRoleArn: String?
        /// If set to true, update indicates that this is an update request. The default is false. You must supply either the mlModelTrainingJobId or the mlModelTransformJobId.
        public let update: Bool?
        /// The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.
        public let volumeEncryptionKMSKey: String?

        public init(id: String? = nil, instanceCount: Int? = nil, instanceType: String? = nil, mlModelTrainingJobId: String? = nil, mlModelTransformJobId: String? = nil, modelName: String? = nil, neptuneIamRoleArn: String? = nil, update: Bool? = nil, volumeEncryptionKMSKey: String? = nil) {
            self.id = id
            self.instanceCount = instanceCount
            self.instanceType = instanceType
            self.mlModelTrainingJobId = mlModelTrainingJobId
            self.mlModelTransformJobId = mlModelTransformJobId
            self.modelName = modelName
            self.neptuneIamRoleArn = neptuneIamRoleArn
            self.update = update
            self.volumeEncryptionKMSKey = volumeEncryptionKMSKey
        }

        private enum CodingKeys: String, CodingKey {
            case id = "id"
            case instanceCount = "instanceCount"
            case instanceType = "instanceType"
            case mlModelTrainingJobId = "mlModelTrainingJobId"
            case mlModelTransformJobId = "mlModelTransformJobId"
            case modelName = "modelName"
            case neptuneIamRoleArn = "neptuneIamRoleArn"
            case update = "update"
            case volumeEncryptionKMSKey = "volumeEncryptionKMSKey"
        }
    }

    public struct CreateMLEndpointOutput: AWSDecodableShape {
        /// The ARN for the new inference endpoint.
        public let arn: String?
        /// The endpoint creation time, in milliseconds.
        public let creationTimeInMillis: Int64?
        /// The unique ID of the new inference endpoint.
        public let id: String?

        public init(arn: String? = nil, creationTimeInMillis: Int64? = nil, id: String? = nil) {
            self.arn = arn
            self.creationTimeInMillis = creationTimeInMillis
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case creationTimeInMillis = "creationTimeInMillis"
            case id = "id"
        }
    }

    public struct CustomModelTrainingParameters: AWSEncodableShape {
        /// The path to the Amazon S3 location where the Python module implementing your model is located. This must point to a valid existing Amazon S3 location that contains, at a minimum, a training script, a transform script, and a model-hpo-configuration.json file.
        public let sourceS3DirectoryPath: String
        /// The name of the entry point in your module of a script that performs model training and takes hyperparameters as command-line arguments, including fixed hyperparameters. The default is training.py.
        public let trainingEntryPointScript: String?
        /// The name of the entry point in your module of a script that should be run after the best model from the hyperparameter search has been identified, to compute the model artifacts necessary for model deployment. It should be able to run with no command-line arguments.The default is transform.py.
        public let transformEntryPointScript: String?

        public init(sourceS3DirectoryPath: String, trainingEntryPointScript: String? = nil, transformEntryPointScript: String? = nil) {
            self.sourceS3DirectoryPath = sourceS3DirectoryPath
            self.trainingEntryPointScript = trainingEntryPointScript
            self.transformEntryPointScript = transformEntryPointScript
        }

        private enum CodingKeys: String, CodingKey {
            case sourceS3DirectoryPath = "sourceS3DirectoryPath"
            case trainingEntryPointScript = "trainingEntryPointScript"
            case transformEntryPointScript = "transformEntryPointScript"
        }
    }

    public struct CustomModelTransformParameters: AWSEncodableShape {
        /// The path to the Amazon S3 location where the Python module implementing your model is located. This must point to a valid existing Amazon S3 location that contains, at a minimum, a training script, a transform script, and a model-hpo-configuration.json file.
        public let sourceS3DirectoryPath: String
        /// The name of the entry point in your module of a script that should be run after the best model from the hyperparameter search has been identified, to compute the model artifacts necessary for model deployment. It should be able to run with no command-line arguments. The default is transform.py.
        public let transformEntryPointScript: String?

        public init(sourceS3DirectoryPath: String, transformEntryPointScript: String? = nil) {
            self.sourceS3DirectoryPath = sourceS3DirectoryPath
            self.transformEntryPointScript = transformEntryPointScript
        }

        private enum CodingKeys: String, CodingKey {
            case sourceS3DirectoryPath = "sourceS3DirectoryPath"
            case transformEntryPointScript = "transformEntryPointScript"
        }
    }

    public struct DeleteMLEndpointInput: AWSEncodableShape {
        /// If this flag is set to TRUE, all Neptune ML S3 artifacts should be deleted when the job is stopped. The default is FALSE.
        public let clean: Bool?
        /// The unique identifier of the inference endpoint.
        public let id: String
        /// The ARN of an IAM role providing Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will be thrown.
        public let neptuneIamRoleArn: String?

        public init(clean: Bool? = nil, id: String, neptuneIamRoleArn: String? = nil) {
            self.clean = clean
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.clean, key: "clean")
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct DeleteMLEndpointOutput: AWSDecodableShape {
        /// The status of the cancellation.
        public let status: String?

        public init(status: String? = nil) {
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case status = "status"
        }
    }

    public struct DeletePropertygraphStatisticsOutput: AWSDecodableShape {
        /// The deletion payload.
        public let payload: DeleteStatisticsValueMap?
        /// The cancel status.
        public let status: String?
        /// The HTTP response code: 200 if the delete was successful, or 204 if there were no statistics to delete.
        public let statusCode: Int?

        public init(payload: DeleteStatisticsValueMap? = nil, status: String? = nil, statusCode: Int? = nil) {
            self.payload = payload
            self.status = status
            self.statusCode = statusCode
        }

        public init(from decoder: Decoder) throws {
            let response = decoder.userInfo[.awsResponse]! as! ResponseDecodingContainer
            let container = try decoder.container(keyedBy: CodingKeys.self)
            self.payload = try container.decodeIfPresent(DeleteStatisticsValueMap.self, forKey: .payload)
            self.status = try container.decodeIfPresent(String.self, forKey: .status)
            self.statusCode = response.decodeStatus()
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct DeleteSparqlStatisticsOutput: AWSDecodableShape {
        /// The deletion payload.
        public let payload: DeleteStatisticsValueMap?
        /// The cancel status.
        public let status: String?
        /// The HTTP response code: 200 if the delete was successful, or 204 if there were no statistics to delete.
        public let statusCode: Int?

        public init(payload: DeleteStatisticsValueMap? = nil, status: String? = nil, statusCode: Int? = nil) {
            self.payload = payload
            self.status = status
            self.statusCode = statusCode
        }

        public init(from decoder: Decoder) throws {
            let response = decoder.userInfo[.awsResponse]! as! ResponseDecodingContainer
            let container = try decoder.container(keyedBy: CodingKeys.self)
            self.payload = try container.decodeIfPresent(DeleteStatisticsValueMap.self, forKey: .payload)
            self.status = try container.decodeIfPresent(String.self, forKey: .status)
            self.statusCode = response.decodeStatus()
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct DeleteStatisticsValueMap: AWSDecodableShape {
        /// The current status of the statistics.
        public let active: Bool?
        /// The ID of the statistics generation run that is currently occurring.
        public let statisticsId: String?

        public init(active: Bool? = nil, statisticsId: String? = nil) {
            self.active = active
            self.statisticsId = statisticsId
        }

        private enum CodingKeys: String, CodingKey {
            case active = "active"
            case statisticsId = "statisticsId"
        }
    }

    public struct EdgeStructure: AWSDecodableShape {
        /// The number of edges that have this specific structure.
        public let count: Int64?
        /// A list of edge properties present in this specific structure.
        public let edgeProperties: [String]?

        public init(count: Int64? = nil, edgeProperties: [String]? = nil) {
            self.count = count
            self.edgeProperties = edgeProperties
        }

        private enum CodingKeys: String, CodingKey {
            case count = "count"
            case edgeProperties = "edgeProperties"
        }
    }

    public struct ExecuteFastResetInput: AWSEncodableShape {
        /// The fast reset action. One of the following values:     initiateDatabaseReset   –   This action generates a unique token needed to actually perform the  fast reset.     performDatabaseReset   –   This action uses the token generated by the initiateDatabaseReset action to actually perform the fast reset.
        public let action: Action
        /// The fast-reset token to initiate the reset.
        public let token: String?

        public init(action: Action, token: String? = nil) {
            self.action = action
            self.token = token
        }

        private enum CodingKeys: String, CodingKey {
            case action = "action"
            case token = "token"
        }
    }

    public struct ExecuteFastResetOutput: AWSDecodableShape {
        /// The payload is only returned by the initiateDatabaseReset action, and contains the unique token to use with the performDatabaseReset action to make the reset occur.
        public let payload: FastResetToken?
        /// The status is only returned for the performDatabaseReset action, and indicates whether or not the fast reset rquest is accepted.
        public let status: String

        public init(payload: FastResetToken? = nil, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct ExecuteGremlinExplainQueryInput: AWSEncodableShape {
        /// The Gremlin explain query string.
        public let gremlinQuery: String

        public init(gremlinQuery: String) {
            self.gremlinQuery = gremlinQuery
        }

        private enum CodingKeys: String, CodingKey {
            case gremlinQuery = "gremlin"
        }
    }

    public struct ExecuteGremlinExplainQueryOutput: AWSDecodableShape {
        public static let _options: AWSShapeOptions = [.rawPayload]
        /// A text blob containing the Gremlin explain result, as described in Tuning Gremlin queries.
        public let output: AWSHTTPBody

        public init(output: AWSHTTPBody) {
            self.output = output
        }

        public init(from decoder: Decoder) throws {
            let container = try decoder.singleValueContainer()
            self.output = try container.decode(AWSHTTPBody.self)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ExecuteGremlinProfileQueryInput: AWSEncodableShape {
        /// If non-zero, causes the results string to be truncated at that number of characters. If set to zero, the string contains all the results.
        public let chop: Int?
        /// The Gremlin query string to profile.
        public let gremlinQuery: String
        /// If this flag is set to TRUE, the results include a detailed report of all index operations that took place during query execution and serialization.
        public let indexOps: Bool?
        /// If this flag is set to TRUE, the query results are gathered and displayed as part of the profile report. If FALSE, only the result count is displayed.
        public let results: Bool?
        /// If non-null, the gathered results are returned in a serialized response message in the format specified by this parameter. See Gremlin profile API in Neptune for more information.
        public let serializer: String?

        public init(chop: Int? = nil, gremlinQuery: String, indexOps: Bool? = nil, results: Bool? = nil, serializer: String? = nil) {
            self.chop = chop
            self.gremlinQuery = gremlinQuery
            self.indexOps = indexOps
            self.results = results
            self.serializer = serializer
        }

        private enum CodingKeys: String, CodingKey {
            case chop = "profile.chop"
            case gremlinQuery = "gremlin"
            case indexOps = "profile.indexOps"
            case results = "profile.results"
            case serializer = "profile.serializer"
        }
    }

    public struct ExecuteGremlinProfileQueryOutput: AWSDecodableShape {
        public static let _options: AWSShapeOptions = [.rawPayload]
        /// A text blob containing the Gremlin Profile result. See Gremlin profile API in Neptune for details.
        public let output: AWSHTTPBody

        public init(output: AWSHTTPBody) {
            self.output = output
        }

        public init(from decoder: Decoder) throws {
            let container = try decoder.singleValueContainer()
            self.output = try container.decode(AWSHTTPBody.self)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ExecuteGremlinQueryInput: AWSEncodableShape {
        /// Using this API, you can run Gremlin queries in string format much as you can using the HTTP endpoint. The interface is compatible with whatever Gremlin version your DB cluster is using (see the Tinkerpop client section to determine which Gremlin releases your engine version supports).
        public let gremlinQuery: String
        /// If non-null, the query results are returned in a serialized response message in the format specified by this parameter. See the GraphSON section in the TinkerPop documentation for a list of the formats that are currently supported.
        public let serializer: String?

        public init(gremlinQuery: String, serializer: String? = nil) {
            self.gremlinQuery = gremlinQuery
            self.serializer = serializer
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            var container = encoder.container(keyedBy: CodingKeys.self)
            try container.encode(self.gremlinQuery, forKey: .gremlinQuery)
            request.encodeHeader(self.serializer, key: "accept")
        }

        private enum CodingKeys: String, CodingKey {
            case gremlinQuery = "gremlin"
        }
    }

    public struct ExecuteGremlinQueryOutput: AWSDecodableShape {
        /// Metadata about the Gremlin query.
        public let meta: String?
        /// The unique identifier of the Gremlin query.
        public let requestId: String?
        /// The Gremlin query output from the server.
        public let result: String?
        /// The status of the Gremlin query.
        public let status: GremlinQueryStatusAttributes?

        public init(meta: String? = nil, requestId: String? = nil, result: String? = nil, status: GremlinQueryStatusAttributes? = nil) {
            self.meta = meta
            self.requestId = requestId
            self.result = result
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case meta = "meta"
            case requestId = "requestId"
            case result = "result"
            case status = "status"
        }
    }

    public struct ExecuteOpenCypherExplainQueryInput: AWSEncodableShape {
        /// The openCypher explain mode. Can be one of: static, dynamic, or details.
        public let explainMode: OpenCypherExplainMode
        /// The openCypher query string.
        public let openCypherQuery: String
        /// The openCypher query parameters.
        public let parameters: String?

        public init(explainMode: OpenCypherExplainMode, openCypherQuery: String, parameters: String? = nil) {
            self.explainMode = explainMode
            self.openCypherQuery = openCypherQuery
            self.parameters = parameters
        }

        private enum CodingKeys: String, CodingKey {
            case explainMode = "explain"
            case openCypherQuery = "query"
            case parameters = "parameters"
        }
    }

    public struct ExecuteOpenCypherExplainQueryOutput: AWSDecodableShape {
        public static let _options: AWSShapeOptions = [.rawPayload]
        /// A text blob containing the openCypher explain results.
        public let results: AWSHTTPBody

        public init(results: AWSHTTPBody) {
            self.results = results
        }

        public init(from decoder: Decoder) throws {
            let container = try decoder.singleValueContainer()
            self.results = try container.decode(AWSHTTPBody.self)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ExecuteOpenCypherQueryInput: AWSEncodableShape {
        /// The openCypher query string to be executed.
        public let openCypherQuery: String
        /// The openCypher query parameters for query execution. See Examples of openCypher parameterized queries for more information.
        public let parameters: String?

        public init(openCypherQuery: String, parameters: String? = nil) {
            self.openCypherQuery = openCypherQuery
            self.parameters = parameters
        }

        private enum CodingKeys: String, CodingKey {
            case openCypherQuery = "query"
            case parameters = "parameters"
        }
    }

    public struct ExecuteOpenCypherQueryOutput: AWSDecodableShape {
        /// The openCypherquery results.
        public let results: String

        public init(results: String) {
            self.results = results
        }

        private enum CodingKeys: String, CodingKey {
            case results = "results"
        }
    }

    public struct FastResetToken: AWSDecodableShape {
        /// A UUID generated by the database in the initiateDatabaseReset action, and then consumed by the performDatabaseReset to reset the database.
        public let token: String?

        public init(token: String? = nil) {
            self.token = token
        }

        private enum CodingKeys: String, CodingKey {
            case token = "token"
        }
    }

    public struct GetEngineStatusOutput: AWSDecodableShape {
        /// Set to the Neptune engine version running on your DB cluster. If this engine version has been manually patched since it was released, the version number is prefixed by Patch-.
        public let dbEngineVersion: String?
        /// Set to enabled if the DFE engine is fully enabled, or to viaQueryHint (the default) if the DFE engine is only used with queries that have the useDFE query hint set to true.
        public let dfeQueryEngine: String?
        /// Contains status information about the features enabled on your DB cluster.
        public let features: [String: String]?
        /// Contains information about the Gremlin query language available on your cluster. Specifically, it contains a version field that specifies the current TinkerPop version being used by the engine.
        public let gremlin: QueryLanguageVersion?
        /// Contains Lab Mode settings being used by the engine.
        public let labMode: [String: String]?
        /// Contains information about the openCypher query language available on your cluster. Specifically, it contains a version field that specifies the current operCypher version being used by the engine.
        public let opencypher: QueryLanguageVersion?
        /// Set to reader if the instance is a read-replica, or to writer if the instance is the primary instance.
        public let role: String?
        /// If there are transactions being rolled back, this field is set to the number of such transactions.  If there are none, the field doesn't appear at all.
        public let rollingBackTrxCount: Int?
        /// Set to the start time of the earliest transaction being rolled back. If no transactions are being rolled back, the field doesn't appear at all.
        public let rollingBackTrxEarliestStartTime: String?
        /// Contains information about the current settings on your DB cluster. For example, contains the current cluster query timeout setting (clusterQueryTimeoutInMs).
        public let settings: [String: String]?
        /// Contains information about the SPARQL query language available on your cluster. Specifically, it contains a version field that specifies the current SPARQL version being used by the engine.
        public let sparql: QueryLanguageVersion?
        /// Set to the UTC time at which the current server process started.
        public let startTime: String?
        /// Set to healthy if the instance is not experiencing problems. If the instance is recovering from a crash or from being rebooted and there are active transactions running from the latest server shutdown, status is set to recovery.
        public let status: String?

        public init(dbEngineVersion: String? = nil, dfeQueryEngine: String? = nil, features: [String: String]? = nil, gremlin: QueryLanguageVersion? = nil, labMode: [String: String]? = nil, opencypher: QueryLanguageVersion? = nil, role: String? = nil, rollingBackTrxCount: Int? = nil, rollingBackTrxEarliestStartTime: String? = nil, settings: [String: String]? = nil, sparql: QueryLanguageVersion? = nil, startTime: String? = nil, status: String? = nil) {
            self.dbEngineVersion = dbEngineVersion
            self.dfeQueryEngine = dfeQueryEngine
            self.features = features
            self.gremlin = gremlin
            self.labMode = labMode
            self.opencypher = opencypher
            self.role = role
            self.rollingBackTrxCount = rollingBackTrxCount
            self.rollingBackTrxEarliestStartTime = rollingBackTrxEarliestStartTime
            self.settings = settings
            self.sparql = sparql
            self.startTime = startTime
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case dbEngineVersion = "dbEngineVersion"
            case dfeQueryEngine = "dfeQueryEngine"
            case features = "features"
            case gremlin = "gremlin"
            case labMode = "labMode"
            case opencypher = "opencypher"
            case role = "role"
            case rollingBackTrxCount = "rollingBackTrxCount"
            case rollingBackTrxEarliestStartTime = "rollingBackTrxEarliestStartTime"
            case settings = "settings"
            case sparql = "sparql"
            case startTime = "startTime"
            case status = "status"
        }
    }

    public struct GetGremlinQueryStatusInput: AWSEncodableShape {
        /// The unique identifier that identifies the Gremlin query.
        public let queryId: String

        public init(queryId: String) {
            self.queryId = queryId
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.queryId, key: "queryId")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetGremlinQueryStatusOutput: AWSDecodableShape {
        /// The evaluation status of the Gremlin query.
        public let queryEvalStats: QueryEvalStats?
        /// The ID of the query for which status is being returned.
        public let queryId: String?
        /// The Gremlin query string.
        public let queryString: String?

        public init(queryEvalStats: QueryEvalStats? = nil, queryId: String? = nil, queryString: String? = nil) {
            self.queryEvalStats = queryEvalStats
            self.queryId = queryId
            self.queryString = queryString
        }

        private enum CodingKeys: String, CodingKey {
            case queryEvalStats = "queryEvalStats"
            case queryId = "queryId"
            case queryString = "queryString"
        }
    }

    public struct GetLoaderJobStatusInput: AWSEncodableShape {
        /// Flag indicating whether or not to include details beyond the overall status (TRUE or FALSE; the default is FALSE).
        public let details: Bool?
        /// Flag indicating whether or not to include a list of errors encountered (TRUE or FALSE; the default is FALSE). The list of errors is paged. The page and errorsPerPage parameters allow you to page through all the errors.
        public let errors: Bool?
        /// The number of errors returned in each page (a positive integer; the default is 10). Only valid when the errors parameter set to TRUE.
        public let errorsPerPage: Int?
        /// The load ID of the load job to get the status of.
        public let loadId: String
        /// The error page number (a positive integer; the default is 1). Only valid when the errors parameter is set to TRUE.
        public let page: Int?

        public init(details: Bool? = nil, errors: Bool? = nil, errorsPerPage: Int? = nil, loadId: String, page: Int? = nil) {
            self.details = details
            self.errors = errors
            self.errorsPerPage = errorsPerPage
            self.loadId = loadId
            self.page = page
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.details, key: "details")
            request.encodeQuery(self.errors, key: "errors")
            request.encodeQuery(self.errorsPerPage, key: "errorsPerPage")
            request.encodePath(self.loadId, key: "loadId")
            request.encodeQuery(self.page, key: "page")
        }

        public func validate(name: String) throws {
            try self.validate(self.errorsPerPage, name: "errorsPerPage", parent: name, min: 1)
            try self.validate(self.page, name: "page", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetLoaderJobStatusOutput: AWSDecodableShape {
        /// Status information about the load job, in a layout that could look like this:
        public let payload: String
        /// The HTTP response code for the request.
        public let status: String

        public init(payload: String, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct GetMLDataProcessingJobInput: AWSEncodableShape {
        /// The unique identifier of the data-processing job to be retrieved.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(id: String, neptuneIamRoleArn: String? = nil) {
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetMLDataProcessingJobOutput: AWSDecodableShape {
        /// The unique identifier of this data-processing job.
        public let id: String?
        /// Definition of the data processing job.
        public let processingJob: MlResourceDefinition?
        /// Status of the data processing job.
        public let status: String?

        public init(id: String? = nil, processingJob: MlResourceDefinition? = nil, status: String? = nil) {
            self.id = id
            self.processingJob = processingJob
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case id = "id"
            case processingJob = "processingJob"
            case status = "status"
        }
    }

    public struct GetMLEndpointInput: AWSEncodableShape {
        /// The unique identifier of the inference endpoint.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(id: String, neptuneIamRoleArn: String? = nil) {
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetMLEndpointOutput: AWSDecodableShape {
        /// The endpoint definition.
        public let endpoint: MlResourceDefinition?
        /// The endpoint configuration
        public let endpointConfig: MlConfigDefinition?
        /// The unique identifier of the inference endpoint.
        public let id: String?
        /// The status of the inference endpoint.
        public let status: String?

        public init(endpoint: MlResourceDefinition? = nil, endpointConfig: MlConfigDefinition? = nil, id: String? = nil, status: String? = nil) {
            self.endpoint = endpoint
            self.endpointConfig = endpointConfig
            self.id = id
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case endpoint = "endpoint"
            case endpointConfig = "endpointConfig"
            case id = "id"
            case status = "status"
        }
    }

    public struct GetMLModelTrainingJobInput: AWSEncodableShape {
        /// The unique identifier of the model-training job to retrieve.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(id: String, neptuneIamRoleArn: String? = nil) {
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetMLModelTrainingJobOutput: AWSDecodableShape {
        /// The HPO job.
        public let hpoJob: MlResourceDefinition?
        /// The unique identifier of this model-training job.
        public let id: String?
        /// A list of the configurations of the ML models being used.
        public let mlModels: [MlConfigDefinition]?
        /// The model transform job.
        public let modelTransformJob: MlResourceDefinition?
        /// The data processing job.
        public let processingJob: MlResourceDefinition?
        /// The status of the model training job.
        public let status: String?

        public init(hpoJob: MlResourceDefinition? = nil, id: String? = nil, mlModels: [MlConfigDefinition]? = nil, modelTransformJob: MlResourceDefinition? = nil, processingJob: MlResourceDefinition? = nil, status: String? = nil) {
            self.hpoJob = hpoJob
            self.id = id
            self.mlModels = mlModels
            self.modelTransformJob = modelTransformJob
            self.processingJob = processingJob
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case hpoJob = "hpoJob"
            case id = "id"
            case mlModels = "mlModels"
            case modelTransformJob = "modelTransformJob"
            case processingJob = "processingJob"
            case status = "status"
        }
    }

    public struct GetMLModelTransformJobInput: AWSEncodableShape {
        /// The unique identifier of the model-transform job to be reetrieved.
        public let id: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(id: String, neptuneIamRoleArn: String? = nil) {
            self.id = id
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.id, key: "id")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetMLModelTransformJobOutput: AWSDecodableShape {
        /// The base data processing job.
        public let baseProcessingJob: MlResourceDefinition?
        /// The unique identifier of the model-transform job to be retrieved.
        public let id: String?
        /// A list of the configuration information for the models being used.
        public let models: [MlConfigDefinition]?
        /// The remote model transform job.
        public let remoteModelTransformJob: MlResourceDefinition?
        /// The status of the model-transform job.
        public let status: String?

        public init(baseProcessingJob: MlResourceDefinition? = nil, id: String? = nil, models: [MlConfigDefinition]? = nil, remoteModelTransformJob: MlResourceDefinition? = nil, status: String? = nil) {
            self.baseProcessingJob = baseProcessingJob
            self.id = id
            self.models = models
            self.remoteModelTransformJob = remoteModelTransformJob
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case baseProcessingJob = "baseProcessingJob"
            case id = "id"
            case models = "models"
            case remoteModelTransformJob = "remoteModelTransformJob"
            case status = "status"
        }
    }

    public struct GetOpenCypherQueryStatusInput: AWSEncodableShape {
        /// The unique ID of the openCypher query for which to retrieve the query status.
        public let queryId: String

        public init(queryId: String) {
            self.queryId = queryId
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodePath(self.queryId, key: "queryId")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetOpenCypherQueryStatusOutput: AWSDecodableShape {
        /// The openCypher query evaluation status.
        public let queryEvalStats: QueryEvalStats?
        /// The unique ID of the query for which status is being returned.
        public let queryId: String?
        /// The openCypher query string.
        public let queryString: String?

        public init(queryEvalStats: QueryEvalStats? = nil, queryId: String? = nil, queryString: String? = nil) {
            self.queryEvalStats = queryEvalStats
            self.queryId = queryId
            self.queryString = queryString
        }

        private enum CodingKeys: String, CodingKey {
            case queryEvalStats = "queryEvalStats"
            case queryId = "queryId"
            case queryString = "queryString"
        }
    }

    public struct GetPropertygraphStatisticsOutput: AWSDecodableShape {
        /// Statistics for property-graph data.
        public let payload: Statistics
        /// The HTTP return code of the request. If the request succeeded, the code is 200. See Common error codes for DFE statistics request for a list of common errors.
        public let status: String

        public init(payload: Statistics, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct GetPropertygraphStreamInput: AWSEncodableShape {
        /// The commit number of the starting record to read from the change-log stream. This parameter is required when iteratorType isAT_SEQUENCE_NUMBER or AFTER_SEQUENCE_NUMBER, and ignored when iteratorType is TRIM_HORIZON or LATEST.
        public let commitNum: Int64?
        /// If set to TRUE, Neptune compresses the response using gzip encoding.
        public let encoding: Encoding?
        /// Can be one of:    AT_SEQUENCE_NUMBER   –   Indicates that reading should start from the event sequence number specified jointly by the commitNum and opNum parameters.    AFTER_SEQUENCE_NUMBER   –   Indicates that reading should start right after the event sequence number specified jointly by the commitNum and opNum parameters.    TRIM_HORIZON   –   Indicates that reading should start at the last untrimmed record in the system, which is the oldest unexpired (not yet deleted) record in the change-log stream.    LATEST   –   Indicates that reading should start at the most recent record in the system, which is the latest unexpired (not yet deleted) record in the change-log stream.
        public let iteratorType: IteratorType?
        /// Specifies the maximum number of records to return. There is also a size limit of 10 MB on the response that can't be modified and that takes precedence over the number of records specified in the limit parameter. The response does include a threshold-breaching record if the 10 MB limit was reached. The range for limit is 1 to 100,000, with a default of 10.
        public let limit: Int64?
        /// The operation sequence number within the specified commit to start reading from in the change-log stream data. The default is 1.
        public let opNum: Int64?

        public init(commitNum: Int64? = nil, encoding: Encoding? = nil, iteratorType: IteratorType? = nil, limit: Int64? = nil, opNum: Int64? = nil) {
            self.commitNum = commitNum
            self.encoding = encoding
            self.iteratorType = iteratorType
            self.limit = limit
            self.opNum = opNum
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.commitNum, key: "commitNum")
            request.encodeHeader(self.encoding, key: "Accept-Encoding")
            request.encodeQuery(self.iteratorType, key: "iteratorType")
            request.encodeQuery(self.limit, key: "limit")
            request.encodeQuery(self.opNum, key: "opNum")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetPropertygraphStreamOutput: AWSDecodableShape {
        /// Serialization format for the change records being returned. Currently, the only supported value is PG_JSON.
        public let format: String
        /// Sequence identifier of the last change in the stream response. An event ID is composed of two fields: a commitNum, which identifies a transaction that changed the graph, and an opNum, which identifies a specific operation within that transaction:
        public let lastEventId: [String: String]
        /// The time at which the commit for the transaction was requested, in milliseconds from the Unix epoch.
        public let lastTrxTimestampInMillis: Int64
        /// An array of serialized change-log stream records included in the response.
        public let records: [PropertygraphRecord]
        /// The total number of records in the response.
        public let totalRecords: Int

        public init(format: String, lastEventId: [String: String], lastTrxTimestampInMillis: Int64, records: [PropertygraphRecord], totalRecords: Int) {
            self.format = format
            self.lastEventId = lastEventId
            self.lastTrxTimestampInMillis = lastTrxTimestampInMillis
            self.records = records
            self.totalRecords = totalRecords
        }

        private enum CodingKeys: String, CodingKey {
            case format = "format"
            case lastEventId = "lastEventId"
            case lastTrxTimestampInMillis = "lastTrxTimestamp"
            case records = "records"
            case totalRecords = "totalRecords"
        }
    }

    public struct GetPropertygraphSummaryInput: AWSEncodableShape {
        /// Mode can take one of two values: BASIC (the default), and DETAILED.
        public let mode: GraphSummaryType?

        public init(mode: GraphSummaryType? = nil) {
            self.mode = mode
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.mode, key: "mode")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetPropertygraphSummaryOutput: AWSDecodableShape {
        /// Payload containing the property graph summary response.
        public let payload: PropertygraphSummaryValueMap?
        /// The HTTP return code of the request. If the request succeeded, the code is 200.
        public let statusCode: Int?

        public init(payload: PropertygraphSummaryValueMap? = nil, statusCode: Int? = nil) {
            self.payload = payload
            self.statusCode = statusCode
        }

        public init(from decoder: Decoder) throws {
            let response = decoder.userInfo[.awsResponse]! as! ResponseDecodingContainer
            let container = try decoder.container(keyedBy: CodingKeys.self)
            self.payload = try container.decodeIfPresent(PropertygraphSummaryValueMap.self, forKey: .payload)
            self.statusCode = response.decodeStatus()
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
        }
    }

    public struct GetRDFGraphSummaryInput: AWSEncodableShape {
        /// Mode can take one of two values: BASIC (the default), and DETAILED.
        public let mode: GraphSummaryType?

        public init(mode: GraphSummaryType? = nil) {
            self.mode = mode
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.mode, key: "mode")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetRDFGraphSummaryOutput: AWSDecodableShape {
        /// Payload for an RDF graph summary response
        public let payload: RDFGraphSummaryValueMap?
        /// The HTTP return code of the request. If the request succeeded, the code is 200.
        public let statusCode: Int?

        public init(payload: RDFGraphSummaryValueMap? = nil, statusCode: Int? = nil) {
            self.payload = payload
            self.statusCode = statusCode
        }

        public init(from decoder: Decoder) throws {
            let response = decoder.userInfo[.awsResponse]! as! ResponseDecodingContainer
            let container = try decoder.container(keyedBy: CodingKeys.self)
            self.payload = try container.decodeIfPresent(RDFGraphSummaryValueMap.self, forKey: .payload)
            self.statusCode = response.decodeStatus()
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
        }
    }

    public struct GetSparqlStatisticsOutput: AWSDecodableShape {
        /// Statistics for RDF data.
        public let payload: Statistics
        /// The HTTP return code of the request. If the request succeeded, the code is 200. See Common error codes for DFE statistics request for a list of common errors. When invoking this operation in a Neptune cluster that has IAM authentication enabled, the IAM user or role making the request must have a policy attached that allows the neptune-db:GetStatisticsStatus IAM action in that cluster.
        public let status: String

        public init(payload: Statistics, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct GetSparqlStreamInput: AWSEncodableShape {
        /// The commit number of the starting record to read from the change-log stream. This parameter is required when iteratorType isAT_SEQUENCE_NUMBER or AFTER_SEQUENCE_NUMBER, and ignored when iteratorType is TRIM_HORIZON or LATEST.
        public let commitNum: Int64?
        /// If set to TRUE, Neptune compresses the response using gzip encoding.
        public let encoding: Encoding?
        /// Can be one of:    AT_SEQUENCE_NUMBER   –   Indicates that reading should start from the event sequence number specified jointly by the commitNum and opNum parameters.    AFTER_SEQUENCE_NUMBER   –   Indicates that reading should start right after the event sequence number specified jointly by the commitNum and opNum parameters.    TRIM_HORIZON   –   Indicates that reading should start at the last untrimmed record in the system, which is the oldest unexpired (not yet deleted) record in the change-log stream.    LATEST   –   Indicates that reading should start at the most recent record in the system, which is the latest unexpired (not yet deleted) record in the change-log stream.
        public let iteratorType: IteratorType?
        /// Specifies the maximum number of records to return. There is also a size limit of 10 MB on the response that can't be modified and that takes precedence over the number of records specified in the limit parameter. The response does include a threshold-breaching record if the 10 MB limit was reached. The range for limit is 1 to 100,000, with a default of 10.
        public let limit: Int64?
        /// The operation sequence number within the specified commit to start reading from in the change-log stream data. The default is 1.
        public let opNum: Int64?

        public init(commitNum: Int64? = nil, encoding: Encoding? = nil, iteratorType: IteratorType? = nil, limit: Int64? = nil, opNum: Int64? = nil) {
            self.commitNum = commitNum
            self.encoding = encoding
            self.iteratorType = iteratorType
            self.limit = limit
            self.opNum = opNum
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.commitNum, key: "commitNum")
            request.encodeHeader(self.encoding, key: "Accept-Encoding")
            request.encodeQuery(self.iteratorType, key: "iteratorType")
            request.encodeQuery(self.limit, key: "limit")
            request.encodeQuery(self.opNum, key: "opNum")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct GetSparqlStreamOutput: AWSDecodableShape {
        /// Serialization format for the change records being returned. Currently, the only supported value is NQUADS.
        public let format: String
        /// Sequence identifier of the last change in the stream response. An event ID is composed of two fields: a commitNum, which identifies a transaction that changed the graph, and an opNum, which identifies a specific operation within that transaction:
        public let lastEventId: [String: String]
        /// The time at which the commit for the transaction was requested, in milliseconds from the Unix epoch.
        public let lastTrxTimestampInMillis: Int64
        /// An array of serialized change-log stream records included in the response.
        public let records: [SparqlRecord]
        /// The total number of records in the response.
        public let totalRecords: Int

        public init(format: String, lastEventId: [String: String], lastTrxTimestampInMillis: Int64, records: [SparqlRecord], totalRecords: Int) {
            self.format = format
            self.lastEventId = lastEventId
            self.lastTrxTimestampInMillis = lastTrxTimestampInMillis
            self.records = records
            self.totalRecords = totalRecords
        }

        private enum CodingKeys: String, CodingKey {
            case format = "format"
            case lastEventId = "lastEventId"
            case lastTrxTimestampInMillis = "lastTrxTimestamp"
            case records = "records"
            case totalRecords = "totalRecords"
        }
    }

    public struct GremlinQueryStatus: AWSDecodableShape {
        /// The query statistics of the Gremlin query.
        public let queryEvalStats: QueryEvalStats?
        /// The ID of the Gremlin query.
        public let queryId: String?
        /// The query string of the Gremlin query.
        public let queryString: String?

        public init(queryEvalStats: QueryEvalStats? = nil, queryId: String? = nil, queryString: String? = nil) {
            self.queryEvalStats = queryEvalStats
            self.queryId = queryId
            self.queryString = queryString
        }

        private enum CodingKeys: String, CodingKey {
            case queryEvalStats = "queryEvalStats"
            case queryId = "queryId"
            case queryString = "queryString"
        }
    }

    public struct GremlinQueryStatusAttributes: AWSDecodableShape {
        /// Attributes of the Gremlin query status.
        public let attributes: String?
        /// The HTTP response code returned fro the Gremlin query request..
        public let code: Int?
        /// The status message.
        public let message: String?

        public init(attributes: String? = nil, code: Int? = nil, message: String? = nil) {
            self.attributes = attributes
            self.code = code
            self.message = message
        }

        private enum CodingKeys: String, CodingKey {
            case attributes = "attributes"
            case code = "code"
            case message = "message"
        }
    }

    public struct ListGremlinQueriesInput: AWSEncodableShape {
        /// If set to TRUE, the list returned includes waiting queries. The default is FALSE;
        public let includeWaiting: Bool?

        public init(includeWaiting: Bool? = nil) {
            self.includeWaiting = includeWaiting
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.includeWaiting, key: "includeWaiting")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListGremlinQueriesOutput: AWSDecodableShape {
        /// The number of queries that have been accepted but not yet completed, including queries in the queue.
        public let acceptedQueryCount: Int?
        /// A list of the current queries.
        public let queries: [GremlinQueryStatus]?
        /// The number of Gremlin queries currently running.
        public let runningQueryCount: Int?

        public init(acceptedQueryCount: Int? = nil, queries: [GremlinQueryStatus]? = nil, runningQueryCount: Int? = nil) {
            self.acceptedQueryCount = acceptedQueryCount
            self.queries = queries
            self.runningQueryCount = runningQueryCount
        }

        private enum CodingKeys: String, CodingKey {
            case acceptedQueryCount = "acceptedQueryCount"
            case queries = "queries"
            case runningQueryCount = "runningQueryCount"
        }
    }

    public struct ListLoaderJobsInput: AWSEncodableShape {
        /// An optional parameter that can be used to exclude the load IDs of queued load requests when requesting a list of load IDs by setting the parameter to FALSE. The default value is TRUE.
        public let includeQueuedLoads: Bool?
        /// The number of load IDs to list. Must be a positive integer greater than zero and not more than 100 (which is the default).
        public let limit: Int?

        public init(includeQueuedLoads: Bool? = nil, limit: Int? = nil) {
            self.includeQueuedLoads = includeQueuedLoads
            self.limit = limit
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.includeQueuedLoads, key: "includeQueuedLoads")
            request.encodeQuery(self.limit, key: "limit")
        }

        public func validate(name: String) throws {
            try self.validate(self.limit, name: "limit", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListLoaderJobsOutput: AWSDecodableShape {
        /// The requested list of job IDs.
        public let payload: LoaderIdResult
        /// Returns the status of the job list request.
        public let status: String

        public init(payload: LoaderIdResult, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct ListMLDataProcessingJobsInput: AWSEncodableShape {
        /// The maximum number of items to return (from 1 to 1024; the default is 10).
        public let maxItems: Int?
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(maxItems: Int? = nil, neptuneIamRoleArn: String? = nil) {
            self.maxItems = maxItems
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.maxItems, key: "maxItems")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        public func validate(name: String) throws {
            try self.validate(self.maxItems, name: "maxItems", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListMLDataProcessingJobsOutput: AWSDecodableShape {
        /// A page listing data processing job IDs.
        public let ids: [String]?

        public init(ids: [String]? = nil) {
            self.ids = ids
        }

        private enum CodingKeys: String, CodingKey {
            case ids = "ids"
        }
    }

    public struct ListMLEndpointsInput: AWSEncodableShape {
        /// The maximum number of items to return (from 1 to 1024; the default is 10.
        public let maxItems: Int?
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(maxItems: Int? = nil, neptuneIamRoleArn: String? = nil) {
            self.maxItems = maxItems
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.maxItems, key: "maxItems")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        public func validate(name: String) throws {
            try self.validate(self.maxItems, name: "maxItems", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListMLEndpointsOutput: AWSDecodableShape {
        /// A page from the list of inference endpoint IDs.
        public let ids: [String]?

        public init(ids: [String]? = nil) {
            self.ids = ids
        }

        private enum CodingKeys: String, CodingKey {
            case ids = "ids"
        }
    }

    public struct ListMLModelTrainingJobsInput: AWSEncodableShape {
        /// The maximum number of items to return (from 1 to 1024; the default is 10).
        public let maxItems: Int?
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(maxItems: Int? = nil, neptuneIamRoleArn: String? = nil) {
            self.maxItems = maxItems
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.maxItems, key: "maxItems")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        public func validate(name: String) throws {
            try self.validate(self.maxItems, name: "maxItems", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListMLModelTrainingJobsOutput: AWSDecodableShape {
        /// A page of the list of model training job IDs.
        public let ids: [String]?

        public init(ids: [String]? = nil) {
            self.ids = ids
        }

        private enum CodingKeys: String, CodingKey {
            case ids = "ids"
        }
    }

    public struct ListMLModelTransformJobsInput: AWSEncodableShape {
        /// The maximum number of items to return (from 1 to 1024; the default is 10).
        public let maxItems: Int?
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?

        public init(maxItems: Int? = nil, neptuneIamRoleArn: String? = nil) {
            self.maxItems = maxItems
            self.neptuneIamRoleArn = neptuneIamRoleArn
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.maxItems, key: "maxItems")
            request.encodeQuery(self.neptuneIamRoleArn, key: "neptuneIamRoleArn")
        }

        public func validate(name: String) throws {
            try self.validate(self.maxItems, name: "maxItems", parent: name, min: 1)
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListMLModelTransformJobsOutput: AWSDecodableShape {
        /// A page from the list of model transform IDs.
        public let ids: [String]?

        public init(ids: [String]? = nil) {
            self.ids = ids
        }

        private enum CodingKeys: String, CodingKey {
            case ids = "ids"
        }
    }

    public struct ListOpenCypherQueriesInput: AWSEncodableShape {
        ///  When set to TRUE and other parameters are not present, causes status information to be returned for waiting queries as well as for running queries.
        public let includeWaiting: Bool?

        public init(includeWaiting: Bool? = nil) {
            self.includeWaiting = includeWaiting
        }

        public func encode(to encoder: Encoder) throws {
            let request = encoder.userInfo[.awsRequest]! as! RequestEncodingContainer
            _ = encoder.container(keyedBy: CodingKeys.self)
            request.encodeQuery(self.includeWaiting, key: "includeWaiting")
        }

        private enum CodingKeys: CodingKey {}
    }

    public struct ListOpenCypherQueriesOutput: AWSDecodableShape {
        /// The number of queries that have been accepted but not yet completed, including queries in the queue.
        public let acceptedQueryCount: Int?
        /// A list of current openCypher queries.
        public let queries: [GremlinQueryStatus]?
        /// The number of currently running openCypher queries.
        public let runningQueryCount: Int?

        public init(acceptedQueryCount: Int? = nil, queries: [GremlinQueryStatus]? = nil, runningQueryCount: Int? = nil) {
            self.acceptedQueryCount = acceptedQueryCount
            self.queries = queries
            self.runningQueryCount = runningQueryCount
        }

        private enum CodingKeys: String, CodingKey {
            case acceptedQueryCount = "acceptedQueryCount"
            case queries = "queries"
            case runningQueryCount = "runningQueryCount"
        }
    }

    public struct LoaderIdResult: AWSDecodableShape {
        /// A list of load IDs.
        public let loadIds: [String]?

        public init(loadIds: [String]? = nil) {
            self.loadIds = loadIds
        }

        private enum CodingKeys: String, CodingKey {
            case loadIds = "loadIds"
        }
    }

    public struct ManagePropertygraphStatisticsInput: AWSEncodableShape {
        /// The statistics generation mode. One of: DISABLE_AUTOCOMPUTE, ENABLE_AUTOCOMPUTE, or REFRESH, the last of which manually triggers DFE statistics generation.
        public let mode: StatisticsAutoGenerationMode?

        public init(mode: StatisticsAutoGenerationMode? = nil) {
            self.mode = mode
        }

        private enum CodingKeys: String, CodingKey {
            case mode = "mode"
        }
    }

    public struct ManagePropertygraphStatisticsOutput: AWSDecodableShape {
        /// This is only returned for refresh mode.
        public let payload: RefreshStatisticsIdMap?
        /// The HTTP return code of the request. If the request succeeded, the code is 200.
        public let status: String

        public init(payload: RefreshStatisticsIdMap? = nil, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct ManageSparqlStatisticsInput: AWSEncodableShape {
        /// The statistics generation mode. One of: DISABLE_AUTOCOMPUTE, ENABLE_AUTOCOMPUTE, or REFRESH, the last of which manually triggers DFE statistics generation.
        public let mode: StatisticsAutoGenerationMode?

        public init(mode: StatisticsAutoGenerationMode? = nil) {
            self.mode = mode
        }

        private enum CodingKeys: String, CodingKey {
            case mode = "mode"
        }
    }

    public struct ManageSparqlStatisticsOutput: AWSDecodableShape {
        /// This is only returned for refresh mode.
        public let payload: RefreshStatisticsIdMap?
        /// The HTTP return code of the request. If the request succeeded, the code is 200.
        public let status: String

        public init(payload: RefreshStatisticsIdMap? = nil, status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct MlConfigDefinition: AWSDecodableShape {
        /// The ARN for the configuration.
        public let arn: String?
        /// The configuration name.
        public let name: String?

        public init(arn: String? = nil, name: String? = nil) {
            self.arn = arn
            self.name = name
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case name = "name"
        }
    }

    public struct MlResourceDefinition: AWSDecodableShape {
        /// The resource ARN.
        public let arn: String?
        /// The CloudWatch log URL for the resource.
        public let cloudwatchLogUrl: String?
        /// The failure reason, in case of a failure.
        public let failureReason: String?
        /// The resource name.
        public let name: String?
        /// The output location.
        public let outputLocation: String?
        /// The resource status.
        public let status: String?

        public init(arn: String? = nil, cloudwatchLogUrl: String? = nil, failureReason: String? = nil, name: String? = nil, outputLocation: String? = nil, status: String? = nil) {
            self.arn = arn
            self.cloudwatchLogUrl = cloudwatchLogUrl
            self.failureReason = failureReason
            self.name = name
            self.outputLocation = outputLocation
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case cloudwatchLogUrl = "cloudwatchLogUrl"
            case failureReason = "failureReason"
            case name = "name"
            case outputLocation = "outputLocation"
            case status = "status"
        }
    }

    public struct NodeStructure: AWSDecodableShape {
        /// Number of nodes that have this specific structure.
        public let count: Int64?
        /// A list of distinct outgoing edge labels present in this specific structure.
        public let distinctOutgoingEdgeLabels: [String]?
        /// A list of the node properties present in this specific structure.
        public let nodeProperties: [String]?

        public init(count: Int64? = nil, distinctOutgoingEdgeLabels: [String]? = nil, nodeProperties: [String]? = nil) {
            self.count = count
            self.distinctOutgoingEdgeLabels = distinctOutgoingEdgeLabels
            self.nodeProperties = nodeProperties
        }

        private enum CodingKeys: String, CodingKey {
            case count = "count"
            case distinctOutgoingEdgeLabels = "distinctOutgoingEdgeLabels"
            case nodeProperties = "nodeProperties"
        }
    }

    public struct PropertygraphData: AWSDecodableShape {
        /// If this is an edge (type = e), the ID of the corresponding from vertex or source node.
        public let from: String?
        /// The ID of the Gremlin or openCypher element.
        public let id: String
        /// The property name. For element labels, this is label.
        public let key: String
        /// If this is an edge (type = e), the ID of the corresponding to vertex or target node.
        public let to: String?
        /// The type of this Gremlin or openCypher element. Must be one of:     v1   -   Vertex label for Gremlin, or node label for openCypher.     vp   -   Vertex properties for Gremlin, or node properties for openCypher.     e   -   Edge and edge label for Gremlin, or relationship and relationship type for openCypher.     ep   -   Edge properties for Gremlin, or relationship properties for openCypher.
        public let type: String
        /// This is a JSON object that contains a value field for the value itself, and a datatype field for the JSON data type of that value:
        public let value: String

        public init(from: String? = nil, id: String, key: String, to: String? = nil, type: String, value: String) {
            self.from = from
            self.id = id
            self.key = key
            self.to = to
            self.type = type
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case from = "from"
            case id = "id"
            case key = "key"
            case to = "to"
            case type = "type"
            case value = "value"
        }
    }

    public struct PropertygraphRecord: AWSDecodableShape {
        /// The time at which the commit for the transaction was requested, in milliseconds from the Unix epoch.
        public let commitTimestampInMillis: Int64
        /// The serialized Gremlin or openCypher change record.
        public let data: PropertygraphData
        /// The sequence identifier of the stream change record.
        public let eventId: [String: String]
        /// Only present if this operation is the last one in its transaction. If present, it is set to true. It is useful for ensuring that an entire transaction is consumed.
        public let isLastOp: Bool?
        /// The operation that created the change.
        public let op: String

        public init(commitTimestampInMillis: Int64, data: PropertygraphData, eventId: [String: String], isLastOp: Bool? = nil, op: String) {
            self.commitTimestampInMillis = commitTimestampInMillis
            self.data = data
            self.eventId = eventId
            self.isLastOp = isLastOp
            self.op = op
        }

        private enum CodingKeys: String, CodingKey {
            case commitTimestampInMillis = "commitTimestamp"
            case data = "data"
            case eventId = "eventId"
            case isLastOp = "isLastOp"
            case op = "op"
        }
    }

    public struct PropertygraphSummary: AWSDecodableShape {
        /// A list of the distinct edge labels in the graph.
        public let edgeLabels: [String]?
        /// A list of the distinct edge properties in the graph, along with the count of edges where each property is used.
        public let edgeProperties: [[String: Int64]]?
        /// This field is only present when the requested mode is DETAILED. It contains a list of edge structures.
        public let edgeStructures: [EdgeStructure]?
        /// A list of the distinct node labels in the graph.
        public let nodeLabels: [String]?
        /// The number of distinct node properties in the graph.
        public let nodeProperties: [[String: Int64]]?
        /// This field is only present when the requested mode is DETAILED. It contains a list of node structures.
        public let nodeStructures: [NodeStructure]?
        /// The number of distinct edge labels in the graph.
        public let numEdgeLabels: Int64?
        /// The number of distinct edge properties in the graph.
        public let numEdgeProperties: Int64?
        /// The number of edges in the graph.
        public let numEdges: Int64?
        /// The number of distinct node labels in the graph.
        public let numNodeLabels: Int64?
        /// A list of the distinct node properties in the graph, along with the count of nodes where each property is used.
        public let numNodeProperties: Int64?
        /// The number of nodes in the graph.
        public let numNodes: Int64?
        /// The total number of usages of all edge properties.
        public let totalEdgePropertyValues: Int64?
        /// The total number of usages of all node properties.
        public let totalNodePropertyValues: Int64?

        public init(edgeLabels: [String]? = nil, edgeProperties: [[String: Int64]]? = nil, edgeStructures: [EdgeStructure]? = nil, nodeLabels: [String]? = nil, nodeProperties: [[String: Int64]]? = nil, nodeStructures: [NodeStructure]? = nil, numEdgeLabels: Int64? = nil, numEdgeProperties: Int64? = nil, numEdges: Int64? = nil, numNodeLabels: Int64? = nil, numNodeProperties: Int64? = nil, numNodes: Int64? = nil, totalEdgePropertyValues: Int64? = nil, totalNodePropertyValues: Int64? = nil) {
            self.edgeLabels = edgeLabels
            self.edgeProperties = edgeProperties
            self.edgeStructures = edgeStructures
            self.nodeLabels = nodeLabels
            self.nodeProperties = nodeProperties
            self.nodeStructures = nodeStructures
            self.numEdgeLabels = numEdgeLabels
            self.numEdgeProperties = numEdgeProperties
            self.numEdges = numEdges
            self.numNodeLabels = numNodeLabels
            self.numNodeProperties = numNodeProperties
            self.numNodes = numNodes
            self.totalEdgePropertyValues = totalEdgePropertyValues
            self.totalNodePropertyValues = totalNodePropertyValues
        }

        private enum CodingKeys: String, CodingKey {
            case edgeLabels = "edgeLabels"
            case edgeProperties = "edgeProperties"
            case edgeStructures = "edgeStructures"
            case nodeLabels = "nodeLabels"
            case nodeProperties = "nodeProperties"
            case nodeStructures = "nodeStructures"
            case numEdgeLabels = "numEdgeLabels"
            case numEdgeProperties = "numEdgeProperties"
            case numEdges = "numEdges"
            case numNodeLabels = "numNodeLabels"
            case numNodeProperties = "numNodeProperties"
            case numNodes = "numNodes"
            case totalEdgePropertyValues = "totalEdgePropertyValues"
            case totalNodePropertyValues = "totalNodePropertyValues"
        }
    }

    public struct PropertygraphSummaryValueMap: AWSDecodableShape {
        /// The graph summary.
        public let graphSummary: PropertygraphSummary?
        /// The timestamp, in ISO 8601 format, of the time at which Neptune last computed statistics.
        public let lastStatisticsComputationTime: Date?
        /// The version of this graph summary response.
        public let version: String?

        public init(graphSummary: PropertygraphSummary? = nil, lastStatisticsComputationTime: Date? = nil, version: String? = nil) {
            self.graphSummary = graphSummary
            self.lastStatisticsComputationTime = lastStatisticsComputationTime
            self.version = version
        }

        private enum CodingKeys: String, CodingKey {
            case graphSummary = "graphSummary"
            case lastStatisticsComputationTime = "lastStatisticsComputationTime"
            case version = "version"
        }
    }

    public struct QueryEvalStats: AWSDecodableShape {
        /// Set to TRUE if the query was cancelled, or FALSE otherwise.
        public let cancelled: Bool?
        /// The number of milliseconds the query has been running so far.
        public let elapsed: Int?
        /// The number of subqueries in this query.
        public let subqueries: String?
        /// Indicates how long the query waited, in milliseconds.
        public let waited: Int?

        public init(cancelled: Bool? = nil, elapsed: Int? = nil, subqueries: String? = nil, waited: Int? = nil) {
            self.cancelled = cancelled
            self.elapsed = elapsed
            self.subqueries = subqueries
            self.waited = waited
        }

        private enum CodingKeys: String, CodingKey {
            case cancelled = "cancelled"
            case elapsed = "elapsed"
            case subqueries = "subqueries"
            case waited = "waited"
        }
    }

    public struct QueryLanguageVersion: AWSDecodableShape {
        /// The version of the query language.
        public let version: String

        public init(version: String) {
            self.version = version
        }

        private enum CodingKeys: String, CodingKey {
            case version = "version"
        }
    }

    public struct RDFGraphSummary: AWSDecodableShape {
        /// A list of the classes in the graph.
        public let classes: [String]?
        /// The number of classes in the graph.
        public let numClasses: Int64?
        /// The number of distinct predicates in the graph.
        public let numDistinctPredicates: Int64?
        /// The number of distinct subjects in the graph.
        public let numDistinctSubjects: Int64?
        /// The number of quads in the graph.
        public let numQuads: Int64?
        /// "A list of predicates in the graph, along with the predicate counts.
        public let predicates: [[String: Int64]]?
        /// This field is only present when the request mode is DETAILED. It contains a list of subject structures.
        public let subjectStructures: [SubjectStructure]?

        public init(classes: [String]? = nil, numClasses: Int64? = nil, numDistinctPredicates: Int64? = nil, numDistinctSubjects: Int64? = nil, numQuads: Int64? = nil, predicates: [[String: Int64]]? = nil, subjectStructures: [SubjectStructure]? = nil) {
            self.classes = classes
            self.numClasses = numClasses
            self.numDistinctPredicates = numDistinctPredicates
            self.numDistinctSubjects = numDistinctSubjects
            self.numQuads = numQuads
            self.predicates = predicates
            self.subjectStructures = subjectStructures
        }

        private enum CodingKeys: String, CodingKey {
            case classes = "classes"
            case numClasses = "numClasses"
            case numDistinctPredicates = "numDistinctPredicates"
            case numDistinctSubjects = "numDistinctSubjects"
            case numQuads = "numQuads"
            case predicates = "predicates"
            case subjectStructures = "subjectStructures"
        }
    }

    public struct RDFGraphSummaryValueMap: AWSDecodableShape {
        /// The graph summary of an RDF graph. See Graph summary response for an RDF graph.
        public let graphSummary: RDFGraphSummary?
        /// The timestamp, in ISO 8601 format, of the time at which Neptune last computed statistics.
        public let lastStatisticsComputationTime: Date?
        /// The version of this graph summary response.
        public let version: String?

        public init(graphSummary: RDFGraphSummary? = nil, lastStatisticsComputationTime: Date? = nil, version: String? = nil) {
            self.graphSummary = graphSummary
            self.lastStatisticsComputationTime = lastStatisticsComputationTime
            self.version = version
        }

        private enum CodingKeys: String, CodingKey {
            case graphSummary = "graphSummary"
            case lastStatisticsComputationTime = "lastStatisticsComputationTime"
            case version = "version"
        }
    }

    public struct RefreshStatisticsIdMap: AWSDecodableShape {
        /// The ID of the statistics generation run that is currently occurring.
        public let statisticsId: String?

        public init(statisticsId: String? = nil) {
            self.statisticsId = statisticsId
        }

        private enum CodingKeys: String, CodingKey {
            case statisticsId = "statisticsId"
        }
    }

    public struct SparqlData: AWSDecodableShape {
        /// Holds an N-QUADS statement expressing the changed quad.
        public let stmt: String

        public init(stmt: String) {
            self.stmt = stmt
        }

        private enum CodingKeys: String, CodingKey {
            case stmt = "stmt"
        }
    }

    public struct SparqlRecord: AWSDecodableShape {
        /// The time at which the commit for the transaction was requested, in milliseconds from the Unix epoch.
        public let commitTimestampInMillis: Int64
        /// The serialized SPARQL change record. The serialization formats of each record are described in more detail in Serialization Formats in Neptune Streams.
        public let data: SparqlData
        /// The sequence identifier of the stream change record.
        public let eventId: [String: String]
        /// Only present if this operation is the last one in its transaction. If present, it is set to true. It is useful for ensuring that an entire transaction is consumed.
        public let isLastOp: Bool?
        /// The operation that created the change.
        public let op: String

        public init(commitTimestampInMillis: Int64, data: SparqlData, eventId: [String: String], isLastOp: Bool? = nil, op: String) {
            self.commitTimestampInMillis = commitTimestampInMillis
            self.data = data
            self.eventId = eventId
            self.isLastOp = isLastOp
            self.op = op
        }

        private enum CodingKeys: String, CodingKey {
            case commitTimestampInMillis = "commitTimestamp"
            case data = "data"
            case eventId = "eventId"
            case isLastOp = "isLastOp"
            case op = "op"
        }
    }

    public struct StartLoaderJobInput: AWSEncodableShape {
        /// This is an optional parameter that can make a queued load request contingent on the successful completion of one or more previous jobs in the queue. Neptune can queue up as many as 64 load requests at a time, if their queueRequest parameters are set to "TRUE". The dependencies parameter lets you make execution of such a queued request dependent on the successful completion of one or more specified previous requests in the queue. For example, if load Job-A and Job-B are independent of each other, but load Job-C needs Job-A and Job-B to be finished before it begins, proceed as follows:   Submit  load-job-A and load-job-B one after another in any order, and save their load-ids.   Submit load-job-C with the load-ids of the two jobs in its dependencies field:   Because of the dependencies parameter, the bulk loader will not start Job-C until Job-A and Job-B have completed successfully. If either one of them fails, Job-C will not be executed, and its status will be set to LOAD_FAILED_BECAUSE_DEPENDENCY_NOT_SATISFIED. You can set up multiple levels of dependency in this way, so that the failure of one job will cause all requests that are directly or indirectly dependent on it to be cancelled.
        public let dependencies: [String]?
        ///   failOnError   –   A flag to toggle a complete stop on an error.  Allowed values: "TRUE", "FALSE".  Default value: "TRUE". When this parameter is set to "FALSE", the loader tries to load all the data in the location specified, skipping any entries with errors. When this parameter is set to "TRUE", the loader stops as soon as it encounters an error.  Data loaded up to that point persists.
        public let failOnError: Bool?
        /// The format of the data. For more information about data formats for the Neptune Loader command, see Load Data Formats.  Allowed values      csv for the Gremlin CSV data format.     opencypher for the openCypher CSV data format.     ntriples for the N-Triples RDF data format.     nquads for the N-Quads RDF data format.     rdfxml for the RDF\XML RDF data format.     turtle for the Turtle RDF data format.
        public let format: Format
        /// The Amazon Resource Name (ARN) for an IAM role to be assumed by the Neptune DB instance for access to the S3 bucket. The IAM role ARN provided here should be attached to the DB cluster (see Adding the IAM Role to an Amazon Neptune Cluster.
        public let iamRoleArn: String
        /// The load job mode.  Allowed values: RESUME, NEW, AUTO.  Default value: AUTO.       RESUME   –   In RESUME mode, the loader looks for a previous load from this source, and if it finds one, resumes that load job. If no previous load job is  found, the loader stops. The loader avoids reloading files that were successfully loaded in a previous job. It only tries to process failed files. If you dropped previously loaded data from your Neptune cluster, that data is not reloaded in this mode. If a previous load job loaded all files from the same source successfully, nothing is reloaded, and the loader returns success.    NEW   –   In NEW mode, the creates a new load request regardless of any previous loads. You can use this mode to reload all the data from a source after dropping previously loaded data from your Neptune cluster, or to load new data available at the same source.    AUTO   –   In AUTO mode, the loader looks for a previous load job from the same source, and if it finds one, resumes that job, just as in RESUME mode. If the loader doesn't find a previous load job from the same source, it loads all data from the source, just as in NEW mode.
        public let mode: Mode?
        /// The optional parallelism parameter can be set to reduce the number of threads used by the bulk load process.  Allowed values:    LOW –   The number of threads used is the number of available vCPUs divided by 8.    MEDIUM –   The number of threads used is the number of available vCPUs divided by 2.    HIGH –   The number of threads used is the same as the number of available vCPUs.    OVERSUBSCRIBE –   The number of threads used is the number of available vCPUs multiplied by 2. If this value is used, the bulk loader takes up all available resources. This does not mean, however, that the OVERSUBSCRIBE setting results in 100% CPU utilization. Because the load operation is I/O bound, the highest CPU utilization to expect is in the 60% to 70% range.    Default value: HIGH  The parallelism setting can sometimes result in a deadlock between threads when loading openCypher data. When this happens, Neptune returns the LOAD_DATA_DEADLOCK error. You can generally fix the issue by setting parallelism to a lower setting and retrying the load command.
        public let parallelism: Parallelism?
        ///   parserConfiguration   –   An optional object with additional parser configuration values. Each of the child parameters is also optional:        namedGraphUri   –   The default graph for all RDF formats when no graph is specified (for non-quads formats and NQUAD entries with no graph). The default is https://aws.amazon.com/neptune/vocab/v01/DefaultNamedGraph.     baseUri   –   The base URI for RDF/XML and Turtle formats. The default is https://aws.amazon.com/neptune/default.     allowEmptyStrings   –   Gremlin users need to be able to pass empty string values("") as node and edge properties when loading CSV data. If allowEmptyStrings is set to false (the default), such empty strings are treated as nulls and are not loaded. If allowEmptyStrings is set to true, the loader treats empty strings as valid property values and loads them accordingly.
        public let parserConfiguration: [String: String]?
        /// This is an optional flag parameter that indicates whether the load request can be queued up or not.  You don't have to wait for one load job to complete before issuing the next one, because Neptune can queue up as many as 64 jobs at a time, provided that their queueRequest parameters are all set to "TRUE". The queue order of the jobs will be first-in-first-out (FIFO). If the queueRequest parameter is omitted or set to "FALSE", the load request will fail if another load job is already running.  Allowed values: "TRUE", "FALSE".  Default value: "FALSE".
        public let queueRequest: Bool?
        /// The Amazon region of the S3 bucket. This must match the Amazon Region of the DB cluster.
        public let s3BucketRegion: S3BucketRegion
        /// The source parameter accepts an S3 URI that identifies a single file, multiple files, a folder, or multiple folders. Neptune loads every data file in any folder that is specified. The URI can be in any of the following formats.    s3://(bucket_name)/(object-key-name)     https://s3.amazonaws.com/(bucket_name)/(object-key-name)     https://s3.us-east-1.amazonaws.com/(bucket_name)/(object-key-name)    The object-key-name element of the URI is equivalent to the prefix parameter in an S3 ListObjects API call.  It identifies all the objects in the specified S3 bucket whose names begin with that prefix.  That can be a single file or folder, or multiple files and/or folders. The specified folder or folders can contain multiple vertex files and multiple edge files.
        public let source: String
        ///  updateSingleCardinalityProperties is an optional parameter that controls how the bulk loader treats a new value for single-cardinality vertex or edge properties. This is not supported for loading openCypher data.  Allowed values: "TRUE", "FALSE".  Default value: "FALSE". By default, or when updateSingleCardinalityProperties is explicitly set to "FALSE", the loader treats a new value as an error, because it violates single cardinality. When updateSingleCardinalityProperties is set to "TRUE", on the other hand, the bulk loader replaces the existing value with the new one. If multiple edge or single-cardinality vertex property values are provided in the source file(s) being loaded, the final value at the end of the bulk load could be any one of those new values. The loader only guarantees that the existing value has been replaced by one of the new ones.
        public let updateSingleCardinalityProperties: Bool?
        /// This parameter is required only when loading openCypher data that contains relationship IDs. It must be included and set to True when openCypher relationship IDs are explicitly provided in the load data (recommended). When userProvidedEdgeIds is absent or set to True, an :ID column must be present in every relationship file in the load. When userProvidedEdgeIds is present and set to False, relationship files in the load must not contain an :ID column. Instead, the Neptune loader automatically generates an ID for each relationship. It's useful to provide relationship IDs explicitly so that the loader can resume loading after error in the CSV data have been fixed, without having to reload any relationships that have already been loaded. If relationship IDs have not been explicitly assigned, the loader cannot resume a failed load if any relationship file has had to be corrected, and must instead reload all the relationships.
        public let userProvidedEdgeIds: Bool?

        public init(dependencies: [String]? = nil, failOnError: Bool? = nil, format: Format, iamRoleArn: String, mode: Mode? = nil, parallelism: Parallelism? = nil, parserConfiguration: [String: String]? = nil, queueRequest: Bool? = nil, s3BucketRegion: S3BucketRegion, source: String, updateSingleCardinalityProperties: Bool? = nil, userProvidedEdgeIds: Bool? = nil) {
            self.dependencies = dependencies
            self.failOnError = failOnError
            self.format = format
            self.iamRoleArn = iamRoleArn
            self.mode = mode
            self.parallelism = parallelism
            self.parserConfiguration = parserConfiguration
            self.queueRequest = queueRequest
            self.s3BucketRegion = s3BucketRegion
            self.source = source
            self.updateSingleCardinalityProperties = updateSingleCardinalityProperties
            self.userProvidedEdgeIds = userProvidedEdgeIds
        }

        private enum CodingKeys: String, CodingKey {
            case dependencies = "dependencies"
            case failOnError = "failOnError"
            case format = "format"
            case iamRoleArn = "iamRoleArn"
            case mode = "mode"
            case parallelism = "parallelism"
            case parserConfiguration = "parserConfiguration"
            case queueRequest = "queueRequest"
            case s3BucketRegion = "region"
            case source = "source"
            case updateSingleCardinalityProperties = "updateSingleCardinalityProperties"
            case userProvidedEdgeIds = "userProvidedEdgeIds"
        }
    }

    public struct StartLoaderJobOutput: AWSDecodableShape {
        /// Contains a loadId name-value pair that provides an identifier for the load operation.
        public let payload: [String: String]
        /// The HTTP return code indicating the status of the load job.
        public let status: String

        public init(payload: [String: String], status: String) {
            self.payload = payload
            self.status = status
        }

        private enum CodingKeys: String, CodingKey {
            case payload = "payload"
            case status = "status"
        }
    }

    public struct StartMLDataProcessingJobInput: AWSEncodableShape {
        /// A data specification file that describes how to load the exported graph data for training. The file is automatically generated by the Neptune export toolkit. The default is training-data-configuration.json.
        public let configFileName: String?
        /// A unique identifier for the new job. The default is an autogenerated UUID.
        public let id: String?
        /// The URI of the Amazon S3 location where you want SageMaker to download the data needed to run the data processing job.
        public let inputDataS3Location: String
        /// One of the two model types that Neptune ML currently supports: heterogeneous graph models (heterogeneous), and knowledge graph (kge). The default is none. If not specified, Neptune ML chooses the model type automatically based on the data.
        public let modelType: String?
        /// The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?
        /// The job ID of a completed data processing job run on an earlier version of the data.
        public let previousDataProcessingJobId: String?
        /// The URI of the Amazon S3 location where you want SageMaker to save the results of a data processing job.
        public let processedDataS3Location: String
        /// The type of ML instance used during data processing. Its memory should be large enough to hold the processed dataset. The default is the smallest ml.r5 type whose memory is ten times larger than the size of the exported graph data on disk.
        public let processingInstanceType: String?
        /// The disk volume size of the processing instance. Both input data and processed data are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML chooses the volume size automatically based on the data size.
        public let processingInstanceVolumeSizeInGB: Int?
        /// Timeout in seconds for the data processing job. The default is 86,400 (1 day).
        public let processingTimeOutInSeconds: Int?
        /// The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.
        public let s3OutputEncryptionKMSKey: String?
        /// The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.
        public let sagemakerIamRoleArn: String?
        /// The VPC security group IDs. The default is None.
        public let securityGroupIds: [String]?
        /// The IDs of the subnets in the Neptune VPC. The default is None.
        public let subnets: [String]?
        /// The Amazon Key Management Service (Amazon KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.
        public let volumeEncryptionKMSKey: String?

        public init(configFileName: String? = nil, id: String? = nil, inputDataS3Location: String, modelType: String? = nil, neptuneIamRoleArn: String? = nil, previousDataProcessingJobId: String? = nil, processedDataS3Location: String, processingInstanceType: String? = nil, processingInstanceVolumeSizeInGB: Int? = nil, processingTimeOutInSeconds: Int? = nil, s3OutputEncryptionKMSKey: String? = nil, sagemakerIamRoleArn: String? = nil, securityGroupIds: [String]? = nil, subnets: [String]? = nil, volumeEncryptionKMSKey: String? = nil) {
            self.configFileName = configFileName
            self.id = id
            self.inputDataS3Location = inputDataS3Location
            self.modelType = modelType
            self.neptuneIamRoleArn = neptuneIamRoleArn
            self.previousDataProcessingJobId = previousDataProcessingJobId
            self.processedDataS3Location = processedDataS3Location
            self.processingInstanceType = processingInstanceType
            self.processingInstanceVolumeSizeInGB = processingInstanceVolumeSizeInGB
            self.processingTimeOutInSeconds = processingTimeOutInSeconds
            self.s3OutputEncryptionKMSKey = s3OutputEncryptionKMSKey
            self.sagemakerIamRoleArn = sagemakerIamRoleArn
            self.securityGroupIds = securityGroupIds
            self.subnets = subnets
            self.volumeEncryptionKMSKey = volumeEncryptionKMSKey
        }

        private enum CodingKeys: String, CodingKey {
            case configFileName = "configFileName"
            case id = "id"
            case inputDataS3Location = "inputDataS3Location"
            case modelType = "modelType"
            case neptuneIamRoleArn = "neptuneIamRoleArn"
            case previousDataProcessingJobId = "previousDataProcessingJobId"
            case processedDataS3Location = "processedDataS3Location"
            case processingInstanceType = "processingInstanceType"
            case processingInstanceVolumeSizeInGB = "processingInstanceVolumeSizeInGB"
            case processingTimeOutInSeconds = "processingTimeOutInSeconds"
            case s3OutputEncryptionKMSKey = "s3OutputEncryptionKMSKey"
            case sagemakerIamRoleArn = "sagemakerIamRoleArn"
            case securityGroupIds = "securityGroupIds"
            case subnets = "subnets"
            case volumeEncryptionKMSKey = "volumeEncryptionKMSKey"
        }
    }

    public struct StartMLDataProcessingJobOutput: AWSDecodableShape {
        /// The ARN of the data processing job.
        public let arn: String?
        /// The time it took to create the new processing job, in milliseconds.
        public let creationTimeInMillis: Int64?
        /// The unique ID of the new data processing job.
        public let id: String?

        public init(arn: String? = nil, creationTimeInMillis: Int64? = nil, id: String? = nil) {
            self.arn = arn
            self.creationTimeInMillis = creationTimeInMillis
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case creationTimeInMillis = "creationTimeInMillis"
            case id = "id"
        }
    }

    public struct StartMLModelTrainingJobInput: AWSEncodableShape {
        /// The type of ML instance used in preparing and managing training of ML models. This is a CPU instance chosen based on memory requirements for processing the training data and model.
        public let baseProcessingInstanceType: String?
        /// The configuration for custom model training. This is a JSON object.
        public let customModelTrainingParameters: CustomModelTrainingParameters?
        /// The job ID of the completed data-processing job that has created the data that the training will work with.
        public let dataProcessingJobId: String
        /// Optimizes the cost of training machine-learning models by using Amazon Elastic Compute Cloud spot instances. The default is False.
        public let enableManagedSpotTraining: Bool?
        /// A unique identifier for the new job. The default is An autogenerated UUID.
        public let id: String?
        /// Maximum total number of training jobs to start for the hyperparameter tuning job. The default is 2. Neptune ML automatically tunes the hyperparameters of the machine learning model.  To obtain a model that performs well, use at least 10 jobs (in other words, set maxHPONumberOfTrainingJobs to 10). In general, the more tuning runs, the better the results.
        public let maxHPONumberOfTrainingJobs: Int?
        /// Maximum number of parallel training jobs to start for the hyperparameter tuning job. The default is 2. The number of parallel jobs you can run is limited by the available resources on your training instance.
        public let maxHPOParallelTrainingJobs: Int?
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?
        /// The job ID of a completed model-training job that you want to update incrementally based on updated data.
        public let previousModelTrainingJobId: String?
        /// The Amazon Key Management Service (KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.
        public let s3OutputEncryptionKMSKey: String?
        /// The ARN of an IAM role for SageMaker execution.This must be listed in your DB cluster parameter group or an error will occur.
        public let sagemakerIamRoleArn: String?
        /// The VPC security group IDs. The default is None.
        public let securityGroupIds: [String]?
        /// The IDs of the subnets in the Neptune VPC. The default is None.
        public let subnets: [String]?
        /// The type of ML instance used for model training. All Neptune ML models support CPU, GPU, and multiGPU training. The default is ml.p3.2xlarge. Choosing the right instance type for training depends on the task type, graph size, and your budget.
        public let trainingInstanceType: String?
        /// The disk volume size of the training instance. Both input data and the output model are stored on disk, so the volume size must be large enough to hold both data sets. The default is 0. If not specified or 0, Neptune ML selects a disk volume size based on the recommendation generated in the data processing step.
        public let trainingInstanceVolumeSizeInGB: Int?
        /// Timeout in seconds for the training job. The default is 86,400 (1 day).
        public let trainingTimeOutInSeconds: Int?
        /// The location in Amazon S3 where the model artifacts are to be stored.
        public let trainModelS3Location: String
        /// The Amazon Key Management Service (KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.
        public let volumeEncryptionKMSKey: String?

        public init(baseProcessingInstanceType: String? = nil, customModelTrainingParameters: CustomModelTrainingParameters? = nil, dataProcessingJobId: String, enableManagedSpotTraining: Bool? = nil, id: String? = nil, maxHPONumberOfTrainingJobs: Int? = nil, maxHPOParallelTrainingJobs: Int? = nil, neptuneIamRoleArn: String? = nil, previousModelTrainingJobId: String? = nil, s3OutputEncryptionKMSKey: String? = nil, sagemakerIamRoleArn: String? = nil, securityGroupIds: [String]? = nil, subnets: [String]? = nil, trainingInstanceType: String? = nil, trainingInstanceVolumeSizeInGB: Int? = nil, trainingTimeOutInSeconds: Int? = nil, trainModelS3Location: String, volumeEncryptionKMSKey: String? = nil) {
            self.baseProcessingInstanceType = baseProcessingInstanceType
            self.customModelTrainingParameters = customModelTrainingParameters
            self.dataProcessingJobId = dataProcessingJobId
            self.enableManagedSpotTraining = enableManagedSpotTraining
            self.id = id
            self.maxHPONumberOfTrainingJobs = maxHPONumberOfTrainingJobs
            self.maxHPOParallelTrainingJobs = maxHPOParallelTrainingJobs
            self.neptuneIamRoleArn = neptuneIamRoleArn
            self.previousModelTrainingJobId = previousModelTrainingJobId
            self.s3OutputEncryptionKMSKey = s3OutputEncryptionKMSKey
            self.sagemakerIamRoleArn = sagemakerIamRoleArn
            self.securityGroupIds = securityGroupIds
            self.subnets = subnets
            self.trainingInstanceType = trainingInstanceType
            self.trainingInstanceVolumeSizeInGB = trainingInstanceVolumeSizeInGB
            self.trainingTimeOutInSeconds = trainingTimeOutInSeconds
            self.trainModelS3Location = trainModelS3Location
            self.volumeEncryptionKMSKey = volumeEncryptionKMSKey
        }

        private enum CodingKeys: String, CodingKey {
            case baseProcessingInstanceType = "baseProcessingInstanceType"
            case customModelTrainingParameters = "customModelTrainingParameters"
            case dataProcessingJobId = "dataProcessingJobId"
            case enableManagedSpotTraining = "enableManagedSpotTraining"
            case id = "id"
            case maxHPONumberOfTrainingJobs = "maxHPONumberOfTrainingJobs"
            case maxHPOParallelTrainingJobs = "maxHPOParallelTrainingJobs"
            case neptuneIamRoleArn = "neptuneIamRoleArn"
            case previousModelTrainingJobId = "previousModelTrainingJobId"
            case s3OutputEncryptionKMSKey = "s3OutputEncryptionKMSKey"
            case sagemakerIamRoleArn = "sagemakerIamRoleArn"
            case securityGroupIds = "securityGroupIds"
            case subnets = "subnets"
            case trainingInstanceType = "trainingInstanceType"
            case trainingInstanceVolumeSizeInGB = "trainingInstanceVolumeSizeInGB"
            case trainingTimeOutInSeconds = "trainingTimeOutInSeconds"
            case trainModelS3Location = "trainModelS3Location"
            case volumeEncryptionKMSKey = "volumeEncryptionKMSKey"
        }
    }

    public struct StartMLModelTrainingJobOutput: AWSDecodableShape {
        /// The ARN of the new model training job.
        public let arn: String?
        /// The model training job creation time, in milliseconds.
        public let creationTimeInMillis: Int64?
        /// The unique ID of the new model training job.
        public let id: String?

        public init(arn: String? = nil, creationTimeInMillis: Int64? = nil, id: String? = nil) {
            self.arn = arn
            self.creationTimeInMillis = creationTimeInMillis
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case creationTimeInMillis = "creationTimeInMillis"
            case id = "id"
        }
    }

    public struct StartMLModelTransformJobInput: AWSEncodableShape {
        /// The type of ML instance used in preparing and managing training of ML models. This is an ML compute instance chosen based on memory requirements for processing the training data and model.
        public let baseProcessingInstanceType: String?
        /// The disk volume size of the training instance in gigabytes. The default is 0. Both input data and the output model are stored on disk, so the volume size must be large enough to hold both data sets. If not specified or 0, Neptune ML selects a disk volume size based on the recommendation generated in the data processing step.
        public let baseProcessingInstanceVolumeSizeInGB: Int?
        /// Configuration information for a model transform using a custom model. The customModelTransformParameters object contains the following fields, which must have values compatible with the saved model parameters from the training job:
        public let customModelTransformParameters: CustomModelTransformParameters?
        /// The job ID of a completed data-processing job. You must include either dataProcessingJobId and a mlModelTrainingJobId, or a trainingJobName.
        public let dataProcessingJobId: String?
        /// A unique identifier for the new job. The default is an autogenerated UUID.
        public let id: String?
        /// The job ID of a completed model-training job. You must include either dataProcessingJobId and a mlModelTrainingJobId, or a trainingJobName.
        public let mlModelTrainingJobId: String?
        /// The location in Amazon S3 where the model artifacts are to be stored.
        public let modelTransformOutputS3Location: String
        /// The ARN of an IAM role that provides Neptune access to SageMaker and Amazon S3 resources. This must be listed in your DB cluster parameter group or an error will occur.
        public let neptuneIamRoleArn: String?
        /// The Amazon Key Management Service (KMS) key that SageMaker uses to encrypt the output of the processing job. The default is none.
        public let s3OutputEncryptionKMSKey: String?
        /// The ARN of an IAM role for SageMaker execution. This must be listed in your DB cluster parameter group or an error will occur.
        public let sagemakerIamRoleArn: String?
        /// The VPC security group IDs. The default is None.
        public let securityGroupIds: [String]?
        /// The IDs of the subnets in the Neptune VPC. The default is None.
        public let subnets: [String]?
        /// The name of a completed SageMaker training job. You must include either dataProcessingJobId and a mlModelTrainingJobId, or a trainingJobName.
        public let trainingJobName: String?
        /// The Amazon Key Management Service (KMS) key that SageMaker uses to encrypt data on the storage volume attached to the ML compute instances that run the training job. The default is None.
        public let volumeEncryptionKMSKey: String?

        public init(baseProcessingInstanceType: String? = nil, baseProcessingInstanceVolumeSizeInGB: Int? = nil, customModelTransformParameters: CustomModelTransformParameters? = nil, dataProcessingJobId: String? = nil, id: String? = nil, mlModelTrainingJobId: String? = nil, modelTransformOutputS3Location: String, neptuneIamRoleArn: String? = nil, s3OutputEncryptionKMSKey: String? = nil, sagemakerIamRoleArn: String? = nil, securityGroupIds: [String]? = nil, subnets: [String]? = nil, trainingJobName: String? = nil, volumeEncryptionKMSKey: String? = nil) {
            self.baseProcessingInstanceType = baseProcessingInstanceType
            self.baseProcessingInstanceVolumeSizeInGB = baseProcessingInstanceVolumeSizeInGB
            self.customModelTransformParameters = customModelTransformParameters
            self.dataProcessingJobId = dataProcessingJobId
            self.id = id
            self.mlModelTrainingJobId = mlModelTrainingJobId
            self.modelTransformOutputS3Location = modelTransformOutputS3Location
            self.neptuneIamRoleArn = neptuneIamRoleArn
            self.s3OutputEncryptionKMSKey = s3OutputEncryptionKMSKey
            self.sagemakerIamRoleArn = sagemakerIamRoleArn
            self.securityGroupIds = securityGroupIds
            self.subnets = subnets
            self.trainingJobName = trainingJobName
            self.volumeEncryptionKMSKey = volumeEncryptionKMSKey
        }

        private enum CodingKeys: String, CodingKey {
            case baseProcessingInstanceType = "baseProcessingInstanceType"
            case baseProcessingInstanceVolumeSizeInGB = "baseProcessingInstanceVolumeSizeInGB"
            case customModelTransformParameters = "customModelTransformParameters"
            case dataProcessingJobId = "dataProcessingJobId"
            case id = "id"
            case mlModelTrainingJobId = "mlModelTrainingJobId"
            case modelTransformOutputS3Location = "modelTransformOutputS3Location"
            case neptuneIamRoleArn = "neptuneIamRoleArn"
            case s3OutputEncryptionKMSKey = "s3OutputEncryptionKMSKey"
            case sagemakerIamRoleArn = "sagemakerIamRoleArn"
            case securityGroupIds = "securityGroupIds"
            case subnets = "subnets"
            case trainingJobName = "trainingJobName"
            case volumeEncryptionKMSKey = "volumeEncryptionKMSKey"
        }
    }

    public struct StartMLModelTransformJobOutput: AWSDecodableShape {
        /// The ARN of the model transform job.
        public let arn: String?
        /// The creation time of the model transform job, in milliseconds.
        public let creationTimeInMillis: Int64?
        /// The unique ID of the new model transform job.
        public let id: String?

        public init(arn: String? = nil, creationTimeInMillis: Int64? = nil, id: String? = nil) {
            self.arn = arn
            self.creationTimeInMillis = creationTimeInMillis
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case arn = "arn"
            case creationTimeInMillis = "creationTimeInMillis"
            case id = "id"
        }
    }

    public struct Statistics: AWSDecodableShape {
        /// Indicates whether or not DFE statistics generation is enabled at all.
        public let active: Bool?
        /// Indicates whether or not automatic statistics generation is enabled.
        public let autoCompute: Bool?
        /// The UTC time at which DFE statistics have most recently been generated.
        public let date: Date?
        /// A note about problems in the case where statistics are invalid.
        public let note: String?
        /// A StatisticsSummary structure that contains:    signatureCount - The total number of signatures across all characteristic sets.    instanceCount - The total number of characteristic-set instances.    predicateCount - The total number of unique predicates.
        public let signatureInfo: StatisticsSummary?
        /// Reports the ID of the current statistics generation run. A value of -1 indicates that no statistics have been generated.
        public let statisticsId: String?

        public init(active: Bool? = nil, autoCompute: Bool? = nil, date: Date? = nil, note: String? = nil, signatureInfo: StatisticsSummary? = nil, statisticsId: String? = nil) {
            self.active = active
            self.autoCompute = autoCompute
            self.date = date
            self.note = note
            self.signatureInfo = signatureInfo
            self.statisticsId = statisticsId
        }

        private enum CodingKeys: String, CodingKey {
            case active = "active"
            case autoCompute = "autoCompute"
            case date = "date"
            case note = "note"
            case signatureInfo = "signatureInfo"
            case statisticsId = "statisticsId"
        }
    }

    public struct StatisticsSummary: AWSDecodableShape {
        /// The total number of characteristic-set instances.
        public let instanceCount: Int?
        /// The total number of unique predicates.
        public let predicateCount: Int?
        /// The total number of signatures across all characteristic sets.
        public let signatureCount: Int?

        public init(instanceCount: Int? = nil, predicateCount: Int? = nil, signatureCount: Int? = nil) {
            self.instanceCount = instanceCount
            self.predicateCount = predicateCount
            self.signatureCount = signatureCount
        }

        private enum CodingKeys: String, CodingKey {
            case instanceCount = "instanceCount"
            case predicateCount = "predicateCount"
            case signatureCount = "signatureCount"
        }
    }

    public struct SubjectStructure: AWSDecodableShape {
        /// Number of occurrences of this specific structure.
        public let count: Int64?
        /// A list of predicates present in this specific structure.
        public let predicates: [String]?

        public init(count: Int64? = nil, predicates: [String]? = nil) {
            self.count = count
            self.predicates = predicates
        }

        private enum CodingKeys: String, CodingKey {
            case count = "count"
            case predicates = "predicates"
        }
    }
}

// MARK: - Errors

/// Error enum for Neptunedata
public struct NeptunedataErrorType: AWSErrorType {
    enum Code: String {
        case accessDeniedException = "AccessDeniedException"
        case badRequestException = "BadRequestException"
        case bulkLoadIdNotFoundException = "BulkLoadIdNotFoundException"
        case cancelledByUserException = "CancelledByUserException"
        case clientTimeoutException = "ClientTimeoutException"
        case concurrentModificationException = "ConcurrentModificationException"
        case constraintViolationException = "ConstraintViolationException"
        case expiredStreamException = "ExpiredStreamException"
        case failureByQueryException = "FailureByQueryException"
        case illegalArgumentException = "IllegalArgumentException"
        case internalFailureException = "InternalFailureException"
        case invalidArgumentException = "InvalidArgumentException"
        case invalidNumericDataException = "InvalidNumericDataException"
        case invalidParameterException = "InvalidParameterException"
        case loadUrlAccessDeniedException = "LoadUrlAccessDeniedException"
        case malformedQueryException = "MalformedQueryException"
        case memoryLimitExceededException = "MemoryLimitExceededException"
        case methodNotAllowedException = "MethodNotAllowedException"
        case missingParameterException = "MissingParameterException"
        case mlResourceNotFoundException = "MLResourceNotFoundException"
        case parsingException = "ParsingException"
        case preconditionsFailedException = "PreconditionsFailedException"
        case queryLimitExceededException = "QueryLimitExceededException"
        case queryLimitException = "QueryLimitException"
        case queryTooLargeException = "QueryTooLargeException"
        case readOnlyViolationException = "ReadOnlyViolationException"
        case s3Exception = "S3Exception"
        case serverShutdownException = "ServerShutdownException"
        case statisticsNotAvailableException = "StatisticsNotAvailableException"
        case streamRecordsNotFoundException = "StreamRecordsNotFoundException"
        case throttlingException = "ThrottlingException"
        case timeLimitExceededException = "TimeLimitExceededException"
        case tooManyRequestsException = "TooManyRequestsException"
        case unsupportedOperationException = "UnsupportedOperationException"
    }

    private let error: Code
    public let context: AWSErrorContext?

    /// initialize Neptunedata
    public init?(errorCode: String, context: AWSErrorContext) {
        guard let error = Code(rawValue: errorCode) else { return nil }
        self.error = error
        self.context = context
    }

    internal init(_ error: Code) {
        self.error = error
        self.context = nil
    }

    /// return error code string
    public var errorCode: String { self.error.rawValue }

    /// Raised in case of an authentication or authorization failure.
    public static var accessDeniedException: Self { .init(.accessDeniedException) }
    /// Raised when a request is submitted that cannot be processed.
    public static var badRequestException: Self { .init(.badRequestException) }
    /// Raised when a specified bulk-load job ID cannot be found.
    public static var bulkLoadIdNotFoundException: Self { .init(.bulkLoadIdNotFoundException) }
    /// Raised when a user cancelled a request.
    public static var cancelledByUserException: Self { .init(.cancelledByUserException) }
    /// Raised when a request timed out in the client.
    public static var clientTimeoutException: Self { .init(.clientTimeoutException) }
    /// Raised when a request attempts to modify data that is concurrently being modified by another process.
    public static var concurrentModificationException: Self { .init(.concurrentModificationException) }
    /// Raised when a value in a request field did not satisfy required constraints.
    public static var constraintViolationException: Self { .init(.constraintViolationException) }
    /// Raised when a request attempts to access an stream that has expired.
    public static var expiredStreamException: Self { .init(.expiredStreamException) }
    /// Raised when a request fails.
    public static var failureByQueryException: Self { .init(.failureByQueryException) }
    /// Raised when an argument in a request is not supported.
    public static var illegalArgumentException: Self { .init(.illegalArgumentException) }
    /// Raised when the processing of the request failed unexpectedly.
    public static var internalFailureException: Self { .init(.internalFailureException) }
    /// Raised when an argument in a request has an invalid value.
    public static var invalidArgumentException: Self { .init(.invalidArgumentException) }
    /// Raised when invalid numerical data is encountered when servicing a request.
    public static var invalidNumericDataException: Self { .init(.invalidNumericDataException) }
    /// Raised when a parameter value is not valid.
    public static var invalidParameterException: Self { .init(.invalidParameterException) }
    /// Raised when access is denied to a specified load URL.
    public static var loadUrlAccessDeniedException: Self { .init(.loadUrlAccessDeniedException) }
    /// Raised when a query is submitted that is syntactically incorrect or does not pass additional validation.
    public static var malformedQueryException: Self { .init(.malformedQueryException) }
    /// Raised when a request fails because of insufficient memory resources. The request can be retried.
    public static var memoryLimitExceededException: Self { .init(.memoryLimitExceededException) }
    /// Raised when the HTTP method used by a request is not supported by the endpoint being used.
    public static var methodNotAllowedException: Self { .init(.methodNotAllowedException) }
    /// Raised when a required parameter is missing.
    public static var missingParameterException: Self { .init(.missingParameterException) }
    /// Raised when a specified machine-learning resource could not be found.
    public static var mlResourceNotFoundException: Self { .init(.mlResourceNotFoundException) }
    /// Raised when a parsing issue is encountered.
    public static var parsingException: Self { .init(.parsingException) }
    /// Raised when a precondition for processing a request is not satisfied.
    public static var preconditionsFailedException: Self { .init(.preconditionsFailedException) }
    /// Raised when the number of active queries exceeds what the server can process. The query in question can be retried when the system is less busy.
    public static var queryLimitExceededException: Self { .init(.queryLimitExceededException) }
    /// Raised when the size of a query exceeds the system limit.
    public static var queryLimitException: Self { .init(.queryLimitException) }
    /// Raised when the body of a query is too large.
    public static var queryTooLargeException: Self { .init(.queryTooLargeException) }
    /// Raised when a request attempts to write to a read-only resource.
    public static var readOnlyViolationException: Self { .init(.readOnlyViolationException) }
    /// Raised when there is a problem accessing Amazon S3.
    public static var s3Exception: Self { .init(.s3Exception) }
    /// Raised when the server shuts down while processing a request.
    public static var serverShutdownException: Self { .init(.serverShutdownException) }
    /// Raised when statistics needed to satisfy a request are not available.
    public static var statisticsNotAvailableException: Self { .init(.statisticsNotAvailableException) }
    /// Raised when stream records requested by a query cannot be found.
    public static var streamRecordsNotFoundException: Self { .init(.streamRecordsNotFoundException) }
    /// Raised when the rate of requests exceeds the maximum throughput. Requests can be retried after encountering this exception.
    public static var throttlingException: Self { .init(.throttlingException) }
    /// Raised when the an operation exceeds the time limit allowed for it.
    public static var timeLimitExceededException: Self { .init(.timeLimitExceededException) }
    /// Raised when the number of requests being processed exceeds the limit.
    public static var tooManyRequestsException: Self { .init(.tooManyRequestsException) }
    /// Raised when a request attempts to initiate an operation that is not supported.
    public static var unsupportedOperationException: Self { .init(.unsupportedOperationException) }
}

extension NeptunedataErrorType: Equatable {
    public static func == (lhs: NeptunedataErrorType, rhs: NeptunedataErrorType) -> Bool {
        lhs.error == rhs.error
    }
}

extension NeptunedataErrorType: CustomStringConvertible {
    public var description: String {
        return "\(self.error.rawValue): \(self.message ?? "")"
    }
}
